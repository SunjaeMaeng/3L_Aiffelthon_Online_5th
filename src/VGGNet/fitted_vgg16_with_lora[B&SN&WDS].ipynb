{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McBYcpzkTZ9_",
    "outputId": "d4f50f7f-1f36-499e-c7f5-06fd2a6556f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 01:28:18.144435: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 01:28:18.144512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 01:28:18.144544: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 01:28:18.185690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3H9TbtJTO5k"
   },
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GWr9Ep7TOZi",
    "outputId": "136299f0-86c1-481e-ab3c-05ec906f35e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 90s 1us/step\n",
      "train data\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "test data\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('train data')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('test data')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5IyhwDy0TcOf"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리: 정규화\n",
    "x_train, x_test = x_train / 255.0,  x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1xQRMYeTg3_",
    "outputId": "fc0fd22a-d6a6-44ed-ff49-3e6b1ccd80fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "test data\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 01:29:55.853836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18452 MB memory:  -> device: 0, name: NVIDIA RTX 4000 SFF Ada Generation, pci bus id: 0000:08:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# scalar 형태의 레이블(0-9)을 one-hot encoding 형태로 변환합니다\n",
    "\n",
    "y_train = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
    "y_test = tf.squeeze(tf.one_hot(y_test, 10), axis=1)\n",
    "\n",
    "print('train data')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('test data')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj-DhZZZTRxC"
   },
   "source": [
    "# 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfhhV71RMn2Y",
    "outputId": "1bd29034-f8a3-4a9b-e809-0421850e535a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_LJi10btMdaM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_vgg16 = load_model(\"./best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olYdP2YUM_Pi",
    "outputId": "e1f2a0d2-57ee-4317-d058-7b8c4492fc43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18918730 (72.17 MB)\n",
      "Trainable params: 18918730 (72.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoj2Gx6bfMfH"
   },
   "source": [
    "# inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj3unl9_8z33",
    "outputId": "27b87c46-7be8-4dfb-8256-c78a7bc72bcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 01:35:43.480334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8905\n",
      "2023-12-01 01:35:43.655075: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-01 01:35:44.222682: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 7ms/step - loss: 0.5326 - accuracy: 0.8536\n",
      "Evaluation time: 4.1580 seconds\n",
      "Loss: 0.5325827598571777, Accuracy: 0.853600025177002\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score = best_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score[0]}, Accuracy: {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv-4CTjZPIoJ"
   },
   "source": [
    "## 가중치 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1m-0r85R0TO",
    "outputId": "4d9c8f1d-2b58-40d2-e874-bddce66cdb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 1792\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36928\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 73856\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 147584\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 295168\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 590080\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 590080\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 1180160\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 2101248\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 2097664\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 5130\n",
      "  Non-trainable parameters: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in best_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX5RRcHq9CDt"
   },
   "source": [
    "# [Code] LoRA\n",
    "\n",
    "아래의 lora 코드에는 scheduling factor와 noise가 포함되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UylB2lpL9Gy5"
   },
   "source": [
    "## ConvLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "npn-lPaP9Hev"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, initializers\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, Conv3D\n",
    "\n",
    "class ConvLoRALayer00_cdn2(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_conv_layer,\n",
    "        total_iteration = 1000 ,  # Total number of iterations for the decay\n",
    "        start_percent=0.1,  # The percentage of total_iteration when decay starts\n",
    "        end_percent=0.9,  # The percentage of total_iteration when decay ends\n",
    "        min_decay_factor=0,  # The minimum value that decay factor can take\n",
    "        rank=32,\n",
    "        alpha=32,\n",
    "        trainable=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Capture the original layer's configuration.\n",
    "        original_layer_config = original_conv_layer.get_config()\n",
    "        name = original_layer_config[\"name\"]\n",
    "        kwargs.pop(\"name\", None)\n",
    "\n",
    "        super().__init__(name=name, trainable=trainable, **kwargs)\n",
    "\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self._scale = alpha / rank\n",
    "\n",
    "        # The original convolutional layer is set to non-trainable to freeze its weights.\n",
    "        self.original_conv_layer = original_conv_layer\n",
    "        self.original_conv_layer.trainable = False\n",
    "\n",
    "        self.kernel = None\n",
    "        self.filters = original_conv_layer.filters #\n",
    "        self.kernel_size = original_conv_layer.kernel_size[0] #\n",
    "        self.in_channels = None\n",
    "\n",
    "        self.total_iteration = total_iteration\n",
    "        self.start_step = int(total_iteration * start_percent)\n",
    "        self.end_step = int(total_iteration * end_percent)\n",
    "        self.min_decay_factor = min_decay_factor\n",
    "\n",
    "        #trainable=False, 이 변수가 텐서플로우의 자동 미분 및 최적화 과정에 의해 업데이트되지 않는다는 뜻\n",
    "        #수동으로 업데이트될 수 있습니다. 예를 들어, 반복문 안에서 이 변수의 값을 업데이트하는 로직을 작성할 수 있음!\n",
    "        self.current_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.decay_factor = tf.Variable(1.0, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Ensure the original convolutional layer is built.\n",
    "        #if not self.original_conv_layer.built:\n",
    "        #    self.original_conv_layer.build(input_shape)\n",
    "\n",
    "        # Calculate the shape for LoRA weights A and B.\n",
    "        #self.kernel = self.original_conv_layer.kernel\n",
    "        self.in_channels = input_shape[-1]\n",
    "\n",
    "        in_channels = self.in_channels\n",
    "        out_channels = self.filters\n",
    "        kernel_size = self.original_conv_layer.kernel_size[0]\n",
    "\n",
    "        # LoRA weights A and B.\n",
    "        self.A_weight = self.add_weight(\n",
    "            name=\"lora_A_weight\",\n",
    "            shape=(self.rank*kernel_size, in_channels*kernel_size),\n",
    "            initializer=initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform'),\n",
    "            trainable=self.trainable\n",
    "        )\n",
    "\n",
    "        self.B_weight = self.add_weight(\n",
    "            name=\"lora_B_weight\",\n",
    "            shape=(out_channels*kernel_size, self.rank*kernel_size),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=self.trainable\n",
    "        )\n",
    "\n",
    "        bias_shape = self.original_conv_layer.bias.shape\n",
    "        self.C_weight = self.add_weight(\n",
    "            name=\"lora_C_weight\",\n",
    "            shape=bias_shape,\n",
    "            initializer=\"zeros\",\n",
    "            trainable=self.trainable\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None:\n",
    "                training = self.trainable\n",
    "\n",
    "        # Calculate the linear decay factor\n",
    "        if self.current_step < self.start_step:\n",
    "            self.decay_factor.assign(1.0)  # Decay has not started yet\n",
    "        elif self.current_step > self.end_step:\n",
    "            self.decay_factor.assign(tf.cast(self.min_decay_factor, dtype=tf.float32))  # Ensure float32 type for consistency\n",
    "        else:\n",
    "            # Linear decay between start_step and end_step\n",
    "            self.decay_factor.assign(1.0 - ((tf.cast(self.current_step, dtype=tf.float32) - self.start_step) /\n",
    "                                    (self.end_step - self.start_step) *\n",
    "                                    (1.0 - tf.cast(self.min_decay_factor, dtype=tf.float32))))\n",
    "\n",
    "        lora_BA = (self.B_weight@self.A_weight)\n",
    "\n",
    "        kernel_size = self.original_conv_layer.kernel_size[0]\n",
    "        in_channels = self.in_channels\n",
    "        out_channels = self.filters\n",
    "\n",
    "           # lora_BA의 형태 변환\n",
    "           # lora_BA가 (out_channels*kernel_size*kernel_size, in_channels*kernel_size*kernel_size) 형태라고 가정\n",
    "           # 이를 (kernel_size, kernel_size, in_channels, out_channels)로 변환\n",
    "        lora_BA_reshaped = tf.reshape(lora_BA, (out_channels, kernel_size, kernel_size, in_channels))\n",
    "        lora_BA_reshaped = tf.transpose(lora_BA_reshaped, [1, 2, 3, 0])\n",
    "        lora_output = tf.nn.conv2d(inputs, lora_BA_reshaped, strides=[1, 1, 1, 1], padding='SAME') * self._scale\n",
    "\n",
    "        # original_output = self.original_conv_layer(inputs) * self.decay_factor\n",
    "\n",
    "        if training:\n",
    "            original_output = self.original_conv_layer(inputs)\n",
    "            # 평균과 표준편차 계산\n",
    "            original_weight_matrix = self.original_conv_layer.weights[0]\n",
    "            original_mean = tf.reduce_mean(original_weight_matrix)\n",
    "            original_variance = tf.reduce_mean(tf.square(original_weight_matrix - original_mean))\n",
    "            original_stddev = tf.sqrt(original_variance)\n",
    "\n",
    "            # decay_factor가 0.3보다 작으면 noise_mean과 noise_std를 0으로 설정\n",
    "            noise_mean = tf.where(self.decay_factor < 0.3, 0.0, original_mean * (1 - self.decay_factor))\n",
    "            noise_std = tf.where(self.decay_factor < 0.3, 0.0, original_stddev * tf.sqrt(1 - tf.square(self.decay_factor)))\n",
    "            noise = tf.random.normal(tf.shape(original_weight_matrix), mean=noise_mean, stddev=noise_std)\n",
    "            noise_output = tf.nn.conv2d(inputs, noise, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            self.current_step.assign_add(1)\n",
    "\n",
    "            return original_output * self.decay_factor + noise_output + lora_output + self.C_weight\n",
    "\n",
    "        else:\n",
    "            # 추론 모드에서는 LoRA 출력만 반환\n",
    "            return lora_output + self.C_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLLXZoFi9UgM"
   },
   "source": [
    "## DenseLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b3zto3tY9Wu8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow import keras\n",
    "\n",
    "class LoraLayer(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_layer,\n",
    "        total_iteration = 1000 ,  # Total number of iterations for the decay\n",
    "        start_percent=0.1,  # The percentage of total_iteration when decay starts\n",
    "        end_percent=0.9,  # The percentage of total_iteration when decay ends\n",
    "        min_decay_factor=0,  # The minimum value that decay factor can take\n",
    "        rank=32,\n",
    "        alpha=32,\n",
    "        trainable=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        original_layer_config = original_layer.get_config()\n",
    "        name = original_layer_config[\"name\"]\n",
    "        kwargs.pop(\"name\", None)\n",
    "\n",
    "        super().__init__(name=name, trainable=trainable, **kwargs)\n",
    "\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self._scale = alpha / rank\n",
    "\n",
    "        self.original_layer = original_layer\n",
    "        self.original_layer.trainable = False\n",
    "\n",
    "\n",
    "        self.total_iteration = total_iteration\n",
    "        self.start_step = int(total_iteration * start_percent)\n",
    "        self.end_step = int(total_iteration * end_percent)\n",
    "        self.min_decay_factor = min_decay_factor\n",
    "\n",
    "        #trainable=False, 이 변수가 텐서플로우의 자동 미분 및 최적화 과정에 의해 업데이트되지 않는다는 뜻\n",
    "        #수동으로 업데이트될 수 있습니다. 예를 들어, 반복문 안에서 이 변수의 값을 업데이트하는 로직을 작성할 수 있음!\n",
    "        self.current_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.decay_factor = tf.Variable(1.0, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # LoRA weights.\n",
    "        kernel_shape = self.original_layer.kernel.shape\n",
    "        self.A_weight = self.add_weight(\n",
    "            name=\"lora_A_weight\",\n",
    "            shape=(self.rank, kernel_shape[0]),\n",
    "            initializer=keras.initializers.VarianceScaling(\n",
    "                scale=math.sqrt(5), mode=\"fan_in\", distribution=\"uniform\"\n",
    "            ),\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "\n",
    "        self.B_weight = self.add_weight(\n",
    "            name=\"lora_B_weight\",\n",
    "            shape=(self.original_layer.units, self.rank),\n",
    "            initializer='zeros',\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "        self.C_weight = self.add_weight(\n",
    "            name=\"lora_C_weight\",\n",
    "            shape=(self.original_layer.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "            if training is None:\n",
    "                training = self.trainable\n",
    "\n",
    "            # Calculate the linear decay factor\n",
    "            if self.current_step < self.start_step:\n",
    "                self.decay_factor.assign(1.0)  # Decay has not started yet\n",
    "            elif self.current_step > self.end_step:\n",
    "                self.decay_factor.assign(tf.cast(self.min_decay_factor, dtype=tf.float32))  # Ensure float32 type for consistency\n",
    "            else:\n",
    "                # Linear decay between start_step and end_step\n",
    "                self.decay_factor.assign(1.0 - ((tf.cast(self.current_step, dtype=tf.float32) - self.start_step) /\n",
    "                                        (self.end_step - self.start_step) *\n",
    "                                        (1.0 - tf.cast(self.min_decay_factor, dtype=tf.float32))))\n",
    "\n",
    "            # Matrix multiplication for A and B weights with inputs\n",
    "            lora_A_output = tf.matmul(self.A_weight, tf.transpose(inputs))  # Ax\n",
    "            lora_output = tf.transpose(tf.matmul(self.B_weight, lora_A_output) * self._scale)  # BAx Transpose back to [batch_size, original_layer.units]\n",
    "\n",
    "            #lora_output *= (1 - self.decay_factor) # 멘토링 때 나온 의견\n",
    "\n",
    "            if training:\n",
    "                original_output = self.original_layer(inputs)\n",
    "                # 평균과 표준편차 계산\n",
    "                original_weight_matrix = self.original_layer.weights[0]\n",
    "                original_mean = tf.reduce_mean(original_weight_matrix, axis=0)\n",
    "                original_variance = tf.reduce_mean(tf.square(original_weight_matrix - original_mean), axis=0)\n",
    "                original_stddev = tf.sqrt(original_variance)\n",
    "\n",
    "                # decay_factor가 0.3보다 작으면 noise_mean과 noise_std를 0으로 설정\n",
    "                noise_mean = tf.where(self.decay_factor < 0.3, 0.0, original_mean * (1 - self.decay_factor))\n",
    "                noise_std = tf.where(self.decay_factor < 0.3, 0.0, original_stddev * tf.sqrt(1 - tf.square(self.decay_factor)))\n",
    "                noise = tf.random.normal(tf.shape(original_weight_matrix), mean=noise_mean, stddev=noise_std)\n",
    "\n",
    "                self.current_step.assign_add(1)\n",
    "\n",
    "                return original_output * self.decay_factor + (inputs @ noise) + lora_output + self.C_weight\n",
    "\n",
    "            else:\n",
    "                # 추론 모드에서는 LoRA 출력만 반환\n",
    "                return lora_output + self.C_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBM9sOz3_Yt1"
   },
   "source": [
    "# LoRA 적용. Exp1: Convlora + Denselayer는 ❄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pww7eFLm30pR"
   },
   "source": [
    "## 1-1. (16, -) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zuTOhngBFiYl"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BPKqW1Hk_X6m"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp11_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uFd65OKPpW9T"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp11_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP-6DUC7FopE",
    "outputId": "48880b0e-06ed-4516-e050-be5ad1460155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11506     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55426     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101634    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184578    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350722    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1291266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20066196 (76.55 MB)\n",
      "Trainable params: 1147440 (4.38 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp11_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gdRpVfKPM3t"
   },
   "source": [
    "## 가중치 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEO3IP_PRqSl",
    "outputId": "257892f3-e271-442e-9f73-28ee97f583a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9712\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18496\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27776\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36992\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55552\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 111104\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2101248\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2097664\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp11_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMG9bhGIU2ch"
   },
   "source": [
    "## 스케줄링 및 노이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Knnl1gljU8aT"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp11_lora_vgg16.layers:\n",
    "    if isinstance(layer, ConvLoRALayer00_cdn2) or isinstance(layer, LoraLayer):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ESXAgLxgZVzR"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "f70WB6oBaKLk"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PhpCpsu_aMtY"
   },
   "outputs": [],
   "source": [
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKWXrQnopKB6"
   },
   "source": [
    "##학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pnAakdZ8aRCW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp11_lora_vgg16.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQ1mcREqapIR",
    "outputId": "da53d9b8-4072-48c6-a097-d55324328ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11506     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55426     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101634    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184578    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350722    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1291266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20066196 (76.55 MB)\n",
      "Trainable params: 1147440 (4.38 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp11_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQWxiR4Qas7b",
    "outputId": "14e05c72-9c65-409e-97bd-709c7cb93ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 01:36:06.564436: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6cbc311770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-01 01:36:06.564473: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 4000 SFF Ada Generation, Compute Capability 8.9\n",
      "2023-12-01 01:36:06.571602: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-01 01:36:06.732409: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9301\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.303544282913208, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 77s 35ms/step - loss: 0.2186 - accuracy: 0.9301 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9386\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3035888671875, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 56s 34ms/step - loss: 0.1933 - accuracy: 0.9386 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8961\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.3040318489074707, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.3305 - accuracy: 0.8961 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.8443\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3046720027923584, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 36ms/step - loss: 0.4873 - accuracy: 0.8443 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.8055\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3057711124420166, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 89s 53ms/step - loss: 0.6092 - accuracy: 0.8055 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7253 - accuracy: 0.7663\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.308471918106079, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.7253 - accuracy: 0.7663 - val_loss: 2.3085 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.7277\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3092241287231445, acc: 0.09839999675750732\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.8477 - accuracy: 0.7277 - val_loss: 2.3092 - val_accuracy: 0.0985\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9512 - accuracy: 0.6948\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3216018676757812, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.9512 - accuracy: 0.6948 - val_loss: 2.3216 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0492 - accuracy: 0.6599\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.3442890644073486, acc: 0.08669999986886978\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 1.0492 - accuracy: 0.6599 - val_loss: 2.3443 - val_accuracy: 0.0868\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1604 - accuracy: 0.6248\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3469016551971436, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 36ms/step - loss: 1.1604 - accuracy: 0.6248 - val_loss: 2.3469 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2451 - accuracy: 0.5906\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.523818016052246, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 1.2451 - accuracy: 0.5906 - val_loss: 2.5238 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3370 - accuracy: 0.5603\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 3.6609809398651123, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 1.3370 - accuracy: 0.5603 - val_loss: 3.6617 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.4316 - accuracy: 0.5215\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 4.949944496154785, acc: 0.10019999742507935\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 1.4316 - accuracy: 0.5215 - val_loss: 4.9496 - val_accuracy: 0.1002\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0225 - accuracy: 0.6819\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.5808846950531006, acc: 0.10220000147819519\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 1.0225 - accuracy: 0.6819 - val_loss: 2.5809 - val_accuracy: 0.1022\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.7641\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.697819709777832, acc: 0.10029999911785126\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.6933 - accuracy: 0.7641 - val_loss: 2.6978 - val_accuracy: 0.1003\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.7601\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.302431344985962, acc: 0.2093999981880188\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.7072 - accuracy: 0.7601 - val_loss: 2.3024 - val_accuracy: 0.2093\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.7548\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 2.1753787994384766, acc: 0.35420000553131104\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.7231 - accuracy: 0.7548 - val_loss: 2.1754 - val_accuracy: 0.3542\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.7481\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.8067662119865417, acc: 0.7253000140190125\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.7443 - accuracy: 0.7481 - val_loss: 0.8067 - val_accuracy: 0.7253\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7114 - accuracy: 0.7609\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.8284336924552917, acc: 0.7275999784469604\n",
      "\n",
      "1667/1667 [==============================] - 70s 42ms/step - loss: 0.7114 - accuracy: 0.7609 - val_loss: 0.8284 - val_accuracy: 0.7276\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.7780\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7723437547683716, acc: 0.7466999888420105\n",
      "\n",
      "1667/1667 [==============================] - 118s 71ms/step - loss: 0.6656 - accuracy: 0.7780 - val_loss: 0.7724 - val_accuracy: 0.7467\n"
     ]
    }
   ],
   "source": [
    "history11 = exp11_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxbUXaLxfZIF"
   },
   "source": [
    "## inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "k_0T6tZy5Lb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 0.7723 - accuracy: 0.7467\n",
      "Evaluation time: 6.5064 seconds\n",
      "Loss: 0.7723437547683716, Accuracy: 0.7466999888420105\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score11 = exp11_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score11[0]}, Accuracy: {score11[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "xLQEo46Gbt-o",
    "outputId": "24899d78-ba3f-4706-c3a9-4b3c85edabed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history11.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history11.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history11.history['loss'], label='Training Loss')\n",
    "plt.plot(history11.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvAH25Td4TPl"
   },
   "source": [
    "## 1-2. (32, -) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oX1SFBOl4f0i"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp12_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wk9goxZs4f0i"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp12_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaPm45ig4f0i",
    "outputId": "17e7ddf8-157d-4086-b404-219bb82115e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21154     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73858     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129282    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221442    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         406018    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401858   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21209412 (80.91 MB)\n",
      "Trainable params: 2290656 (8.74 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp12_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F77s-EYN4vcq",
    "outputId": "5ed50c15-9671-4598-858c-9f4bad9446c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19360\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36928\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55424\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73856\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110848\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221696\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2101248\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2097664\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp12_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "OK4liexw4zdy"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp12_lora_vgg16.layers:\n",
    "    if isinstance(layer, ConvLoRALayer00_cdn2) or isinstance(layer, LoraLayer):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1iKvTdFN4zdy"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lL8z4Ky84zdz"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vmjY3HT-4zdz"
   },
   "outputs": [],
   "source": [
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtqOiU8844Ta"
   },
   "source": [
    "##학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pCKYMJdu44Tb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp12_lora_vgg16.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSTgDSLX44Tb",
    "outputId": "a29a81ee-9af3-48ee-a7a7-5b40b65809ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21154     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73858     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129282    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221442    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         406018    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401858   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21209412 (80.91 MB)\n",
      "Trainable params: 2290656 (8.74 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp12_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW3wKPlB44Tb",
    "outputId": "809d9ffc-739f-434b-da51-97d045c0bbfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9539\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.303431749343872, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 124s 67ms/step - loss: 0.1465 - accuracy: 0.9539 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9639\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3035244941711426, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 56s 33ms/step - loss: 0.1123 - accuracy: 0.9639 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.9294\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.303805351257324, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.2172 - accuracy: 0.9294 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8868\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3040924072265625, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.3495 - accuracy: 0.8868 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.8588\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3042030334472656, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.4340 - accuracy: 0.8588 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.8268\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3046512603759766, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5231 - accuracy: 0.8268 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.8080\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3050053119659424, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.5870 - accuracy: 0.8080 - val_loss: 2.3050 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6655 - accuracy: 0.7804\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3093061447143555, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.6655 - accuracy: 0.7804 - val_loss: 2.3093 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7473 - accuracy: 0.7554\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.362877130508423, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.7473 - accuracy: 0.7554 - val_loss: 2.3629 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.7282\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.4483888149261475, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.8261 - accuracy: 0.7282 - val_loss: 2.4484 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8903 - accuracy: 0.7065\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.6513872146606445, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.8903 - accuracy: 0.7065 - val_loss: 2.6514 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9583 - accuracy: 0.6821\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 8.8314847946167, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.9583 - accuracy: 0.6821 - val_loss: 8.8310 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0248 - accuracy: 0.6612\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 5.31456184387207, acc: 0.10029999911785126\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 1.0248 - accuracy: 0.6612 - val_loss: 5.3146 - val_accuracy: 0.1003\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8338 - accuracy: 0.7623\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.376718282699585, acc: 0.10499999672174454\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.8338 - accuracy: 0.7623 - val_loss: 2.3767 - val_accuracy: 0.1050\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8205\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.6284425258636475, acc: 0.10689999908208847\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5309 - accuracy: 0.8205 - val_loss: 2.6284 - val_accuracy: 0.1069\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.8236\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.2141668796539307, acc: 0.30550000071525574\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5240 - accuracy: 0.8236 - val_loss: 2.2141 - val_accuracy: 0.3054\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5401 - accuracy: 0.8179\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.758198618888855, acc: 0.4336000084877014\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5401 - accuracy: 0.8179 - val_loss: 1.7582 - val_accuracy: 0.4336\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.8136\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.741447925567627, acc: 0.7523000240325928\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5558 - accuracy: 0.8136 - val_loss: 0.7414 - val_accuracy: 0.7524\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.8233\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.6881487965583801, acc: 0.7710000276565552\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.5279 - accuracy: 0.8233 - val_loss: 0.6882 - val_accuracy: 0.7711\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8430\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7267777919769287, acc: 0.767799973487854\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.4642 - accuracy: 0.8430 - val_loss: 0.7268 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "history12 = exp12_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfO75Di448v9"
   },
   "source": [
    "## inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "wl1krAx59dZi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7268 - accuracy: 0.7678\n",
      "Evaluation time: 3.2879 seconds\n",
      "Loss: 0.7267777919769287, Accuracy: 0.767799973487854\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score12 = exp12_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score12[0]}, Accuracy: {score12[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "oMHh5D1X48v-",
    "outputId": "dd106156-b16a-4ba3-8d3d-b564f77cbfa2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history12.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history12.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history12.history['loss'], label='Training Loss')\n",
    "plt.plot(history12.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iiF1k-9D0hd"
   },
   "source": [
    "---\n",
    "#Experiments 2 : 모든 Convlora + dense6,7에 denselora + dense8 ❄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmYS1wIAD5x8"
   },
   "source": [
    "## 2-1. (32, 32) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "GFXXUUlKFeK7"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Z2OFtKnqD4bc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=32, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp21_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GbLnmfaLELbE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp21_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aP_ss6DrEcBt",
    "outputId": "63671162-e007-44da-f92a-49b173cff6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21154     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73858     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129282    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221442    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         406018    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401858   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2252802   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2245634   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21508936 (82.05 MB)\n",
      "Trainable params: 2590176 (9.88 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp21_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "155io3wREiB2",
    "outputId": "1a1abe8e-8ae7-4f7b-a46a-add76eb92b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19360\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36928\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55424\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73856\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110848\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221696\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 151552\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp21_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6eHa70iQEo_N"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp21_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4vQVbHIuEsVk"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "sWlqdMvwFBdM"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Nv9o4F_-FEAb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp21_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OU9-UYR-4U1"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VH7DGSABFKfM",
    "outputId": "4c8bc6cb-79de-4456-d641-301e2d97ded9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9741\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3026113510131836, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 75s 37ms/step - loss: 0.0808 - accuracy: 0.9741 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9812\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3026628494262695, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 36ms/step - loss: 0.0599 - accuracy: 0.9812 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9512\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.3026323318481445, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 69s 42ms/step - loss: 0.1516 - accuracy: 0.9512 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.8963\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302677631378174, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 89s 53ms/step - loss: 0.3166 - accuracy: 0.8963 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8578\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.302872896194458, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.4377 - accuracy: 0.8578 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.8237\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3030459880828857, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.5342 - accuracy: 0.8237 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.7940\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3036000728607178, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 72s 43ms/step - loss: 0.6275 - accuracy: 0.7940 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7334 - accuracy: 0.7574\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3038623332977295, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 129s 78ms/step - loss: 0.7334 - accuracy: 0.7574 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8190 - accuracy: 0.7299\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.3046200275421143, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 130s 78ms/step - loss: 0.8190 - accuracy: 0.7299 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9138 - accuracy: 0.6985\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.314955949783325, acc: 0.12439999729394913\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.9138 - accuracy: 0.6985 - val_loss: 2.3150 - val_accuracy: 0.1244\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9881 - accuracy: 0.6705\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.5992555618286133, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 129s 77ms/step - loss: 0.9881 - accuracy: 0.6705 - val_loss: 2.5992 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0610 - accuracy: 0.6469\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 4.281917572021484, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 1.0610 - accuracy: 0.6469 - val_loss: 4.2814 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1262 - accuracy: 0.6243\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 7.496343612670898, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 131s 78ms/step - loss: 1.1262 - accuracy: 0.6243 - val_loss: 7.4955 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8946 - accuracy: 0.7220\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.3332839012145996, acc: 0.09780000150203705\n",
      "\n",
      "1667/1667 [==============================] - 133s 80ms/step - loss: 0.8946 - accuracy: 0.7220 - val_loss: 2.3333 - val_accuracy: 0.0978\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.7933\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.224585771560669, acc: 0.16300000250339508\n",
      "\n",
      "1667/1667 [==============================] - 133s 80ms/step - loss: 0.6044 - accuracy: 0.7933 - val_loss: 2.2246 - val_accuracy: 0.1630\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.8031\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.9637815952301025, acc: 0.3149999976158142\n",
      "\n",
      "1667/1667 [==============================] - 131s 79ms/step - loss: 0.5772 - accuracy: 0.8031 - val_loss: 1.9638 - val_accuracy: 0.3150\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8065\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.1075074672698975, acc: 0.6256999969482422\n",
      "\n",
      "1667/1667 [==============================] - 132s 79ms/step - loss: 0.5645 - accuracy: 0.8065 - val_loss: 1.1075 - val_accuracy: 0.6258\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.8067\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7384869456291199, acc: 0.7559999823570251\n",
      "\n",
      "1667/1667 [==============================] - 130s 78ms/step - loss: 0.5633 - accuracy: 0.8067 - val_loss: 0.7385 - val_accuracy: 0.7562\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8237\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.702595591545105, acc: 0.7705000042915344\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.5184 - accuracy: 0.8237 - val_loss: 0.7026 - val_accuracy: 0.7705\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.8468\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7008635997772217, acc: 0.7702999711036682\n",
      "\n",
      "1667/1667 [==============================] - 126s 76ms/step - loss: 0.4498 - accuracy: 0.8468 - val_loss: 0.7008 - val_accuracy: 0.7704\n"
     ]
    }
   ],
   "source": [
    "history_exp21 = exp21_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW-llVuqfwUi",
    "outputId": "7913fd46-3d5e-43c3-a21b-37e64438053b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.7009 - accuracy: 0.7703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7008635997772217, 0.7702999711036682]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp21_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "W7D2q3W09ncl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.7009 - accuracy: 0.7703\n",
      "Evaluation time: 6.7887 seconds\n",
      "Loss: 0.7008635997772217, Accuracy: 0.7702999711036682\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score21 = exp21_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score21[0]}, Accuracy: {score21[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "cQNbKdwVPyWo",
    "outputId": "42b5f2b2-e3fe-4e09-81b9-84460b7ed130"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp21.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp21.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp21.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp21.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZajLvMZefqO"
   },
   "source": [
    "## 2-2. (32, 16) *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "EiCGNbU7eQCm"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "z_Ywjw2xfCHR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=16, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp22_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "7FBFKA9pfDgm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp22_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05V-KQUSfEoE",
    "outputId": "0f0d640a-62de-4526-9de4-135d5f92492f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21154     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73858     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129282    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221442    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         406018    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401858   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2179074   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2171906   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21361480 (81.49 MB)\n",
      "Trainable params: 2442720 (9.32 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp22_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtt2vlBufF-G",
    "outputId": "b9c855fa-fd52-457d-f3a1-29af66784f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19360\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36928\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55424\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73856\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110848\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221696\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 77824\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 74240\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp22_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "p7JVgT5zfG8x"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp22_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ywJfZm9PfIlc"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "yc4NMzPJfJf6"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "3uc9kMrGfKXi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp22_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo9O94YY--zH"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSIOk0uqfMog",
    "outputId": "fdd6ea71-4379-4695-9e6d-899e9f674a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9750\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3026556968688965, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 134s 73ms/step - loss: 0.0807 - accuracy: 0.9750 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9806\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3026490211486816, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 121s 73ms/step - loss: 0.0591 - accuracy: 0.9806 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9493\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302964925765991, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.1599 - accuracy: 0.9493 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8924\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3028039932250977, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 129s 77ms/step - loss: 0.3322 - accuracy: 0.8924 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.8563\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3033084869384766, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.4435 - accuracy: 0.8563 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8197\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.303706645965576, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 125s 75ms/step - loss: 0.5528 - accuracy: 0.8197 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.7840\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3041138648986816, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.6642 - accuracy: 0.7840 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7597 - accuracy: 0.7544\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3042430877685547, acc: 0.08959999680519104\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.7597 - accuracy: 0.7544 - val_loss: 2.3042 - val_accuracy: 0.0896\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8602 - accuracy: 0.7198\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.304138660430908, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.8602 - accuracy: 0.7198 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9508 - accuracy: 0.6904\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3096837997436523, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 125s 75ms/step - loss: 0.9508 - accuracy: 0.6904 - val_loss: 2.3097 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0406 - accuracy: 0.6591\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.3742849826812744, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 126s 75ms/step - loss: 1.0406 - accuracy: 0.6591 - val_loss: 2.3743 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.6358\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.6253907680511475, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 124s 75ms/step - loss: 1.1012 - accuracy: 0.6358 - val_loss: 2.6254 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1850 - accuracy: 0.6077\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 5.87924861907959, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 125s 75ms/step - loss: 1.1850 - accuracy: 0.6077 - val_loss: 5.8794 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.7097\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.360208749771118, acc: 0.10199999809265137\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.9992 - accuracy: 0.7097 - val_loss: 2.3602 - val_accuracy: 0.1020\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.7844\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.66916561126709, acc: 0.1062999963760376\n",
      "\n",
      "1667/1667 [==============================] - 126s 75ms/step - loss: 0.6382 - accuracy: 0.7844 - val_loss: 2.6692 - val_accuracy: 0.1063\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.7945\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.501479148864746, acc: 0.17599999904632568\n",
      "\n",
      "1667/1667 [==============================] - 126s 76ms/step - loss: 0.6058 - accuracy: 0.7945 - val_loss: 2.5015 - val_accuracy: 0.1760\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.7954\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.7117054462432861, acc: 0.38119998574256897\n",
      "\n",
      "1667/1667 [==============================] - 126s 76ms/step - loss: 0.6009 - accuracy: 0.7954 - val_loss: 1.7118 - val_accuracy: 0.3813\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.7936\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.747406005859375, acc: 0.7473000288009644\n",
      "\n",
      "1667/1667 [==============================] - 124s 74ms/step - loss: 0.6059 - accuracy: 0.7936 - val_loss: 0.7474 - val_accuracy: 0.7473\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5584 - accuracy: 0.8096\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7210416197776794, acc: 0.7602999806404114\n",
      "\n",
      "1667/1667 [==============================] - 122s 73ms/step - loss: 0.5584 - accuracy: 0.8096 - val_loss: 0.7210 - val_accuracy: 0.7602\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.8321\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7424664497375488, acc: 0.7615000009536743\n",
      "\n",
      "1667/1667 [==============================] - 115s 69ms/step - loss: 0.4926 - accuracy: 0.8321 - val_loss: 0.7425 - val_accuracy: 0.7614\n"
     ]
    }
   ],
   "source": [
    "history_exp22 = exp22_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Iw8Uuyj31n2E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.7425 - accuracy: 0.7615\n",
      "Evaluation time: 6.7871 seconds\n",
      "Loss: 0.7424664497375488, Accuracy: 0.7615000009536743\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score22 = exp22_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score22[0]}, Accuracy: {score22[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "NYKZmdk1fPCA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp22.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp22.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp22.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp22.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5MbMZ4hehMi"
   },
   "source": [
    "## 2-3. (32, 64) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8WLRVDyWej1q"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "1fICgSqQqwIW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=64, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp23_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "rDp5dkpgqx7G"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp23_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrXZDLTRq4LV",
    "outputId": "a9f141ff-4c3d-4785-bede-79bb43e670ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21154     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73858     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129282    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221442    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         406018    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737794    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401858   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2655234   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2400258   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2393090   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21803848 (83.18 MB)\n",
      "Trainable params: 2885088 (11.01 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp23_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BISzZtRq14v",
    "outputId": "fdf8d3d7-ab5c-4e89-90d0-32bbdcc588de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19360\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36928\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55424\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73856\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110848\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147712\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221696\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 299008\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp23_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "_jH8Ng1iq8s9"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp23_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "6M9Ijmuhq_ql"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "CdXjUGAUrCRa"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ZMc-zQIQrEyM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp23_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dkn_4j2Y_B46"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Xzwh-2nrHaz",
    "outputId": "e345f70c-cfe5-4678-a953-ea24f9ed4af9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9747\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302617311477661, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 135s 74ms/step - loss: 0.0805 - accuracy: 0.9747 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9823\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302633285522461, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 123s 74ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9505\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302682876586914, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 129s 77ms/step - loss: 0.1549 - accuracy: 0.9505 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.8976\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3027563095092773, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 129s 77ms/step - loss: 0.3141 - accuracy: 0.8976 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8613\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3030266761779785, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 129s 77ms/step - loss: 0.4262 - accuracy: 0.8613 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.8235\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.303211212158203, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.5362 - accuracy: 0.8235 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.7941\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.30361008644104, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.6254 - accuracy: 0.7941 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7197 - accuracy: 0.7609\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3035473823547363, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.7197 - accuracy: 0.7609 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8147 - accuracy: 0.7288\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.3047165870666504, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 126s 76ms/step - loss: 0.8147 - accuracy: 0.7288 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.7019\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3383069038391113, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 126s 75ms/step - loss: 0.8985 - accuracy: 0.7019 - val_loss: 2.3383 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9656 - accuracy: 0.6778\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.9385299682617188, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 125s 75ms/step - loss: 0.9656 - accuracy: 0.6778 - val_loss: 2.9385 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0460 - accuracy: 0.6488\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 3.760249137878418, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 1.0460 - accuracy: 0.6488 - val_loss: 3.7604 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0933 - accuracy: 0.6319\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 7.142857074737549, acc: 0.08969999849796295\n",
      "\n",
      "1667/1667 [==============================] - 126s 75ms/step - loss: 1.0933 - accuracy: 0.6319 - val_loss: 7.1438 - val_accuracy: 0.0897\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8646 - accuracy: 0.7322\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 3.7416648864746094, acc: 0.10029999911785126\n",
      "\n",
      "1667/1667 [==============================] - 126s 76ms/step - loss: 0.8646 - accuracy: 0.7322 - val_loss: 3.7419 - val_accuracy: 0.1003\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6063 - accuracy: 0.7908\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.8106234073638916, acc: 0.10050000250339508\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.6063 - accuracy: 0.7908 - val_loss: 2.8107 - val_accuracy: 0.1005\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5773 - accuracy: 0.8018\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.2910218238830566, acc: 0.1444000005722046\n",
      "\n",
      "1667/1667 [==============================] - 128s 77ms/step - loss: 0.5773 - accuracy: 0.8018 - val_loss: 2.2910 - val_accuracy: 0.1444\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.8066\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.3926194906234741, acc: 0.515999972820282\n",
      "\n",
      "1667/1667 [==============================] - 127s 76ms/step - loss: 0.5602 - accuracy: 0.8066 - val_loss: 1.3926 - val_accuracy: 0.5161\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.8079\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7650635838508606, acc: 0.7411999702453613\n",
      "\n",
      "1667/1667 [==============================] - 126s 76ms/step - loss: 0.5579 - accuracy: 0.8079 - val_loss: 0.7650 - val_accuracy: 0.7411\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.8223\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7126179933547974, acc: 0.7699999809265137\n",
      "\n",
      "1667/1667 [==============================] - 122s 73ms/step - loss: 0.5177 - accuracy: 0.8223 - val_loss: 0.7126 - val_accuracy: 0.7701\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.8466\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.6807668209075928, acc: 0.7793999910354614\n",
      "\n",
      "1667/1667 [==============================] - 122s 73ms/step - loss: 0.4489 - accuracy: 0.8466 - val_loss: 0.6807 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "history_exp23 = exp23_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gne3KfeF-APf",
    "outputId": "f7df3b61-5da8-42c0-b741-00b482e0595b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6808 - accuracy: 0.7794\n",
      "Evaluation time: 6.7968 seconds\n",
      "Loss: 0.6807668209075928, Accuracy: 0.7793999910354614\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score23 = exp23_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score23[0]}, Accuracy: {score23[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "dEnYK6elrKvV",
    "outputId": "e329ff26-bd23-4859-dcfb-1f4acd634983"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp23.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp23.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp23.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp23.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsWkREKO1Lps",
    "outputId": "f2701e9b-57bc-4d56-e086-7a498790d169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6808 - accuracy: 0.7794\n",
      "Evaluation time: 6.7467 seconds\n",
      "Loss: 0.6807668209075928, Accuracy: 0.7793999910354614\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score23 = exp23_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score23[0]}, Accuracy: {score23[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu-plqg5N6eQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lR_5oviqMrk"
   },
   "source": [
    "## 2-4. (16, 16) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "xshgj9pkqMrt"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "xFEe2jFMqMrt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=16, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp24_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ff6yIKoKqMrt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp24_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnmdfI4IqMrt",
    "outputId": "23d02fd4-4e40-45f0-b281-0e9eebcce05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11506     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55426     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101634    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184578    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350722    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1291266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2179074   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2171906   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20218264 (77.13 MB)\n",
      "Trainable params: 1299504 (4.96 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp24_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F00Ij82-qMrt",
    "outputId": "30affc13-5eb2-4c04-e7d2-7922b86656c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9712\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18496\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27776\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36992\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55552\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 111104\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 77824\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 74240\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp24_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "iXZC49h7qMru"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp24_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "HNE35A0EqMru"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "zeLLoQGzqMru"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "e6Dj91ILqMru"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp24_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3AQTPMJ_GOG"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gp_zFeAtqMru",
    "outputId": "ce31c6e2-6916-462a-f2f5-1a2bbcf534b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9639\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3026187419891357, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 135s 74ms/step - loss: 0.1145 - accuracy: 0.9639 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9691\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3028955459594727, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 124s 74ms/step - loss: 0.0981 - accuracy: 0.9691 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.9331\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.30289363861084, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 130s 78ms/step - loss: 0.2085 - accuracy: 0.9331 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8772\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.30338191986084, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 131s 79ms/step - loss: 0.3822 - accuracy: 0.8772 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8328\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3034560680389404, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 132s 79ms/step - loss: 0.5197 - accuracy: 0.8328 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.7946\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3036649227142334, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 132s 79ms/step - loss: 0.6396 - accuracy: 0.7946 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.7658 - accuracy: 0.7536\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3046536445617676, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.7658 - accuracy: 0.7537 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.7147\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.306194305419922, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.8852 - accuracy: 0.7147 - val_loss: 2.3062 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0199 - accuracy: 0.6729\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.305901288986206, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 1.0199 - accuracy: 0.6729 - val_loss: 2.3059 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1323 - accuracy: 0.6342\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3151817321777344, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.1323 - accuracy: 0.6342 - val_loss: 2.3152 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2467 - accuracy: 0.5911\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.377546787261963, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.2467 - accuracy: 0.5911 - val_loss: 2.3776 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3566 - accuracy: 0.5507\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.351027727127075, acc: 0.10270000249147415\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.3566 - accuracy: 0.5507 - val_loss: 2.3510 - val_accuracy: 0.1027\n",
      "Epoch 13/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 1.4516 - accuracy: 0.5122\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 2.555499792098999, acc: 0.09989999979734421\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 1.4518 - accuracy: 0.5122 - val_loss: 2.5555 - val_accuracy: 0.0999\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0322 - accuracy: 0.6768\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.386237859725952, acc: 0.10040000081062317\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.0322 - accuracy: 0.6768 - val_loss: 2.3862 - val_accuracy: 0.1004\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.7662\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.4530746936798096, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 66s 39ms/step - loss: 0.6805 - accuracy: 0.7662 - val_loss: 2.4531 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.7763\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.1301488876342773, acc: 0.16410000622272491\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6577 - accuracy: 0.7763 - val_loss: 2.1301 - val_accuracy: 0.1640\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.7767\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.8840693235397339, acc: 0.35109999775886536\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.6571 - accuracy: 0.7767 - val_loss: 1.8842 - val_accuracy: 0.3511\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.7781\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.798149585723877, acc: 0.7354000210762024\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 0.6599 - accuracy: 0.7781 - val_loss: 0.7981 - val_accuracy: 0.7354\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7883\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7723711133003235, acc: 0.7477999925613403\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.6290 - accuracy: 0.7883 - val_loss: 0.7724 - val_accuracy: 0.7477\n",
      "Epoch 20/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.8103\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.762116551399231, acc: 0.753600001335144\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5676 - accuracy: 0.8104 - val_loss: 0.7621 - val_accuracy: 0.7537\n"
     ]
    }
   ],
   "source": [
    "history_exp24 = exp24_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "7WwTFgAD-S0-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7621 - accuracy: 0.7536\n",
      "Evaluation time: 3.7544 seconds\n",
      "Loss: 0.762116551399231, Accuracy: 0.753600001335144\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score24 = exp24_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score24[0]}, Accuracy: {score24[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "IrLS0MAbqMru",
    "outputId": "2dd0e859-da70-4931-f10a-20f2de699df4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp24.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp24.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp24.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp24.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05hTVBWz_a7Q"
   },
   "source": [
    "## 2-5. (16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "yAMaW8tq_a7a"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "yQEGKcv1_a7a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=32, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp25_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "_Nx7V_RG_a7a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp25_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QISgWsIB_a7b",
    "outputId": "63671162-e007-44da-f92a-49b173cff6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11506     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55426     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101634    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184578    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350722    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1291266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2252802   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2245634   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20365720 (77.69 MB)\n",
      "Trainable params: 1446960 (5.52 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp25_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E9kf2WU_a7b",
    "outputId": "1a1abe8e-8ae7-4f7b-a46a-add76eb92b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9712\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18496\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27776\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36992\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55552\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 111104\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 151552\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp25_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "kuMPWKdD_a7b"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp25_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "2er5vDY4_a7b"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Pw6efjC2_a7c"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "ENCdYvNn_a7c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp25_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_LWfZn7_a7c"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ubx3l9if_a7c",
    "outputId": "4c8bc6cb-79de-4456-d641-301e2d97ded9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9629\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3026280403137207, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 76s 39ms/step - loss: 0.1170 - accuracy: 0.9629 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.0903 - accuracy: 0.9712\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3027241230010986, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.0902 - accuracy: 0.9712 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9352\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302744150161743, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.2030 - accuracy: 0.9352 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8800\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3028054237365723, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.3715 - accuracy: 0.8799 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8355\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3030924797058105, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.5043 - accuracy: 0.8355 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.7982\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.303619146347046, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6217 - accuracy: 0.7982 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7425 - accuracy: 0.7569\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3039934635162354, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 66s 40ms/step - loss: 0.7425 - accuracy: 0.7569 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8539 - accuracy: 0.7245\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.304415464401245, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.8539 - accuracy: 0.7245 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9684 - accuracy: 0.6819\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.3077280521392822, acc: 0.08869999647140503\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.9684 - accuracy: 0.6819 - val_loss: 2.3077 - val_accuracy: 0.0887\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.6419\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.307803153991699, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 1.0907 - accuracy: 0.6419 - val_loss: 2.3078 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1889 - accuracy: 0.6059\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.348860263824463, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.1889 - accuracy: 0.6059 - val_loss: 2.3489 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 1.2897 - accuracy: 0.5695\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.4085612297058105, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 1.2896 - accuracy: 0.5695 - val_loss: 2.4086 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3759 - accuracy: 0.5373\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 2.6420276165008545, acc: 0.10689999908208847\n",
      "\n",
      "1667/1667 [==============================] - 67s 40ms/step - loss: 1.3759 - accuracy: 0.5373 - val_loss: 2.6421 - val_accuracy: 0.1069\n",
      "Epoch 14/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.6794\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.3097853660583496, acc: 0.13379999995231628\n",
      "\n",
      "1667/1667 [==============================] - 67s 40ms/step - loss: 1.0129 - accuracy: 0.6794 - val_loss: 2.3098 - val_accuracy: 0.1338\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.7693\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.5399861335754395, acc: 0.16009999811649323\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.6741 - accuracy: 0.7693 - val_loss: 2.5400 - val_accuracy: 0.1600\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.7813\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.1911416053771973, acc: 0.25459998846054077\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.6398 - accuracy: 0.7813 - val_loss: 2.1911 - val_accuracy: 0.2547\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.7855\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.5124390125274658, acc: 0.4726000130176544\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.6289 - accuracy: 0.7855 - val_loss: 1.5125 - val_accuracy: 0.4727\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.7863\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7903489470481873, acc: 0.7407000064849854\n",
      "\n",
      "1667/1667 [==============================] - 69s 42ms/step - loss: 0.6252 - accuracy: 0.7863 - val_loss: 0.7903 - val_accuracy: 0.7408\n",
      "Epoch 19/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.5925 - accuracy: 0.7979\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7524921894073486, acc: 0.7569000124931335\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.5927 - accuracy: 0.7978 - val_loss: 0.7525 - val_accuracy: 0.7570\n",
      "Epoch 20/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.8210\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7643328905105591, acc: 0.7544000148773193\n",
      "\n",
      "1667/1667 [==============================] - 66s 39ms/step - loss: 0.5330 - accuracy: 0.8210 - val_loss: 0.7644 - val_accuracy: 0.7542\n"
     ]
    }
   ],
   "source": [
    "history_exp25 = exp25_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "L9TPQBht-i_C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7643 - accuracy: 0.7544\n",
      "Evaluation time: 3.9667 seconds\n",
      "Loss: 0.7643328905105591, Accuracy: 0.7544000148773193\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score25 = exp25_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score25[0]}, Accuracy: {score25[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "GFAWHfeB_a7c",
    "outputId": "42b5f2b2-e3fe-4e09-81b9-84460b7ed130"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp25.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp25.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp25.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp25.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mqm8sMZACK3"
   },
   "source": [
    "## 2-6. (16, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "wj2k2FjkACK_"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "VvfLtCIcACK_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=64, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp26_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "yZSvkVUZACK_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp26_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "587UuheQACK_",
    "outputId": "63671162-e007-44da-f92a-49b173cff6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11506     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55426     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101634    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184578    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350722    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         664066    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1291266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507778   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2400258   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2393090   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20660632 (78.81 MB)\n",
      "Trainable params: 1741872 (6.64 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp26_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugu_3sPBACK_",
    "outputId": "1a1abe8e-8ae7-4f7b-a46a-add76eb92b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9712\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18496\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27776\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36992\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55552\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73984\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 111104\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147968\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 299008\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 295424\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp26_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "QIRBl6_HACLA"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp26_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "rQLsY-jCACLA"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "i5VDOlyHACLA"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "mYnT-xGlACLA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp26_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU49T8ueACLA"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vw3LrTXoACLA",
    "outputId": "4c8bc6cb-79de-4456-d641-301e2d97ded9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9637\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3026351928710938, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 73s 37ms/step - loss: 0.1154 - accuracy: 0.9637 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9713\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3026785850524902, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9353\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.3026678562164307, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.2034 - accuracy: 0.9353 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8769\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3028903007507324, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.3811 - accuracy: 0.8769 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.8368\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.303105354309082, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5007 - accuracy: 0.8368 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.8002\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3034985065460205, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 0.6155 - accuracy: 0.8002 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7382 - accuracy: 0.7594\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.304333209991455, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.7382 - accuracy: 0.7594 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8472 - accuracy: 0.7217\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.305210590362549, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.8472 - accuracy: 0.7217 - val_loss: 2.3052 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9559 - accuracy: 0.6853\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.304516077041626, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.9559 - accuracy: 0.6853 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 1.0644 - accuracy: 0.6478\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3441436290740967, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.0643 - accuracy: 0.6479 - val_loss: 2.3441 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1623 - accuracy: 0.6144\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.597362756729126, acc: 0.10010000318288803\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.1623 - accuracy: 0.6144 - val_loss: 2.5974 - val_accuracy: 0.1001\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2461 - accuracy: 0.5823\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.660597324371338, acc: 0.10010000318288803\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 1.2461 - accuracy: 0.5823 - val_loss: 2.6608 - val_accuracy: 0.1001\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3288 - accuracy: 0.5547\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 3.9267919063568115, acc: 0.10029999911785126\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.3288 - accuracy: 0.5547 - val_loss: 3.9268 - val_accuracy: 0.1003\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9664 - accuracy: 0.6886\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.2959067821502686, acc: 0.1103999987244606\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.9664 - accuracy: 0.6886 - val_loss: 2.2959 - val_accuracy: 0.1105\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.7713\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.3281807899475098, acc: 0.19040000438690186\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6656 - accuracy: 0.7713 - val_loss: 2.3282 - val_accuracy: 0.1903\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.7810\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.427535057067871, acc: 0.2296999990940094\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.6340 - accuracy: 0.7810 - val_loss: 2.4276 - val_accuracy: 0.2297\n",
      "Epoch 17/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.6184 - accuracy: 0.7870\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.4713348150253296, acc: 0.47029998898506165\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.6183 - accuracy: 0.7870 - val_loss: 1.4713 - val_accuracy: 0.4704\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.7880\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7468522191047668, acc: 0.754800021648407\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.6146 - accuracy: 0.7880 - val_loss: 0.7469 - val_accuracy: 0.7549\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.8008\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.766362190246582, acc: 0.7545999884605408\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5788 - accuracy: 0.8008 - val_loss: 0.7664 - val_accuracy: 0.7546\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.8236\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7367414832115173, acc: 0.7620999813079834\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 0.5162 - accuracy: 0.8236 - val_loss: 0.7367 - val_accuracy: 0.7622\n"
     ]
    }
   ],
   "source": [
    "history_exp26 = exp26_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "9fzTuA4x-pd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7367 - accuracy: 0.7621\n",
      "Evaluation time: 3.7837 seconds\n",
      "Loss: 0.7367414832115173, Accuracy: 0.7620999813079834\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작 전 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가 수행\n",
    "score26 = exp26_lora_vgg16.evaluate(x_test, y_test)\n",
    "\n",
    "# 평가 종료 후 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가에 걸린 시간 계산\n",
    "evaluation_time = end_time - start_time\n",
    "\n",
    "print(f\"Evaluation time: {evaluation_time:.4f} seconds\")\n",
    "print(f\"Loss: {score26[0]}, Accuracy: {score26[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "7lmu1SLyACLB",
    "outputId": "42b5f2b2-e3fe-4e09-81b9-84460b7ed130"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHWCAYAAAALjsguAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAADFmElEQVR4nOzdd3yN5//H8dfJ3hEkIcTem9hqFVVUUdVSs0oXtTrUT6vo0G9bNVtaNdqqUmq1tFZL7R21Z4gRgpCIkXl+fxw5pAkSktwnyfv5eJzHOec+9/icI+5zf851XZ/LZDabzYiIiIiIiIiI4eyMDkBERERERERELJSki4iIiIiIiNgIJekiIiIiIiIiNkJJuoiIiIiIiIiNUJIuIiIiIiIiYiOUpIuIiIiIiIjYCCXpIiIiIiIiIjZCSbqIiIiIiIiIjVCSLiIiIiIiImIjlKSLTenVqxfFihV7qG1HjhyJyWTK2IBszMmTJzGZTMyaNSvLj20ymRg5cqT1+axZszCZTJw8efKB2xYrVoxevXplaDyP8rciIiI5g64b7k/XDXfoukGyEyXpkiYmkylNt7Vr1xodaq43YMAATCYTx44du+c6w4cPx2Qy8e+//2ZhZOl37tw5Ro4cSXBwsNGhpOrgwYOYTCZcXFy4evWq0eGIiNgMXTdkH7puyFxJP5R88cUXRoci2YiD0QFI9vDjjz8me/7DDz+watWqFMvLly//SMeZNm0aiYmJD7Xte++9x7vvvvtIx88JunbtyqRJk5gzZw4jRoxIdZ2ff/6ZypUrU6VKlYc+Tvfu3encuTPOzs4PvY8HOXfuHKNGjaJYsWJUq1Yt2WuP8reSUWbPnk2BAgW4cuUKCxYsoE+fPobGIyJiK3TdkH3oukHE9ihJlzTp1q1bsudbtmxh1apVKZb/140bN3Bzc0vzcRwdHR8qPgAHBwccHPQnXadOHUqVKsXPP/+c6pft5s2bCQkJ4dNPP32k49jb22Nvb/9I+3gUj/K3khHMZjNz5szhhRdeICQkhJ9++slmk/Tr16/j7u5udBgikovouiH70HWDiO1Rd3fJME2aNKFSpUrs3LmTRo0a4ebmxv/93/8BsGTJEtq0aUNAQADOzs6ULFmSDz/8kISEhGT7+O94obu7CH377beULFkSZ2dnatWqxfbt25Ntm9rYMpPJRP/+/Vm8eDGVKlXC2dmZihUr8ueff6aIf+3atdSsWRMXFxdKlizJN998k+bxauvXr6dTp04UKVIEZ2dnAgMDGTx4MDdv3kzx/jw8PDh79izt27fHw8MDX19f3nrrrRSfxdWrV+nVqxfe3t7kyZOHnj17prlLddeuXTl06BC7du1K8dqcOXMwmUx06dKF2NhYRowYQVBQEN7e3ri7u9OwYUP+/vvvBx4jtbFlZrOZjz76iMKFC+Pm5kbTpk3Zv39/im0jIiJ46623qFy5Mh4eHnh5edGqVSv27NljXWft2rXUqlULgBdffNHaNTJpXF1qY8uuX7/Om2++SWBgIM7OzpQtW5YvvvgCs9mcbL30/F3cy8aNGzl58iSdO3emc+fO/PPPP5w5cybFeomJiUyYMIHKlSvj4uKCr68vTz75JDt27Ei23uzZs6lduzZubm74+PjQqFEjVq5cmSzmu8f2JfnvuL2kf5d169bx+uuv4+fnR+HChQE4deoUr7/+OmXLlsXV1ZV8+fLRqVOnVMcHXr16lcGDB1OsWDGcnZ0pXLgwPXr04NKlS0RHR+Pu7s7AgQNTbHfmzBns7e0ZM2ZMGj9JEcmtdN2g64bcdN3wIOHh4bz00kv4+/vj4uJC1apV+f7771OsN3fuXIKCgvD09MTLy4vKlSszYcIE6+txcXGMGjWK0qVL4+LiQr58+XjsscdYtWpVhsUqmU8/H0qGunz5Mq1ataJz585069YNf39/wHJi9vDwYMiQIXh4ePDXX38xYsQIoqKi+Pzzzx+43zlz5nDt2jVeeeUVTCYTn332Gc888wwnTpx44C+jGzZsYOHChbz++ut4enoyceJEOnbsSGhoKPny5QNg9+7dPPnkkxQsWJBRo0aRkJDA6NGj8fX1TdP7nj9/Pjdu3OC1114jX758bNu2jUmTJnHmzBnmz5+fbN2EhARatmxJnTp1+OKLL1i9ejVjx46lZMmSvPbaa4DlS6tdu3Zs2LCBV199lfLly7No0SJ69uyZpni6du3KqFGjmDNnDjVq1Eh27F9++YWGDRtSpEgRLl26xHfffUeXLl3o27cv165dY/r06bRs2ZJt27al6Cr2ICNGjOCjjz6idevWtG7dml27dvHEE08QGxubbL0TJ06wePFiOnXqRPHixblw4QLffPMNjRs35sCBAwQEBFC+fHlGjx7NiBEjePnll2nYsCEA9evXT/XYZrOZp59+mr///puXXnqJatWqsWLFCt5++23Onj3LuHHjkq2flr+L+/npp58oWbIktWrVolKlSri5ufHzzz/z9ttvJ1vvpZdeYtasWbRq1Yo+ffoQHx/P+vXr2bJlCzVr1gRg1KhRjBw5kvr16zN69GicnJzYunUrf/31F0888USaP/+7vf766/j6+jJixAiuX78OwPbt29m0aROdO3emcOHCnDx5kilTptCkSRMOHDhgbb2Kjo6mYcOGHDx4kN69e1OjRg0uXbrE0qVLOXPmDNWqVaNDhw7MmzePL7/8MlnLyM8//4zZbKZr164PFbeI5C66btB1Q265brifmzdv0qRJE44dO0b//v0pXrw48+fPp1evXly9etX6o/iqVavo0qULzZo143//+x9gqY+zceNG6zojR45kzJgx9OnTh9q1axMVFcWOHTvYtWsXLVq0eKQ4JQuZRR5Cv379zP/982ncuLEZME+dOjXF+jdu3Eix7JVXXjG7ubmZb926ZV3Ws2dPc9GiRa3PQ0JCzIA5X7585oiICOvyJUuWmAHzb7/9Zl32wQcfpIgJMDs5OZmPHTtmXbZnzx4zYJ40aZJ1Wdu2bc1ubm7ms2fPWpcdPXrU7ODgkGKfqUnt/Y0ZM8ZsMpnMp06dSvb+APPo0aOTrVu9enVzUFCQ9fnixYvNgPmzzz6zLouPjzc3bNjQDJhnzpz5wJhq1aplLly4sDkhIcG67M8//zQD5m+++ca6z5iYmGTbXblyxezv72/u3bt3suWA+YMPPrA+nzlzphkwh4SEmM1mszk8PNzs5ORkbtOmjTkxMdG63v/93/+ZAXPPnj2ty27dupUsLrPZ8m/t7Oyc7LPZvn37Pd/vf/9Wkj6zjz76KNl6zz77rNlkMiX7G0jr38W9xMbGmvPly2cePny4ddkLL7xgrlq1arL1/vrrLzNgHjBgQIp9JH1GR48eNdvZ2Zk7dOiQ4jO5+3P87+efpGjRosk+26R/l8cee8wcHx+fbN3U/k43b95sBsw//PCDddmIESPMgHnhwoX3jHvFihVmwPzHH38ke71KlSrmxo0bp9hORHI3XTc8+P3pusEip103JP1Nfv755/dcZ/z48WbAPHv2bOuy2NhYc7169cweHh7mqKgos9lsNg8cONDs5eWV4vv9blWrVjW3adPmvjGJ7VN3d8lQzs7OvPjiiymWu7q6Wh9fu3aNS5cu0bBhQ27cuMGhQ4ceuN/nn38eHx8f6/OkX0dPnDjxwG2bN29OyZIlrc+rVKmCl5eXdduEhARWr15N+/btCQgIsK5XqlQpWrVq9cD9Q/L3d/36dS5dukT9+vUxm83s3r07xfqvvvpqsucNGzZM9l6WL1+Og4OD9RdysIzleuONN9IUD1jGA545c4Z//vnHumzOnDk4OTnRqVMn6z6dnJwAS7fsiIgI4uPjqVmzZqpd3u5n9erVxMbG8sYbbyTr6jdo0KAU6zo7O2NnZzn9JCQkcPnyZTw8PChbtmy6j5tk+fLl2NvbM2DAgGTL33zzTcxmM3/88Uey5Q/6u7ifP/74g8uXL9OlSxfrsi5durBnz55k3fR+/fVXTCYTH3zwQYp9JH1GixcvJjExkREjRlg/k/+u8zD69u2bYuzf3X+ncXFxXL58mVKlSpEnT55kn/uvv/5K1apV6dChwz3jbt68OQEBAfz000/W1/bt28e///77wDGnIiJJdN2g64bccN2QllgKFCiQ7LrC0dGRAQMGEB0dzbp16wDIkycP169fv2/X9Tx58rB//36OHj36yHGJcZSkS4YqVKiQ9eR9t/3799OhQwe8vb3x8vLC19fXeiEfGRn5wP0WKVIk2fOkL94rV66ke9uk7ZO2DQ8P5+bNm5QqVSrFeqktS01oaCi9evUib9681vFijRs3BlK+v6RxyfeKByxjhwsWLIiHh0ey9cqWLZumeAA6d+6Mvb09c+bMAeDWrVssWrSIVq1aJbtw+f7776lSpYp13JKvry/Lli1L07/L3U6dOgVA6dKlky339fVNdjywfLGPGzeO0qVL4+zsTP78+fH19eXff/9N93HvPn5AQACenp7JlidVDk6KL8mD/i7uZ/bs2RQvXhxnZ2eOHTvGsWPHKFmyJG5ubsmS1uPHjxMQEEDevHnvua/jx49jZ2dHhQoVHnjc9ChevHiKZTdv3mTEiBHWsXdJn/vVq1eTfe7Hjx+nUqVK992/nZ0dXbt2ZfHixdy4cQOwDAFwcXGxXsyJiDyIrht03ZAbrhvSEkvp0qVT/Fj/31hef/11ypQpQ6tWrShcuDC9e/dOMS5+9OjRXL16lTJlylC5cmXefvttm586T1JSki4Z6u5fhpNcvXqVxo0bs2fPHkaPHs1vv/3GqlWrrGNp0jIdxr2qgZr/U9gjo7dNi4SEBFq0aMGyZcsYOnQoixcvZtWqVdZCJf99f1lV2dTPz48WLVrw66+/EhcXx2+//ca1a9eSjRWePXs2vXr1omTJkkyfPp0///yTVatW8fjjj2fqNCWffPIJQ4YMoVGjRsyePZsVK1awatUqKlasmGXTozzs30VUVBS//fYbISEhlC5d2nqrUKECN27cYM6cORn2t5UW/y0clCS1/4tvvPEGH3/8Mc899xy//PILK1euZNWqVeTLl++hPvcePXoQHR3N4sWLrdXun3rqKby9vdO9LxHJnXTdoOuGtMjO1w0Zyc/Pj+DgYJYuXWodT9+qVatktQcaNWrE8ePHmTFjBpUqVeK7776jRo0afPfdd1kWpzw6FY6TTLd27VouX77MwoULadSokXV5SEiIgVHd4efnh4uLC8eOHUvxWmrL/mvv3r0cOXKE77//nh49eliXP0oVzaJFi7JmzRqio6OT/Sp++PDhdO2na9eu/Pnnn/zxxx/MmTMHLy8v2rZta319wYIFlChRgoULFybrapZa9+y0xAxw9OhRSpQoYV1+8eLFFL8yL1iwgKZNmzJ9+vRky69evUr+/Pmtz9PT3bto0aKsXr2aa9euJftVPKlbZFJ8j2rhwoXcunWLKVOmJIsVLP8+7733Hhs3buSxxx6jZMmSrFixgoiIiHu2ppcsWZLExEQOHDhw34I7Pj4+Kar0xsbGEhYWlubYFyxYQM+ePRk7dqx12a1bt1Lst2TJkuzbt++B+6tUqRLVq1fnp59+onDhwoSGhjJp0qQ0xyMikhpdN6SfrhssbPG6Ia2x/PvvvyQmJiZrTU8tFicnJ9q2bUvbtm1JTEzk9ddf55tvvuH999+39uTImzcvL774Ii+++CLR0dE0atSIkSNH2uxUsZKSWtIl0yX98nj3L42xsbF8/fXXRoWUjL29Pc2bN2fx4sWcO3fOuvzYsWMpxiPda3tI/v7MZnOy6TDSq3Xr1sTHxzNlyhTrsoSEhHQnQO3bt8fNzY2vv/6aP/74g2eeeQYXF5f7xr5161Y2b96c7pibN2+Oo6MjkyZNSra/8ePHp1jX3t4+xS/P8+fP5+zZs8mWJc3tnZYpZFq3bk1CQgKTJ09OtnzcuHGYTKY0jxN8kNmzZ1OiRAleffVVnn322WS3t956Cw8PD2uX944dO2I2mxk1alSK/SS9//bt22NnZ8fo0aNTtAbc/RmVLFky2ThBgG+//faeLempSe1znzRpUop9dOzYkT179rBo0aJ7xp2ke/furFy5kvHjx5MvX74M+5xFJPfSdUP66brBwhavG9KidevWnD9/nnnz5lmXxcfHM2nSJDw8PKxDIS5fvpxsOzs7O6pUqQJATExMqut4eHhQqlQp6+uSPaglXTJd/fr18fHxoWfPngwYMACTycSPP/6Ypd2DHmTkyJGsXLmSBg0a8Nprr1lP2pUqVSI4OPi+25YrV46SJUvy1ltvcfbsWby8vPj1118faYxS27ZtadCgAe+++y4nT56kQoUKLFy4MN3jrjw8PGjfvr11fNl/p8V66qmnWLhwIR06dKBNmzaEhIQwdepUKlSoQHR0dLqOlTRv65gxY3jqqado3bo1u3fv5o8//kjR4vzUU08xevRoXnzxRerXr8/evXv56aefkv2SDpbENE+ePEydOhVPT0/c3d2pU6dOquOt27ZtS9OmTRk+fDgnT56katWqrFy5kiVLljBo0KBkxV4e1rlz5/j7779TFJlJ4uzsTMuWLZk/fz4TJ06kadOmdO/enYkTJ3L06FGefPJJEhMTWb9+PU2bNqV///6UKlWK4cOH8+GHH9KwYUOeeeYZnJ2d2b59OwEBAdb5xvv06cOrr75Kx44dadGiBXv27GHFihUpPtv7eeqpp/jxxx/x9vamQoUKbN68mdWrV6eYOubtt99mwYIFdOrUid69exMUFERERARLly5l6tSpVK1a1bruCy+8wDvvvMOiRYt47bXXHji1kYjIg+i6If103WBha9cNd1uzZg23bt1Ksbx9+/a8/PLLfPPNN/Tq1YudO3dSrFgxFixYwMaNGxk/fry1pb9Pnz5ERETw+OOPU7hwYU6dOsWkSZOoVq2adfx6hQoVaNKkCUFBQeTNm5cdO3awYMEC+vfvn6HvRzJZFlSQlxzoXlOpVKxYMdX1N27caK5bt67Z1dXVHBAQYH7nnXesUzj9/fff1vXuNZVKatNW8J+pPe41lUq/fv1SbPvfaavMZrN5zZo15urVq5udnJzMJUuWNH/33XfmN9980+zi4nKPT+GOAwcOmJs3b2728PAw58+f39y3b1/r1Bx3TwPSs2dPs7u7e4rtU4v98uXL5u7du5u9vLzM3t7e5u7du5t3796d5qlUkixbtswMmAsWLJjqFF+ffPKJuWjRomZnZ2dz9erVzb///nuKfwez+cFTqZjNZnNCQoJ51KhR5oIFC5pdXV3NTZo0Me/bty/F533r1i3zm2++aV2vQYMG5s2bN5sbN26cYvquJUuWmCtUqGCd1ibpvacW47Vr18yDBw82BwQEmB0dHc2lS5c2f/7558mmdkl6L2n9u7jb2LFjzYB5zZo191xn1qxZZsC8ZMkSs9lsma7m888/N5crV87s5ORk9vX1Nbdq1cq8c+fOZNvNmDHDXL16dbOzs7PZx8fH3LhxY/OqVausryckJJiHDh1qzp8/v9nNzc3csmVL87Fjx+45Bdv27dtTxHblyhXziy++aM6fP7/Zw8PD3LJlS/OhQ4dSfd+XL1829+/f31yoUCGzk5OTuXDhwuaePXuaL126lGK/rVu3NgPmTZs23fNzEZHcTdcNyem6wSKnXzeYzXf+Ju91+/HHH81ms9l84cIF63e0k5OTuXLlyin+3RYsWGB+4oknzH5+fmYnJydzkSJFzK+88oo5LCzMus5HH31krl27tjlPnjxmV1dXc7ly5cwff/yxOTY29r5xim0xmc029LOkiI1p3769prEQeYAOHTqwd+/eNI3FFBHJyXTdICIZQWPSRW67efNmsudHjx5l+fLlNGnSxJiARLKBsLAwli1bRvfu3Y0ORUQkS+m6QUQyi1rSRW4rWLAgvXr1okSJEpw6dYopU6YQExPD7t27U8zhKZLbhYSEsHHjRr777ju2b9/O8ePHKVCggNFhiYhkGV03iEhmUeE4kduefPJJfv75Z86fP4+zszP16tXjk08+0RetSCrWrVvHiy++SJEiRfj++++VoItIrqPrBhHJLGpJFxEREREREbERGpMuIiIiIiIiYiOUpIuIiIiIiIjYiFw3Jj0xMZFz587h6emJyWQyOhwRERHMZjPXrl0jICAAOzv9fp4R9H0vIiK2JD3f9bkuST937hyBgYFGhyEiIpLC6dOnKVy4sNFh5Aj6vhcREVuUlu/6XJeke3p6ApYPx8vLy+BoREREICoqisDAQOt3lDw6fd+LiIgtSc93vaFJ+j///MPnn3/Ozp07CQsLY9GiRbRv3/6+26xdu5YhQ4awf/9+AgMDee+99+jVq1eaj5nU5c3Ly0tf2iIiYlPULTvj6PteRERsUVq+6w0d+Hb9+nWqVq3KV199lab1Q0JCaNOmDU2bNiU4OJhBgwbRp08fVqxYkcmRioiIiIiIiGQ+Q1vSW7VqRatWrdK8/tSpUylevDhjx44FoHz58mzYsIFx48bRsmXLzApTREREREREJEtkqxKymzdvpnnz5smWtWzZks2bN99zm5iYGKKiopLdRERERERERGxRtiocd/78efz9/ZMt8/f3Jyoqips3b+Lq6ppimzFjxjBq1KisClFEHpLZbCY+Pp6EhASjQxHJcPb29jg4OGjMuQ3ROUcyi/6/i8ijylZJ+sMYNmwYQ4YMsT5PqqonIrYjNjaWsLAwbty4YXQoIpnGzc2NggUL4uTkZHQohvr0008ZNmwYAwcOZPz48fdcb/78+bz//vucPHmS0qVL87///Y/WrVtnSAw650hm0/93EXkU2SpJL1CgABcuXEi27MKFC3h5eaXaig7g7OyMs7NzVoQnIg8hMTGRkJAQ7O3tCQgIwMnJSa0PkqOYzWZiY2O5ePEiISEhlC5dGju7bDXaLMNs376db775hipVqtx3vU2bNtGlSxfGjBnDU089xZw5c2jfvj27du2iUqVKjxSDzjmSmfT/XUQyQrZK0uvVq8fy5cuTLVu1ahX16tUzKCIReVSxsbEkJiYSGBiIm5ub0eGIZApXV1ccHR05deoUsbGxuLi4GB1SlouOjqZr165MmzaNjz766L7rTpgwgSeffJK3334bgA8//JBVq1YxefJkpk6d+khx6JwjmU3/30XkURn60150dDTBwcEEBwcDlinWgoODCQ0NBSxd1Xv06GFd/9VXX+XEiRO88847HDp0iK+//ppffvmFwYMHGxG+iGQgtTRITpfb/8b79etHmzZtUhSATU1WFIrN7f8ekrn09yUij8LQlvQdO3bQtGlT6/OkseM9e/Zk1qxZhIWFWRN2gOLFi7Ns2TIGDx7MhAkTKFy4MN99952mXxMREbFhc+fOZdeuXWzfvj1N69+rUOz58+fvuY0KxYqISE5haJLepEkTzGbzPV+fNWtWqtvs3r07E6MSERGRjHL69GkGDhzIqlWrMrXbrwrFiohITqG+OCIiNqRYsWL3rXj9X2vXrsVkMnH16tVMi0nkUezcuZPw8HBq1KiBg4MDDg4OrFu3jokTJ+Lg4JDqFGj3KhRboECBex7H2dkZLy+vZDd5MJ1zRERsj5J0EZGHYDKZ7nsbOXLkQ+13+/btvPzyy2lev379+oSFheHt7f1Qx3sY5cqVw9nZ+b5dj0WSNGvWjL1791pr0AQHB1OzZk26du1KcHAw9vb2KbapV68ea9asSbYstxeKzW3nHP0YICK5Wbaq7i4iYivCwsKsj+fNm8eIESM4fPiwdZmHh4f1sdlsJiEhAQeHB59yfX190xWHk5PTfVsXM9qGDRu4efMmzz77LN9//z1Dhw7NsmOnJi4uDkdHR0NjkPvz9PRMMW2au7s7+fLlsy7v0aMHhQoVYsyYMQAMHDiQxo0bM3bsWNq0acPcuXPZsWMH3377bZbHbyty6zlHRCQ3Uku6ga7diuPfM1dZEnyWcauO8MbPu3l2yia++vsY8QmJRocnYhiz2cyN2HhDbverk3G3AgUKWG/e3t6YTCbr80OHDuHp6ckff/xBUFAQzs7ObNiwgePHj9OuXTv8/f3x8PCgVq1arF69Otl+/9v11GQy8d1339GhQwfc3NwoXbo0S5cutb7+39amWbNmkSdPHlasWEH58uXx8PDgySefTHaBHx8fz4ABA8iTJw/58uVj6NCh9OzZk/bt2z/wfU+fPp0XXniB7t27M2PGjBSvnzlzhi5dupA3b17c3d2pWbMmW7dutb7+22+/UatWLVxcXMifPz8dOnRI9l4XL16cbH958uSx1ic5efIkJpOJefPm0bhxY1xcXPjpp5+4fPkyXbp0oVChQri5uVG5cmV+/vnnZPtJTEzks88+o1SpUjg7O1OkSBE+/vhjAB5//HH69++fbP2LFy/i5OSUojVXMkdoaGiyv9H69eszZ84cvv32W6pWrcqCBQtYvHjxI8+Rfi8654y3Pre1c869XLlyhR49euDj44ObmxutWrXi6NGj1tdPnTpF27Zt8fHxwd3dnYoVK1qn8b1y5Qpdu3bF19cXV1dXSpcuzcyZMx86FskmzuyAH9rB+b1GRyLyQGpJz2RxCYmERtwg5OJ1Qi5d58SlaE5cvM6JS9e5eC0m1W12nLrCmoMXmNC5OoF5NYer5D434xKoMGKFIcc+MLolbk4Zc2p89913+eKLLyhRogQ+Pj6cPn2a1q1b8/HHH+Ps7MwPP/xA27ZtOXz4MEWKFLnnfkaNGsVnn33G559/zqRJk+jatSunTp0ib968qa5/48YNvvjiC3788Ufs7Ozo1q0bb731Fj/99BMA//vf//jpp5+YOXMm5cuXZ8KECSxevDjZbBupuXbtGvPnz2fr1q2UK1eOyMhI1q9fT8OGDQHLtJqNGzemUKFCLF26lAIFCrBr1y4SEy0/Oi5btowOHTowfPhwfvjhB2JjY60Xzen9XMeOHUv16tVxcXHh1q1bBAUFMXToULy8vFi2bBndu3enZMmS1K5dG7AUFZs2bRrjxo3jscceIywsjEOHDgHQp08f+vfvz9ixY3F2dgZg9uzZFCpUiMcffzzd8cmDrV279r7PATp16kSnTp2yJB6dc5KzlXPO/fTq1YujR4+ydOlSvLy8GDp0KK1bt+bAgQM4OjrSr18/YmNj+eeff3B3d+fAgQPW3gbvv/8+Bw4c4I8//iB//vwcO3aMmzdvPnQskk1s/w5OrIXds6HV/4yORuS+lKRnALPZzMVrMRxPSsQvRt9OyK8TGnGDhMR7/0qe38OJEvk9KJ7fnRK+7jjY2zF+1RF2hV6l1YT1fNi+Ih2qF87CdyMiGWX06NG0aNHC+jxv3rxUrVrV+vzDDz9k0aJFLF26NEVL7t169epFly5dAPjkk0+YOHEi27Zt48knn0x1/bi4OKZOnUrJkiUB6N+/P6NHj7a+PmnSJIYNG2ZtxZ48eXKakuW5c+dSunRpKlasCEDnzp2ZPn26NUmfM2cOFy9eZPv27daL+VKlSlm3//jjj+ncuXOyabLu/jzSatCgQTzzzDPJlr311lvWx2+88QYrVqzgl19+oXbt2ly7do0JEyYwefJkevbsCUDJkiV57LHHAHjmmWfo378/S5Ys4bnnngMsrYO9evXCZDKlOz4Ro+S0c869JCXnGzdupH79+gD89NNPBAYGsnjxYjp16kRoaCgdO3akcuXKAJQoUcK6fWhoKNWrV6dmzZqApTeB5AIX9lvuI0KMjUMkDZSkP4LpG0JYtPsMIRevcz02ZXXaJK6O9hTP705xX3dK3r4vfjsx93ZNOZbyiQr+DJ4XzI5TVxg8bw9rD1/kw/aV8HLRuEvJHVwd7TkwuqVhx84oSReASaKjoxk5ciTLli0jLCyM+Ph4bt68SWho6H33U6VKFetjd3d3vLy8CA8Pv+f6bm5u1otlgIIFC1rXj4yM5MKFC9YWZgB7e3uCgoKsLd73MmPGDLp162Z93q1bNxo3bsykSZPw9PQkODiY6tWr37O1LTg4mL59+973GGnx3881ISGBTz75hF9++YWzZ88SGxtLTEwMbm6WnkgHDx4kJiaGZs2apbo/FxcXa/f95557jl27drFv375kXXwlZ9M5JzlbOefcy8GDB3FwcKBOnTrWZfny5aNs2bIcPHgQgAEDBvDaa6+xcuVKmjdvTseOHa3v67XXXqNjx47s2rWLJ554gvbt21uTfcmhEuLh4u0aDleUpIvtU5L+CC5Fx7DvbBQAdiYIzOtmScbzu1PC14MSt1vH/T1dsLNLe2tMYF435r5cl6/+Ps7Ev46yJPgcO09dYULnagQVTf3iVyQnMZlMGdb900ju7u7Jnr/11lusWrWKL774glKlSuHq6sqzzz5LbGzsfffz38JoJpPpvhe3qa2f1nGv93LgwAG2bNnCtm3bkhWLS0hIYO7cufTt2xdXV9f77uNBr6cWZ1xcXIr1/vu5fv7550yYMIHx48dTuXJl3N3dGTRokPVzfdBxwdLlvVq1apw5c4aZM2fy+OOPU7Ro0QduJzmDzjnJ2cI551H16dOHli1bsmzZMlauXMmYMWMYO3Ysb7zxBq1ateLUqVMsX76cVatW0axZM/r168cXX3xhaMySiSJOQMLtYaZXTkFiItipNJfYLv11PoJ21QL4pnsQq4c04uCHT7Lu7abMerE2H7StSPe6RWlQKj8FvV3TlaAncbC3Y2Dz0vzySj0C87py5spNOk3dzLhVR1RUTiSb2rhxI7169aJDhw5UrlyZAgUKcPLkySyNwdvbG39/f7Zv325dlpCQwK5du+673fTp02nUqBF79uxJNpXWkCFDmD59OmBpfQsODiYiIiLVfVSpUuW+hdh8fX2TFZs6evQoN27ceOB72rhxI+3ataNbt25UrVqVEiVKcOTIEevrpUuXxtXV9b7Hrly5MjVr1mTatGnMmTOH3r17P/C4IrYuO59z7qd8+fLEx8cnK0p5+fJlDh8+TIUKFazLAgMDefXVV1m4cCFvvvkm06ZNs77m6+tLz549mT17NuPHj8/VMwfkCuH77zxOiIFr54yLRSQNsv/PxgYqV8CLcgW8MvUYQUV9WD6gIR8s2c/C3WeZsOYoG45dYvzz1VRUTiSbKV26NAsXLqRt27aYTCbef//9h+7u+SjeeOMNxowZQ6lSpShXrhyTJk3iypUr9xx/HRcXx48//sjo0aNTVNfu06cPX375Jfv376dLly588skntG/fnjFjxlCwYEF2795NQEAA9erV44MPPqBZs2aULFmSzp07Ex8fz/Lly60t848//jiTJ0+mXr16JCQkMHTo0DRNr1a6dGkWLFjApk2b8PHx4csvv+TChQvWi3UXFxeGDh3KO++8g5OTEw0aNODixYvs37+fl156Kdl76d+/P+7u7smqzotkV9n1nHO3vXv34unpaX1uMpmoWrUq7dq1o2/fvnzzzTd4enry7rvvUqhQIdq1awdYale0atWKMmXKcOXKFf7++2/Kly8PwIgRIwgKCqJixYrExMTw+++/W1+THOrCgeTPI0LAWzWfxHapJT0b8HRx5MvnqzGhczU8nR3YeeoKrSesZ/Hus0aHJiLp8OWXX+Lj40P9+vVp27YtLVu2pEaNGlkex9ChQ+nSpQs9evSgXr16eHh40LJlS1xcXFJdf+nSpVy+fDnVxLV8+fKUL1+e6dOn4+TkxMqVK/Hz86N169ZUrlyZTz/9FHt7y5jbJk2aMH/+fJYuXUq1atV4/PHH2bZtm3VfY8eOJTAwkIYNG/LCCy/w1ltvWceV3897771HjRo1aNmyJU2aNKFAgQIppnZ6//33efPNNxkxYgTly5fn+eefTzHGtkuXLjg4ONClS5d7fhYi2Ul2PefcrVGjRlSvXt16CwoKAmDmzJkEBQXx1FNPUa9ePcxmM8uXL7f+sJeQkEC/fv0oX748Tz75JGXKlOHrr78GLHO9Dxs2jCpVqtCoUSPs7e2ZO3du5n0AYrzw/yTpV04aEoZIWpnMRg8aymJRUVF4e3sTGRmJl1fmtoJnhtMRN6xF5QDaVwtgtIrKSTZ269YtQkJCKF68uBIjgyQmJlK+fHmee+45PvzwQ6PDMczJkycpWbIk27dvz5RE5n5/69n9u8kW3esz1TnHeLnhnKO/MxszsbplXHq+UnD5GDR8E5qNMDoqyWXS812vlvRsJqmo3ODmZbC3M7E4+BytJ6xn56nUx4CKiPzXqVOnmDZtGkeOHGHv3r289tprhISE8MILLxgdmiHi4uI4f/487733HnXr1jWkpVEkJ9M5RwwVe/3OtGvl2ljuNQ2b2Dgl6dmQisqJyKOws7Nj1qxZ1KpViwYNGrB3715Wr16da8dkbty4kYIFC7J9+3amTp1qdDgiOY7OOWKoi4cAM7jlh8K3pwLUNGxi41Q4LhtLKio3Ysl+FqmonIikUWBgIBs3bjQ6DJvRpEkTw6eLEsnJdM4RQyUVjfOvAHmLWx6rJV1snFrSszlPF0fGqaiciIiIiEhKSUXj/CqCTzHL41tX4eYVoyISeSAl6TlEu2qFWD6wITWL+nAtJp5B84IZNHc3UbfijA5NRERERMQY4Xe1pDu5g4e/5bkqvIsNU5KegyQVlRvUvDR2Ju4qKqdfCkVEREQkF7pwV0s63GlNV5d3sWFK0nMYB3s7BjUvw/xX7xSV6/rdFoJPXzU6NBERERGRrHP9ElwPtzz2LWu597k9Ll3F48SGKUnPoYKK5mX5gIY0KuPLrbhE+ny/ndMRN4wOS0REREQka1zYb7n3KQbOHpbHKh4n2YCS9BzM08WRr7vWoEJBLy5Fx/LirO1E3tQYdRERERHJBcL/09Ud7mpJP5nl4YiklZL0HM7D2YEZvWpRwMuFY+HRvDZ7J7HxmktdxFY0adKEQYMGWZ8XK1aM8ePH33cbk8nE4sWLH/nYGbUfEck+dM6RXCWpJd2/wp1leZWki+1Tkp4LFPB2YUavWrg72bPp+GX+b9FezQks8ojatm3Lk08+mepr69evx2Qy8e+//6Z7v9u3b+fll19+1PCSGTlyJNWqVUuxPCwsjFatWmXose7l5s2b5M2bl/z58xMTE5MlxxTJSXTOSZtZs2aRJ0+eTD2GZCPhBy33fncl6UmF4yLPQLy+j8Q2KUnPJSoEeDG5aw3s7Uws2HmGyX8dMzokkWztpZdeYtWqVZw5cybFazNnzqRmzZpUqVIl3fv19fXFzc0tI0J8oAIFCuDs7Jwlx/r111+pWLEi5cqVM7wlzWw2Ex8fb2gMIumlc45IOiUm3knS/e/q7u7uC47ugBmuhhoSmsiDKEnPRZqW9WPk05aT1NhVR1gSfNbgiETuwWyG2OvG3NLYy+Spp57C19eXWbNmJVseHR3N/Pnzeemll7h8+TJdunShUKFCuLm5UblyZX7++ef77ve/XU+PHj1Ko0aNcHFxoUKFCqxatSrFNkOHDqVMmTK4ublRokQJ3n//feLiLPUnZs2axahRo9izZw8mkwmTyWSN+b9dT/fu3cvjjz+Oq6sr+fLl4+WXXyY6Otr6eq9evWjfvj1ffPEFBQsWJF++fPTr1896rPuZPn063bp1o1u3bkyfPj3F6/v37+epp57Cy8sLT09PGjZsyPHjx62vz5gxg4oVK+Ls7EzBggXp378/ACdPnsRkMhEcHGxd9+rVq5hMJtauXQvA2rVrMZlM/PHHHwQFBeHs7MyGDRs4fvw47dq1w9/fHw8PD2rVqsXq1auTxRUTE8PQoUMJDAzE2dmZUqVKMX36dMxmM6VKleKLL75Itn5wcDAmk4ljx/RDaLaic471eU4559xLaGgo7dq1w8PDAy8vL5577jkuXLhgfX3Pnj00bdoUT09PvLy8CAoKYseOHQCcOnWKtm3b4uPjg7u7OxUrVmT58uUPHYtksqunIO462DtB3hJ3lptMKh4nNs/B6AAka3WvW5TQy9eZtj6Et+f/S0FvV2oXz2t0WCLJxd2ATwKMOfb/nQMn9weu5uDgQI8ePZg1axbDhw/HZDIBMH/+fBISEujSpQvR0dEEBQUxdOhQvLy8WLZsGd27d6dkyZLUrl37gcdITEzkmWeewd/fn61btxIZGZlsLGkST09PZs2aRUBAAHv37qVv3754enryzjvv8Pzzz7Nv3z7+/PNPawLq7e2dYh/Xr1+nZcuW1KtXj+3btxMeHk6fPn3o379/sqTg77//pmDBgvz9998cO3aM559/nmrVqtG3b997vo/jx4+zefNmFi5ciNlsZvDgwZw6dYqiRYsCcPbsWRo1akSTJk3466+/8PLyYuPGjdbW7ilTpjBkyBA+/fRTWrVqRWRkJBs3bnzg5/df7777Ll988QUlSpTAx8eH06dP07p1az7++GOcnZ354YcfaNu2LYcPH6ZIkSIA9OjRg82bNzNx4kSqVq1KSEgIly5dwmQy0bt3b2bOnMlbb71lPcbMmTNp1KgRpUqVSnd8YiCdc4Ccc8653/tLStDXrVtHfHw8/fr14/nnn7f+qNe1a1eqV6/OlClTsLe3Jzg4GEdHRwD69etHbGws//zzD+7u7hw4cAAPD490xyFZJKloXP6yYO+Y/DWfYnBhn8ali81Skp4LDWtVntMRN/lz/3le/nEHC1+rTwlffcmIpFfv3r35/PPPWbduHU2aNAEsSVrHjh3x9vbG29s7WQL3xhtvsGLFCn755Zc0XTCvXr2aQ4cOsWLFCgICLAnEJ598kmJM53vvvWd9XKxYMd566y3mzp3LO++8g6urKx4eHjg4OFCgQIF7HmvOnDncunWLH374AXd3S8IwefJk2rZty//+9z/8/f0B8PHxYfLkydjb21OuXDnatGnDmjVr7nvBPGPGDFq1aoWPjw8ALVu2ZObMmYwcORKAr776Cm9vb+bOnWu9GC5Tpox1+48++og333yTgQMHWpfVqlXrgZ/ff40ePZoWLVpYn+fNm5eqVatan3/44YcsWrSIpUuX0r9/f44cOcIvv/zCqlWraN68OQAlStxpjenVqxcjRoxg27Zt1K5dm7i4OObMmZOidV0ko+ick7Zzzr2sWbOGvXv3EhISQmBgIAA//PADFStWZPv27dSqVYvQ0FDefvttypUrB0Dp0qWt24eGhtKxY0cqV64MJD8fiA26cDtJv7toXJK8mitdbJuS9FzIzs7EuOerETZtC3tOX6X3rO0sfL0Bed2djA5NxMLRzdK6ZNSx06hcuXLUr1+fGTNm0KRJE44dO8b69esZPXo0AAkJCXzyySf88ssvnD17ltjYWGJiYtI8/vPgwYMEBgZaL5YB6tWrl2K9efPmMXHiRI4fP050dDTx8fF4eXml+X0kHatq1arWi2WABg0akJiYyOHDh60XzBUrVsTe3t66TsGCBdm7d+8995uQkMD333/PhAkTrMu6devGW2+9xYgRI7CzsyM4OJiGDRtaE/S7hYeHc+7cOZo1a5au95OamjVrJnseHR3NyJEjWbZsGWFhYcTHx3Pz5k1CQy1jFIODg7G3t6dx48ap7i8gIIA2bdowY8YMateuzW+//UZMTAydOnV65Fgli+mcA+SMc86DjhkYGGhN0AEqVKhAnjx5OHjwILVq1WLIkCH06dOHH3/8kebNm9OpUydKliwJwIABA3jttddYuXIlzZs3p2PHjg9VB0CySPjtyu5+qSTpScXj1N1dbJTGpOdSrk72fNejJoV9XDl5+QZ9f9jBrbgEo8MSsTCZLN0/jbjd7kKaVi+99BK//vor165dY+bMmZQsWdKa1H3++edMmDCBoUOH8vfffxMcHEzLli2JjY3NsI9q8+bNdO3aldatW/P777+ze/duhg8fnqHHuNt/E2mTyURi4r2ndVyxYgVnz57l+eefx8HBAQcHBzp37sypU6dYs2YNAK6urvfc/n6vAdjZWb7G7p6x4l7jVe9OBgDeeustFi1axCeffML69esJDg6mcuXK1s/uQccG6NOnD3PnzuXmzZvMnDmT559/PsuKcEkG0jknzWz9nPOoRo4cyf79+2nTpg1//fUXFSpUYNGiRYDl//uJEyfo3r07e/fupWbNmkyaNCnTYpFHZG1Jr5jyNR+1pIttU5Kei/l6OjPrxVp4uTiw89QV3pq/h8RETc0mkh7PPfccdnZ2zJkzhx9++IHevXtbx4pu3LiRdu3a0a1bN6pWrUqJEiU4cuRImvddvnx5Tp8+TVhYmHXZli1bkq2zadMmihYtyvDhw6lZsyalS5fm1KlTydZxcnIiIeH+P8KVL1+ePXv2cP36deuyjRs3YmdnR9myZdMc839Nnz6dzp07ExwcnOzWuXNnawG5KlWqsH79+lSTa09PT4oVK2ZN6P/L19cXINlndHcRufvZuHEjvXr1okOHDlSuXJkCBQpw8uRJ6+uVK1cmMTGRdevW3XMfrVu3xt3dnSlTpvDnn3/Su3fvNB1b5GHpnPPwkt7f6dOnrcsOHDjA1atXqVDhTmtrmTJlGDx4MCtXruSZZ55h5syZ1tcCAwN59dVXWbhwIW+++SbTpk3LlFjlEcXHwOXbBTxTa0m/e670TPzRR+RhKUnP5Ur5eTK1exAOdiZ+/zeML1YeNjokkWzFw8OD559/nmHDhhEWFkavXr2sr5UuXZpVq1axadMmDh48yCuvvJKsivCDNG/enDJlytCzZ0/27NnD+vXrGT58eLJ1SpcuTWhoKHPnzuX48eNMnDjR2uqTpFixYoSEhBAcHMylS5dSnae8a9euuLi40LNnT/bt28fff//NG2+8Qffu3a3dTtPr4sWL/Pbbb/Ts2ZNKlSolu/Xo0YPFixcTERFB//79iYqKonPnzuzYsYOjR4/y448/cviw5Xw0cuRIxo4dy8SJEzl69Ci7du2ytl65urpSt25dPv30Uw4ePMi6deuSjZe9n9KlS7Nw4UKCg4PZs2cPL7zwQrIWumLFitGzZ0969+7N4sWLCQkJYe3atfzyyy/Wdezt7enVqxfDhg2jdOnSqXYNFslIOuc8WEJCQoofBg8ePEjz5s2pXLkyXbt2ZdeuXWzbto0ePXrQuHFjatasyc2bN+nfvz9r167l1KlTbNy4ke3bt1O+fHkABg0axIoVKwgJCWHXrl38/fff1tfExlw6AuYEcPYGr1SKQnoHgske4m9BdNr/j4hkFSXpQv2S+fm0o2VM1ddrjzN3m+aMFEmPl156iStXrtCyZctkYznfe+89atSoQcuWLWnSpAkFChSgffv2ad6vnZ0dixYt4ubNm9SuXZs+ffrw8ccfJ1vn6aefZvDgwfTv359q1aqxadMm3n///WTrdOzYkSeffJKmTZvi6+ub6pRMbm5urFixgoiICGrVqsWzzz5Ls2bNmDx5cvo+jLskFYRKbTx5s2bNcHV1Zfbs2eTLl4+//vqL6OhoGjduTFBQENOmTbN2c+3Zsyfjx4/n66+/pmLFijz11FMcPXrUuq8ZM2YQHx9PUFAQgwYN4qOPPkpTfF9++SU+Pj7Ur1+ftm3b0rJlS2rUqJFsnSlTpvDss8/y+uuvU65cOfr27Zus5Q8s//6xsbG8+OKL6f2IRB6Kzjn3Fx0dTfXq1ZPd2rZti8lkYsmSJfj4+NCoUSOaN29OiRIlmDdvHmD50e3y5cv06NGDMmXK8Nxzz9GqVStGjRoFWJL/fv36Ub58eZ588knKlCnD119//cjxSia4u2hcakNK7B0hz+3aBOryLjbIZDancYLOHCIqKgpvb28iIyPTXeQkp/ty5WEm/nUMezsTs16sRcPSvkaHJLnArVu3CAkJoXjx4ri4uBgdjki6rV+/nmbNmnH69On7tgDe729d300Z716fqc45khX0d2awVSNg4wSo+RI89WXq6/zQDk6shXZfQ/WuWRqe5E7p+a5XS7pYDW5RhvbVAkhINPP67F0cPn/N6JBERGxWTEwMZ86cYeTIkXTq1OmRu+iKiEgGud/0a0lUPE5smJJ0sTKZTPzv2SrULp6XazHx9J61nfCoW0aHJSJik37++WeKFi3K1atX+eyzz4wOR0REkoTfTtL9UqnsniSpeJymYRMbpCRdknF2sOfb7kGUyO/O2as3een7HdyIjTc6LBERm9OrVy8SEhLYuXMnhQoVMjocEREBuHkVos5aHvvdp7CfWtLFhilJlxTyuDkx88Va5HV3Yu/ZSAb8HEyCpmYTEREREVsXftBy71UIXPPce727p2ETsTFK0iVVRfO5M61HEE4Odqw+eIGPlh0wOiTJ4XJZDUvJhfQ3blv07yGZSX9fBgrfb7lPbX70u/kUs9zfuAy3ojI1JJH0UpIu9xRUNC9fPlcVgJkbTzJro7oDScZLmmbrxo0bBkcikrmS/saT/ubFGDrnSFbQ/3cDpaVoHICzJ7jltzxWl3exMQ5GByC27akqAYRG3OCzPw8z+vcDFPZxo3kFVTCWjGNvb0+ePHkIDw8HLHPnmlKb01QkmzKbzdy4cYPw8HDy5MmDvb290SFlqSlTpjBlyhROnjwJQMWKFRkxYgStWrVKdf1Zs2almHPe2dmZW7cyppCpzjmSmXL7/3ebkJaicUnyFocblyzF4wpWzdy4RNJBSbo80GuNSxJ6+QZzt5/mjZ9388sr9ahc2NvosCQHKVCgAID1olkkJ8qTJ4/1bz03KVy4MJ9++imlS5fGbDbz/fff065dO3bv3k3FiqlfRHt5eXH48GHr84xOonXOkcyWW/+/G85sTntLOliKx53ZrpZ0sTlK0uWBTCYTH7avxNmrN1l/9BK9v9/OzF61qFRIibpkDJPJRMGCBfHz8yMuLs7ocEQynKOjY65tUWvbtm2y5x9//DFTpkxhy5Yt90zSTSZTpiY4OudIZsrN/98NF3UOYiLBZA/5yzx4fRWPExulJF3SxNHejq+61uC5qZs5dP4aHads4tOOlelQvbDRoUkOYm9vrwsbkRwsISGB+fPnc/36derVq3fP9aKjoylatCiJiYnUqFGDTz755J4JfZKYmBhiYmKsz6OiHlwISucckRwmqat7vlLg4Pzg9ZOKx2mudLExKhwnaebl4si8V+rRtKwvMfGJDJ63h9G/HSAuIdHo0ERExIbt3bsXDw8PnJ2defXVV1m0aBEVKqTeFbVs2bLMmDGDJUuWMHv2bBITE6lfvz5nzpy57zHGjBmDt7e39RYYGJgZb0VEbNmF25Xd09LVHTRXutgsJemSLt6ujkzvWYsBj5cCYMbGELpP38ql6JgHbCkiIrlV2bJlCQ4OZuvWrbz22mv07NmTAwdSn9qzXr169OjRg2rVqtG4cWMWLlyIr68v33zzzX2PMWzYMCIjI62306dPZ8ZbERFblp6icXCnu3vkGYiPzZyYRB6CknRJNzs7E0OeKMvUbkG4O9mz5UQET0/awN4zkUaHJiIiNsjJyYlSpUoRFBTEmDFjqFq1KhMmTEjTto6OjlSvXp1jx47ddz1nZ2e8vLyS3UQkl0lP0TgAD39wdANzIkTqhz2xHUrS5aE9WakAS/o3oER+d85F3qLj1E38uvP+3RFFREQSExOTjR+/n4SEBPbu3UvBggUzOSoRydYS4uDS7Vkh/NKYpJtMd8alq8u72BAl6fJISvl5srh/A5qV8yM2PpE35+9h5NL9GqcuIiKApRv6P//8w8mTJ9m7dy/Dhg1j7dq1dO3aFYAePXowbNgw6/qjR49m5cqVnDhxgl27dtGtWzdOnTpFnz59jHoLIpIdRJyAhFhwdIc8RdO+nYrHiQ1SdXd5ZF4ujkzrUZMJa44yYc1RZm06yYGwKL56oQa+nmmorCkiIjlWeHg4PXr0ICwsDG9vb6pUqcKKFSto0aIFAKGhodjZ3WkzuHLlCn379uX8+fP4+PgQFBTEpk2b7lloTkQEuFM0zq8c2KWjHdJH07CJ7VGSLhnCzs7E4BZlqFTIm8HzgtkWEsHTkzcwtVsQVQPzGB2eiIgYZPr06fd9fe3atcmejxs3jnHjxmViRCKSI1mLxqXzB72k4nFqSRcbou7ukqFaVPBncb8GlPR1JyzyFp2+2cwvO1SIQ0REREQykbVoXBoruyfRNGxig5SkS4Yr5efB4n4NaFHBn9j4RN5Z8C/vL95HbLzGqYuIiIhIJghP6u7+kC3pV06C2ZyhIYk8LCXpkik8XRz5plsQQ1qUwWSCH7ec4oVpWwi/dsvo0EREREQkJ4mJvjOmPL0t6d6BYLKDuBsQHZ7hoYk8DCXpkmns7EwMaFaa73rUxNPZgR2nrtB20gZ2hV4xOjQRERERySku3p56zd0P3POnb1sHJ/AqbHmsLu9iI5SkS6ZrVt6fJf0bUNrPgwtRMXT+Zgtzt4UaHZaIiIiI5ATWru7lH277vMUs9yoeJzZCSbpkiRK+Hizq14CWFf2JTUjk3YV7+b9Fe4mJTzA6NBERERHJzh62aFwSFY8TG6MkXbKMh7MDU7oG8XbLsphMMGdrKF2+3cKFKI1TFxEREZGH9LBF45JoGjaxMUrSJUvZ2Zno17QUM3rWwtPFgV2hV3lq0ga2nLhsdGgiIiIikh1ZW9IfMkn3KWa5Tyo+J2IwJeliiKbl/Pit/2OU8ffg4rUYukzbwpcrDxOfoGnaRERERCSNosPhxiXABL4POSZd3d3FxihJF8MUy+/Ootcb8FzNwpjNMPGvYzz/7RZOR9wwOjQRERERyQ7Cb7ei5y0OTm4Pt4+k7u7XL0LMtYyJS+QRKEkXQ7k7O/DZs1WZ2KU6ns4O7Dx1hdYT1/P7v+eMDk1EREREbF1SV/eHHY8O4OINrnktj9XlXWyAknSxCU9XDWD5wIZUL5KHa7fi6T9nN+/++i83YuONDk1EREREbNWjFo1LouJxYkOUpIvNCMzrxi+v1KN/01KYTDB3+2naTtrAgXNRRocmIpLMleuxTFpzlNlbThkdiohI7vaoReOSqHic2BAHowMQuZujvR1vtSxL/VL5GDwvmOMXr9P+q40Ma12OXvWLYTKZjA5RRHKx0Ms3+G7DCX7ZcZpbcYn4eTrzXM1AnBz0m7eISJZLTISLhyyP/R5yjvQkKh4nNkRJutik+iXz88fARryzYA+rD4Yz6rcDrD96ic+frUI+D2ejwxORXGZ36BWmrT/Bn/vOk2i2LKsY4MXLjUpgp98ORUSMcSUE4m6AvTPkLfFo+1J3d7EhStLFZuV1d2Jaj5r8sPkUHy8/yF+Hwmk1YT3jnq9Gg1L5jQ5PRHK4xEQzaw6FM+2fE2w7GWFd3qSsLy83KkG9EvnUu0dExEhJld19y4L9I6Y1akkXG6IkXWyayWSiZ/1i1C6elzd+3s2x8Gi6Td/Kq41LMqRFGRzt1cVURDLWrbgEFu46y3frT3Di0nUAHO1NtK9WiD4NS1C2gKfBEYqICADhBy33/o/Y1R3utKRfPQ0JcWDv+Oj7FHlIStIlWyhf0Ivf+j/G6N8P8PO2UKasPc6m45eZ1Lk6RfI95JyYIiJ3ibgey+wtp/h+00kuX48FwNPFgW51i9KrfjH8vVwMjlBERJK5kFTZvfyj78ujgKXbfEIMRJ65k7SLGEBJumQbrk72jHmmMg1L5+fdX/9lz+mrtJ64no87VKJdtUJGhyci2dTJS9eZviGE+TstxeAACuVx5aXHivNcrUA8nPVVKSJik5K6uz9q0TgAOztLhfdLhy1d3pWki4EM7yv81VdfUaxYMVxcXKhTpw7btm277/rjx4+nbNmyuLq6EhgYyODBg7l161YWRSu2oHXlgvwxqBG1ivkQHRPPwLnBvDV/D9djNKe6iKTdrtArvPrjTpqOXcuPW05xKy6RSoW8mNilOuvebkLvx4orQRcRsVVxt+DyccvjR51+LYmKx4mNMPTqY968eQwZMoSpU6dSp04dxo8fT8uWLTl8+DB+fn4p1p8zZw7vvvsuM2bMoH79+hw5coRevXphMpn48ssvDXgHYpRCeVz5uW9dJv11jEl/HWXBzjPsPHWFiZ2rU7mwt9HhiYiNSkg0s/rgBab9c4Idp65Ylz9ezo++DUtQt0ReFYMTEckOLh0GcwK45AHPghmzTxWPExthaJL+5Zdf0rdvX1588UUApk6dyrJly5gxYwbvvvtuivU3bdpEgwYNeOGFFwAoVqwYXbp0YevWrVkat9gGB3s7BrcoQ/2S+Rg0L5iQS9d5ZspGhj5Zjt4NimOneZFE5LbwqFusOHCBGRtCCLldDM7J3o721QPo07AEZfxVDE5EJFu5cLuru39FyKgfV9WSLjbCsCQ9NjaWnTt3MmzYMOsyOzs7mjdvzubNm1Pdpn79+syePZtt27ZRu3ZtTpw4wfLly+nevfs9jxMTE0NMTIz1eVRUVMa9CbEJdUrk44+BDRn667+s2H+Bj5YdZMuJCMY9XxVPF1XmFMmNLkXHsOXEZTYfv8zmE5c5cfG69TWvu4rB+akYnIhI9mQdj55BXd3BMiYd4MqpjNunyEMwLEm/dOkSCQkJ+Pv7J1vu7+/PoUOHUt3mhRde4NKlSzz22GOYzWbi4+N59dVX+b//+797HmfMmDGMGjUqQ2MX25PHzYmp3YL4aWsoo38/wOqDF+jw9Sam9ahJ8fzuRocnIpks4nosW09YEvLNxy9zNDw62esmE1Qo6MWzQYV5rmYg7hprLiKSvVmT9Ayo7J7k7u7uZnPGtdCLpFO2ukpZu3Ytn3zyCV9//TV16tTh2LFjDBw4kA8//JD3338/1W2GDRvGkCFDrM+joqIIDAzMqpAlC5lMJrrVLUrlQt688uNOjoVH027yBia9UIPGZXyNDk9EMlDkjTi2hFgS8i0nLnPo/LUU65Qr4Em9kvmoVyIfdYrnw9tNPWtERHKMu7u7ZxSfooAJYqPh+iXw0PWjGMOwJD1//vzY29tz4cKFZMsvXLhAgQIFUt3m/fffp3v37vTp0weAypUrc/36dV5++WWGDx+OnV3KYvXOzs44Oztn/BsQm1U1MA9L32jAa7N3sfPUFV6cuY2hT5bj5UYlVBBKJJuKuhXHthMRli7sJy5zICwKszn5OmX8PahXIh/1SlqSch93J2OCFRGRzHXzClw7Z3mckS3pDs7gVQiizlha05Wki0EMS9KdnJwICgpizZo1tG/fHoDExETWrFlD//79U93mxo0bKRJxe3t7AMz/vVqTXM3P04U5fevwwZL9zN1+mjF/HOJAWBT/61gFF0d7o8MTybXMZjPxiWbiE8zEJSYSn2AmPiGRuMTb9wlm4m8vv3gtxpqU7zsbSeJ/TvMlfd1vt5Tnp06JvOT30A+yIiK5QlIruncguGTwrD55i1uS9IgQCKydsfsWSSNDu7sPGTKEnj17UrNmTWrXrs348eO5fv26tdp7jx49KFSoEGPGjAGgbdu2fPnll1SvXt3a3f3999+nbdu21mRdJImzgz1jnqlMxQAvRv12gCXB5zh+MZpvutekUB5Xo8MTyZZuxSUQFnmLs1ducvbqDc5evfP46o044hIS7yThtx/HJSRaHidYEvSHVTy/O3Vvt5TXLZEXP08VfRMRyZUyo2hcEp+icHK9pmETQxmapD///PNcvHiRESNGcP78eapVq8aff/5pLSYXGhqarOX8vffew2Qy8d5773H27Fl8fX1p27YtH3/8sVFvQWycyWSie71ilPLzpN+cXew7G0W7yRuY0i2IWsXyGh2eiM2JvBnH2Ss3OXf1JmeTblducuaqZdnFazEP3kk62ZksUyo62pks9/Z2ONqbcHd2IKiIz+2kPB8FvJWUi4gId5J0/8xI0pOKx53M+H2LpJHJnMv6iUdFReHt7U1kZCReXl5GhyNZ6MyVG7z8w04OhEXhaG9i5NMV6VqnqNFhiWQps9nM6YibHAiL5OTlG8kT8is3uRYT/8B9uDraU8jHlUJ5XO/c53Eln4eTNcF2sLPDwd6Eo70dDnam28tvL7v9WtJjOzvVitB3U8bTZyqSg01vCae3wDPToMpzGbvvfb/Cgt4QWBdeWpGx+5ZcLT3fS9mqurvIoyjs48avr9Xn7QV7+P3fMIYv2seBc1F80LYiTg4piw6KZHfxCYkcv3id/eci2X8uin1nIzkQFsW1W/dPxPO6O1EojysBeVwolMfNmogX9nElII8rPm6OKsIoIiLGMJsh/KDlcaZ0d79rGjYRgyhJl1zF1cmeSV2qUyHAi89XHOanraEcuXCNr7sG4eupolOSfd2KS+BgWBT7z1luB85Fcuj8NWLiE1Os62RvR5kCHpTy9bidgLsRkMfFmoS7OemrQUREbFTkGYiJBDsHyF8m4/ef93aSHn0BYq+Dk3vGH0PkAXQlJrmOyWTi9SalKF/AiwFzd7P95BXaTd7Atz1qUqlQBlcIFckEkTfi2B8WyYFzSUl5JMfCo1NUPwdwd7KnYoA3FQK8qBjgRcUAb0r5eaj3iIiIZE9J49HzlQaHTJhq09XHUjH+VqRlXHpGzsMukkZK0iXXalrOj8X9GtD3hx2cuHidjlM28dmzVWhXrZDRoYkkE5eQyI+bT7E15DL7z0Vx5srNVNfL7+FEhQDv28m4JSEvmtdNY75FRCTnuLDfcp8ZReOS+BSHsGAl6WIYJemSq5X09WBxvwYMmhvMX4fCGTg3mAPnonjnyXLYK7ERGzF25RGmrjuebFlhH1drIl4xwItKhbzx83TWWHEREcnZMnM8epK8t5P0CI1LF2Oov6Pkel4ujkzrUZN+TUsC8M0/J+g9azuRN+IMjkwEjl64xnfrTwDQv2kp5vStw54RT7Bh6ON8070mA5qVpll5f/y9XJSgi02aMmUKVapUwcvLCy8vL+rVq8cff/xx323mz59PuXLlcHFxoXLlyixfvjyLohURm5eZc6QnUfE4MZiSdBHA3s7E2y3LMfmF6rg62rPuyEXafbWBY+HXjA5NcjGz2cx7i/cRn2imRQV/3mpZlvol8+Pt5mh0aCJpVrhwYT799FN27tzJjh07ePzxx2nXrh379+9Pdf1NmzbRpUsXXnrpJXbv3k379u1p3749+/bty+LIRcTmJMTBxcOWx5nZ3T2peJxa0sUgmidd5D/2n4vk5R92cvbqTTycHRj/fDWaV/A3OizJhRbtPsPgeXtwcbRj9ZDGFPZxMzqk3CvmGlw+DpePwaWjlvvLR8GrMHSZ88i7z23fTXnz5uXzzz/npZdeSvHa888/z/Xr1/n999+ty+rWrUu1atWYOnVqmo+R2z5TkVwh/CB8XRecPODd02CXSe2NIf/A920hbwkYsDtzjiG5juZJF3kEFQO8Wdq/Af3m7GLLiQj6/riDQc3K0P/xUhqnLlkm8mYcHy+zjLt74/HSStCzQkI8XD11OwG/Oxk/BtfCUt/m+qWsjTGbS0hIYP78+Vy/fp169eqlus7mzZsZMmRIsmUtW7Zk8eLF9913TEwMMTEx1udRUVGPHK+I2JikonF+5TMvQYc73d2vhkJiAtjZZ96xRFKhJF0kFfk8nPnxpTp8vOwgszadZNzqI2w/GcG456tpPnXJEl+uPMyl6FhK+rrTt2EJo8PJOcxmS2Kd1BJ++Rhcuv04IgQS71OLwt0X8pWy3PKXvv24dNbFno3t3buXevXqcevWLTw8PFi0aBEVKqTeVfX8+fP4+yfvveTv78/58+fve4wxY8YwatSoDItZRGxQVoxHB/AKAHsnSIi1zMvuUzRzjyfyH0rSRe7B0d6OkU9XpHIhb95bvI8Nxy7ReuJ6JnSuRv2S+Y0OT3KwvWci+XHLKQA+bFcpd85pvmcu/PURJMaDyQ4wWe5N/Oe56T/Pk5aZUq6TGG+ZTudW5L2P6+ByJxG3JuOlIV9JcM2TBW88ZypbtizBwcFERkayYMECevbsybp16+6ZqD+MYcOGJWuBj4qKIjAwMMP2LyI2IKmye2ZPi2ZnD3mKWn7AvRKiJF2ynJJ0kQfoGFSYqoHevP7TLo5ciKbbd1sZqO7vkkkSEs28t3gviWZoVy2A+qVy6Q9C276FyNOZtHMT5Am80xKerxTkv/3Yq1DmdqHMpZycnChVqhQAQUFBbN++nQkTJvDNN9+kWLdAgQJcuHAh2bILFy5QoECB+x7D2dkZZ2f1dBLJ0e7u7p7Z8ha/08uqRJPMP57IXZSki6RBKT9PlvR7jJFL9zNvx2nGrT7C1pDLjO9cDT9PF6PDkxxk7vZQ9pyJxNPZgeGts+AixBYlJt5pLek8x9Lt0Gy23DCDOfH288QHPP/P+mBJzvOWAEdXY96bAJCYmJhs/Pjd6tWrx5o1axg0aJB12apVq+45hl1EcomYa5a6IQB+mdySDuBTzHKvadjEAErSRdLI1cme/z1bhbol8zJ80T42Hb9M6wkbmNi5Wu5t7ZQMdSk6hs/+tEwtM+SJMvh55dIfgK6EQNwNsHeG0i3BXl9V2dmwYcNo1aoVRYoU4dq1a8yZM4e1a9eyYsUKAHr06EGhQoUYM2YMAAMHDqRx48aMHTuWNm3aMHfuXHbs2MG3335r5NsQEaOFH7Lce/iDe77MP551rvSTmX8skf9Qnz6RdOpQvTBL+z9GWX9PLkXH0HX6VsatOkJCYq6azVAywad/HCLyZhwVCnrRvW4uHv9mLQxUTgl6DhAeHk6PHj0oW7YszZo1Y/v27axYsYIWLVoAEBoaSljYner59evXZ86cOXz77bdUrVqVBQsWsHjxYipVqmTUWxARWxCe1NU9k4vGJdFc6WIgXf2IPIRSfh4s7teAUb/tZ+7200xYc5RtIRFM6KLu7/Jwtp+MYMHOMwB81KESDva5+DfUC0lJehZ0Z5RMN3369Pu+vnbt2hTLOnXqRKdOnTIpIhHJlpK+GzK7aFySu1vSzebbBUlFskYuvgoUeTSuTvZ82rEK45+vhpuTPZtPXKb1hPVsOKp5kyV94hISeW/RPgC61A6kRhEfgyMy2AXLZ4F/FrWWiIiI7cuq6deSJFV0j4mCGxFZc0yR25Skizyi9tUL8dsbj1GugCeXomPpPmMrX648rO7vkmbfbzrJ4QvX8HFz5J2W5YwOx3jhWdxaIiIits1svitJz6Kiqo6u4FnQ8ljF4ySLKUkXyQAlfS3d37vULoLZDBP/OsYL07ZwIeqW0aGJjQuLvMm4VUcAeLdVOXzcnQyOyGCxNyDihOWxuruLiAhAdDjcuAyYwDcLf8z20bh0MYaSdJEM4uJoz5hnKjOhczXcnezZGhJB6wnr+efIRaNDExv20e8HuR6bQI0ieegUFGh0OMa7eMgyZZpbPvDwMzoaERGxBUlF4/KWACe3rDtuXlV4F2MoSRfJYO2qFWLp7e7vl6/H0nPmNr5YcZj4hESjQxMbs+7IRZbtDcPOBB+1r4ydnYrSJOvqriI9IiICdxWNy+JaJdbicWpJl6ylJF0kEyR1f3+hjqX7++S/j/HCd1vV/V2sbsUl8MESS4G0XvWLUyHAy+CIbIQqu4uIyH+FG/TdoGnYxCBK0kUyiYujPZ90uNP9fVtIBK0mrGedur8L8O0/Jzh5+QZ+ns4MblHa6HBshyq7i4jIf1243d09y1vSi1nu1ZIuWUxJukgma1fNUv29fEEvIq7H0nPGNv735yHi1P091zp1+TqT/z4GwPtPVcDTxdHgiGyIKruLiMjdEhPg4mHL46xuSU/q7n4tDOJuZu2xJVdTki6SBUr4erDo9fp0rVMEgClrj/PcN5s5HXHD4Mgkq5nNZkYu3U9sfCKPlcrPU1UKGh2S7YgOh+sXsVTvzaIpdkRExLZdOQnxN8HB5U7386zilhecbw9Hu3Iqa48tuZqSdJEs4uJoz8cdKjP5hep4ujiwO/QqrSesZ0nwWaNDkyy0Yv8F/j58EUd7E6PaVcSk4mh3JHVnzFs8a6v3ioiI7Ur6bvAtC3b2WXtsk0ld3sUQStJFsthTVQJYPqAhNYrk4VpMPAPnBvPW/D1cj4k3OjTJZNdj4hn9m+Vi45VGJSnp62FwRDbGWhhI49FFROQ2o4rGJVHxODGAknQRAwTmdeOXV+ox4PFS2Jlgwc4zPDVpA3vPRBodmmSiiX8d5VzkLQr7uNKvaSmjw7E91il2Khkbh4iI2A6jisYlUUu6GEBJuohBHOztGPJEWX7uW5eC3i6EXLrOM1M28u0/x0lMNBsdnmSwoxeuMX295Qt+1NMVcXXK4i572UG4wRdiIiJie4zuZeWjlnTJekrSRQxWp0Q+/hjYkCcrFiAuwcwnyw/Rc+Y2wq9pTvWcwmw2897ifcQnmmle3p9m5f2NDsn2JCZA+EHLY82RLiIiYKmoHnHC8tioWT+SurtfOWnM8SVXUpIuYgPyuDkxpVsNPu5QCRdHO9YfvUTrCev5+3C40aFJBlgcfJatIRG4ONrxQVu1EqcqIgTib4GDa9ZX7xUREdt08TCYE8HVBzwM+oE7qSX96inLD8oiWUBJuoiNMJlMdK1TlN/6P0a5Ap5cio7lxZnbGf3bAWLi9aWQXUXejOPjZZYW4jceL01gXlUtT1VSV3e/cllfvVdERGzT3UXjjJoNxbsw2DlAQixEnTMmBsl1lKSL2JjS/p4s7teAXvWLATBjYwgdvtrE8YvRxgYmD2XsysNcio6lpK87fRuWMDoc25VUGEhd3UVEJInRRePA8sNxniKWxyoeJ1lESbqIDXJxtGfk0xX5rkdNfNwcORAWxVMTNzBveyhms4rKZRd7z0Ty45ZTAHzYrhJODjrl3pP1QkxJuoiI3GZ00bgkKh4nWUxXjCI2rHkFf/4c1IgGpfJxMy6Bob/upf/Pu4m8GWd0aPIACYlm3lu8F7MZ2lULoH6p/EaHZNuSLsRU2V1ERJJYp+Y0+AdcFY+TLKYkXcTG+Xu58GPvOgx9shwOdiaW/RtG6wnr2XEywujQ5D7mbg9lz5lIPJ0dGN66vNHh2LbY63daJ9TdXUREAG5EQPR5y2PfcsbGktSSru7ukkWUpItkA3Z2Jl5rUpIFr9WnSF43zl69yXPfbGbimqMkaE51m3MpOobP/jwMwJAnyuDn5WJwRDYu/BBgBnc/8PA1OhoREbEFST2svIuAi5exseRVd3fJWkrSRbKRaoF5WDbgMTpUL0SiGb5cdYQu07Zw7upNo0OTu0z+6xiRN+OoUNCL7nWLGh2O7Qu3gcJAIiJiWy7Y0DAon2KWe7WkSxZRki6SzXi6ODLu+WqMe74q7k72bAuJoNWE9azYf97o0AS4FZfAot1nAXjnybI42Os0+0Cq7C4iInczmyEs2PLY6KJxcCdJvxVp6YYvksl09SiSTXWoXphlAxpStbA3kTfjeOXHnYz6bb/mVDfYmoPhRN6Mo4CXCw1Lq+t2mqiyu4iIxFyDg7/DbwNhXCUI/smy3Ba+G5zcwcPf8lit6ZIFHIwOQEQeXrH87sx/tT6frzjEtPUhzNx4kh0nrzD5heoUzedudHi50oKdpwF4pkYh7O1MBkeTDZjNquwuIpIbmc0QfhCOrYKjqyB0CyTeNXuNgwuUag5lWhoX4918ikP0BUuF90JBRkcjOZySdJFszsnBjuFtKlC3RD7enL+HvWcjeWriBsZ0rMxTVQKMDi9XCY+6xbojFwF4NqiwwdFkE9HhcOMymOyMr94rIiKZK+YanFh3OzFfDVFnkr/uUxxKPwGlW0Cxx8DR1Zg4U5O3OJzeouJxkiWUpIvkEM3K+7N8QEMG/LybHaeu0H/ObjYfv8z7T1XAxdHe6PByhUW7z5JohqCiPpTw9TA6nOzhwj7Lfd4StnUxJiIij85shouH4OjKe7eWF3sMSrWwJOb5ShoX64OoeJxkISXpIjlIQB5X5r5cl3Grj/D12uP8tDWUnaeu8FXXGpRU0pipzGYz83daWgTUip4O1q7uNjDmUEREHl2aWstbWFrMizYAJzdj4kyvpLnSI04aGobkDkrSRXIYB3s73m5ZjjrF8zF4XjCHzl+j7aQNfNyhEh2qK3nMLHvORHIsPBoXRzvaVClodDjZR9IUO6rsLiKSve1dALu+h1Obk7eW2ztbWsuTurHbcmv5/STNla6WdMkCStJFcqhGZXz5Y2BDBs4NZvOJywyet4dNxy4zql1F3Jz0Xz+jJRWMe7JiAbxcHA2OJhtJ6u6uonEiItnX7tmwpN+d5z7FLEl5qdtjy7NLa/n9JLWkR52DuFvg6GJsPJKj6UpdJAfz83Jhdp86TPrrKBPWHGX+zjMEn77KV11rUMbf0+jwcoxbcQksDT4HwLNBgQZHk40kxMPFw5bH6u4uIpI9HVtjmTYNoGZvqNvP0lpuymEznLjnBycPiI2Gq6HgW8boiCQH0zzpIjmcvZ2JQc3L8FOfOvh6OnM0PJqnJ2/gl+2nMZvNRoeXI6w6cIGoW/EEeLtQr2Q+o8PJPiJOQEIMOLpDnmJGRyMiIul1fi/80hMS46FyJ2g9FvKXynkJOljek4rHSRZRki6SS9QvmZ8/BjakYen83IpL5J1f/2XwvGCiY+KNDi3bW3C7YNwzNQprbvT0SOrq7lcO7PR1JCKSrUSegZ86Qew1KNYQ2n2V88/lSUm6pmGTTJbD/yeJyN3yezjz/Yu1eefJstjbmVgcfI6nJ21g/7lIo0PLts5H3mL9Uc2N/lBU2V1EJHu6FWlJ0K+FgW85eP5HcHA2OqrMp+JxkkWUpIvkMnZ2Jl5vUoq5L9eloLcLJy5dp8PXm/hxyyl1f38ISXOj1yrmQ7H87kaHk72osnuuMGbMGGrVqoWnpyd+fn60b9+ew4cP33ebWbNmYTKZkt1cXFSkScQmxMfCvO6WH1o9/KHrfHD1MTqqrJFUPO7KSUPDkJxPSbpILlWrWF6WD2hIs3J+xMYn8v7iffSfs5uoW3EP3liApLnRLVXd1Yr+EML3W+5V2T1HW7duHf369WPLli2sWrWKuLg4nnjiCa5fv37f7by8vAgLC7PeTp06lUURi8g9mc3w2wAIWWepJ/LCL5CniNFRZZ2klnR1d5dMpuruIrmYj7sT3/WsyfQNIXz6xyGW7Q3j37NXmdylBlUD8xgdns3bffoqJy5ex8XRjtaVNTd6usRcu9MSoZb0HO3PP/9M9nzWrFn4+fmxc+dOGjVqdM/tTCYTBQoUyOzwRCQ91o6BPT+DyR6e+x4CqhkdUdayFo47CYmJOX8MvhhGf1kiuZzJZKJPwxLMf7UehX1cOR1xk2enbuLrtceIT0g0OjybllQwrnWlgnhqbvT0CT9kufcoAO6qiJ+bREZaamDkzZv3vutFR0dTtGhRAgMDadeuHfv377/v+jExMURFRSW7iUgG2vUjrPuf5fFTX0LpFsbGYwTvQMsPFAkxlvH4IplESbqIAFC9iA/LBjTkyYoFiEsw89mfh+k4ZRNHL1wzOjSbdCsugd/2JM2Nrq7u6aau7rlSYmIigwYNokGDBlSqVOme65UtW5YZM2awZMkSZs+eTWJiIvXr1+fMmTP33GbMmDF4e3tbb4GBgZnxFkRyp2Or78yF3vAtCOplaDiGsXeEPLfPLSoeJ5lISbqIWHm7OjKlWw0+f7YKni4O7DkTSZuJG9SqnooV+89z7VY8hfK4UreEWoLT7UJSkq6u7rlJv3792LdvH3Pnzr3vevXq1aNHjx5Uq1aNxo0bs3DhQnx9ffnmm2/uuc2wYcOIjIy03k6fPp3R4YvkTmH/WuZCNydAlefh8feMjshYKh4nWUBJuogkYzKZ6FQzkFWDG9O0rC+xCYl89udhnpmyiSNqVbdK6uresUYh7DQ3evqpsnuu079/f37//Xf+/vtvChdOX+8TR0dHqlevzrFjx+65jrOzM15eXsluIvKIrp6+PRd6tGUu9KcngymXf+epeJxkASXpIpKqAt4uzOhViy86VcXTxYF/z0Ty1MQNfPW3WtXDIm+y4dglADqqq3v6mc3q7p6LmM1m+vfvz6JFi/jrr78oXrx4uveRkJDA3r17KVhQBRpFsszNq5YEPfr87bnQZ4ODk9FRGc9aPE5JumQeJekick8mk4lngwqzanBjHi/nR2xCIp+vOEyHrzdx+HzubVVfuOssZjPULp6Xovk0N3q6XQuDm1csxXfylzU6Gslk/fr1Y/bs2cyZMwdPT0/Onz/P+fPnuXnzpnWdHj16MGzYMOvz0aNHs3LlSk6cOMGuXbvo1q0bp06dok+fPka8BZHcJz4WfukOFw9aCnx2XQCueYyOyjb4qCVdMp+SdBF5oALeLkzvWZMvn6uKl4sDe89G8tSk9Uz+6yhxuaxV3Ww28+vtru4qGPeQkrq65ysFji7GxiKZbsqUKURGRtKkSRMKFixovc2bN8+6TmhoKGFhdyolX7lyhb59+1K+fHlat25NVFQUmzZtokIF9bwQyXRmMyx9A0L+AScP6PrLnWJpcqe7u1rSJRNpnnQRSROTycQzNQrToFR+/m/hXtYcCueLlUf4c/95vuhUlXIFcsf4z12hVzhx6TqujvaaG/1hqat7rmI2mx+4ztq1a5M9HzduHOPGjcukiETkvv7+BP6da+nt1Ol7KFjV6IhsS1J395tXLEMCbLGHQcw12D0btk6FxAR45R9wu/+0l2Jb1JIuIuni7+XCdz1rMu75qni7OrLvbBRtJ21g0prc0apunRu9ckE8nPU750NJquyuonEiIrZl5/fwz2eWx0+Ng9LNjY3HFjl7gruv5bGtVXiPPAurRsCXFeHPdy3xRZ6G438ZHZmkk5J0EUk3k8lEh+qFWTW4Ec3L+xOXYGbsqiO0/2ojB8OijA4v09yMTeD3PZYuuerq/giSurtr+jUREdtxdDX8PtjyuNHbENTT2Hhsma0VjwvbA7/2hQlVYOMEiIm0DCkLrGt5PXSzsfFJuilJF5GH5uflwrQeQYx/vhrero7sPxfF05M3MGF1zmxVX3ngPNdi4ins40qd4uo29lAS4uDSYctjdXcXEbENYXtgftJc6J2h6XCjI7JttlA8LjERjqyAWU/BN41g7y+QGA9FH4Muc6Hfdqj7mmXd0K3GxSkPRX01ReSRmEwm2lcvRP1S+Ri+aB+rDlxg3OojrLg9Vr1CQM4Zqz5/R9Lc6IU1N/rDunwcEmItxYi8ixgdjYiIXD0NPz1311zokzQX+oMYWTwu7ibsmQtbvoZLRyzLTPZQsQPU6weFatxZt8jtlvTw/XArEly8sz5eeShK0kUkQ/h5uvBt9yCW7jnHB0v3cyDM0qre//FSvN6kFE4O2bvjztmrN9l43DI3urq6P4IL+yz3fhXALnv/TYiIZHvJ5kIvr7nQ08qIlvToi7D9O8vthuV6BGcvy7CE2q+kXoHfs4Cla/6Vk3BmO5RSjYHsQkm6iGQYk8lEu2qFqFcyH+8t2sfKAxcYv/ooK/Zf4PNnq1CpUPb9BXfRrjOYzVC3RF4C87oZHU72FZ40Hl1d3UVEDBUfC/O6WeZC9ywI3TQXeppZW9JPZf6xLh6GzV9ZWs8TYizLvAMtXdmrdweXB/RYDKxrSdJDtypJz0aUpItIhvPzdOGb7kH89m8YHyzZx8GwKNp9tZE+DYszqFkZXJ3sjQ4xXcxms7Wq+7NBmiv2kSQVjVNldxERY9yIsPxguu1bOLneMvzohV/AW73E0iypcFzUGcuPHRnd+8BstsxTv3kyHF15Z3lADajfH8q3A/s0pnFF6lqm1Du9JWNjlEylJF1EMoXJZOLpqgHUK5GPkUv3s2xvGN+sO8Efe8/zSYfKPFY6v9EhptmOU1c4efkGbk72tKpUwOhwsrek6ddU2V1EJHMlxMGlo5bz7oV9lvvwAxB19s46Jnt47nsoWMW4OLMjD39wdIO4G3A1FPKXypj9xsfC/kWweRKc33t7oQnKtYF6/S0Jd3rrBSSNSz+zw/I3Ye+YMbFKpjI8Sf/qq6/4/PPPOX/+PFWrVmXSpEnUrl37nutfvXqV4cOHs3DhQiIiIihatCjjx4+ndevWWRi1iKSVr6czX3WtQYcDF3h/yT5CI27QbfpWOtYozHttyuPjbvtj3xbcLhjXpnJB3DU3+sO7FQWRoZbH6u4uIpIxzGa4dv52Er7/dlK+39JNOjEu9W28i1jOwzVfUhfoh2EyWVrTww9YiselJ0k3my29GS4fg4jjloKqEcctzy+fgLjrlvUcXKF6V6j7OuQr+fCx5i9rKRh3K9KS+N9dWE5slqFXm/PmzWPIkCFMnTqVOnXqMH78eFq2bMnhw4fx8/NLsX5sbCwtWrTAz8+PBQsWUKhQIU6dOkWePHmyPngRSZfmFfypUyIvX6w4zA9bTvHrrjOsPRzOiLYVeLpqACYbrSR7IzaeZXs1N3qGCD9oufcMAFcfY2MREcmOYm9YxpBf2J/8djMi9fWdPC09l/wrWpJy/0rgV15VvjOCT3FLkn6v4nE3r95Ovk/clYTfTshvRd57vx7+ULuv5QcUtwyY7tXOzjIu/egKCN2iJD2bSHeSXqxYMXr37k2vXr0oUuTRps/58ssv6du3Ly+++CIAU6dOZdmyZcyYMYN33303xfozZswgIiKCTZs24ejoaI1HRLIHTxdHRrWrxNPVCjFs4b8cuRDNwLnBLNx1lo/aV7LJgmwr9p8nOiaeInndqFVMc6M/kqTK7urqLtlJ2L/wz2dGR/FgZnM6Xzcb9Lr53svuu04q25jNabi/17rp2cfDbn+byQSYkj9OdRn3Xy8xzjJd2n8/WwCTHeQrdVdCXskyi0aeIppOLbMkFY87vRU8fO+0hCe1jidVYL8Xr8KWFvJ8JSHvXfd5S6R9vHlaFaljSdJPb4F6r2fsviVTpPsvYNCgQcyaNYvRo0fTtGlTXnrpJTp06ICzs3O69hMbG8vOnTsZNmyYdZmdnR3Nmzdn8+bNqW6zdOlS6tWrR79+/ViyZAm+vr688MILDB06FHv71AtRxcTEEBMTY30eFRWVrjhFJOMFFfXh9zca8s2640z66xjrjlzkiXH/8OYTZehVvxgO9rYzNZfmRs9Aquwu2dH1cDj4m9FRiNzhlh8KVLqTiPtXBN+y4OhqdGS5S1LxuH0LLLfUeBS4nXyXuJ2Ql7qdiBfP2n+vIvUs96FbLT8g6Ycbm/dQSfqgQYPYtWsXs2bN4o033uD111/nhRdeoHfv3tSokbYuFJcuXSIhIQF/f/9ky/39/Tl06FCq25w4cYK//vqLrl27snz5co4dO8brr79OXFwcH3zwQarbjBkzhlGjRqXvTYpIpnNysOONZqVpXaUgwxbuZVtIBB8tO8iS4HN82rEyFQOM74p35soNNh2/DMAzNQoZHE0OoMrukh35loM2XxodRdqkuPA22ejrpnsvSy15uOc6ppQtzvdtqf5Pi/WDtn3gfRr2k9SyDilb25Mt4x7rceexyc6S3HmkHBIqBijV3PKDCebbLeGlIF+Ju1rFS4Czp9FRWgRUBztHiD5vmY4tqReA2CyT2fyg/lH3FxcXx9dff83QoUOJi4ujcuXKDBgwgBdffPG+Y0zPnTtHoUKF2LRpE/Xq1bMuf+edd1i3bh1bt25NsU2ZMmW4desWISEh1pbzL7/8ks8//5ywsLBUj5NaS3pgYCCRkZF4eT1gXkERyRKJiWbm7TjNJ8sPcu1WPPZ2JpuYrm3imqN8ueoI9UvmY07fuobFkSOYzfC/opZxeK9ugAKVjY7IpkRFReHt7a3vpgykz1REMl12apX+rjmc2Q4dvoGqnY2OJldKz/fSQ/cpjYuL45dffuHpp5/mzTffpGbNmnz33Xd07NiR//u//6Nr16733T5//vzY29tz4cKFZMsvXLhAgQKpT3FUsGBBypQpk6xre/ny5Tl//jyxsbGpbuPs7IyXl1eym4jYFjs7E11qF2HNkMa0qVyQhEQz36w7Qcvx/7Dh6APGdGWS5HOjq2DcI4s6a0nQ7RwgfxmjoxEREXl02SVBhztTsYVqvvTsIN1J+q5du3jjjTcoWLAg/fv3p2LFiuzbt48NGzbw4osv8v7777N69WoWLVp03/04OTkRFBTEmjVrrMsSExNZs2ZNspb1uzVo0IBjx46RmJhoXXbkyBEKFiyIk5PtT+MkIvfn5+XCV11r8F2PmhT0drFO1/bmL3u4cj31H+Iyy7aQCEIjbuDuZM+Tmhv90SV1dc9XGhzSV8NEREREHlGgkvTsJN1Jeq1atTh69ChTpkzh7NmzfPHFF5QrVy7ZOsWLF6dz5wd3oxgyZAjTpk3j+++/5+DBg7z22mtcv37dWu29R48eyQrLvfbaa0RERDBw4ECOHDnCsmXL+OSTT+jXr19634aI2LDmFfxZObgRPesVxWSCX3edofmX61gSfJZHHKGTZkmt6G2qFMTNSXOjP7Lw/ZZ7FY0TERHJeoF1LPcXD8LNK8bGIg+U7ivPEydOULRo0fuu4+7uzsyZMx+4r+eff56LFy8yYsQIzp8/T7Vq1fjzzz+txeRCQ0Oxs7vzO0JgYCArVqxg8ODBVKlShUKFCjFw4ECGDh2a3rchIjbOyOnarsfcmRu9U83ATDtOrnIhKUlX0TgREZEs5+FrKW53+Ric3g5lnjA6IrmPdCfp4eHhnD9/njp16iRbvnXrVuzt7alZs2a69te/f3/69++f6mtr165NsaxevXps2aJuGiK5xb2maxvcojQ96xfD2SHjC8v9ue88N2ITKJrPjZpFfTJ8/7mSKruLiIgYK7CuJUkP3awk3calu7t7v379OH36dIrlZ8+eVbdzEckUSdO1/TGoIbWL5+VmXAKfLD9E8y/XsXTPORITM7YLvLVgXI3C952lQtIoPhYuHbE8Vnd3ERERYxS53ch6OuUsWmJb0p2kHzhwINW50KtXr86BAwcyJCgRkdSU9PVgbt+6fPZsFfw8nTkdcZMBP++mw9cb2XLicoYc43TEDTafuIzJBM+oqnvGuHwUEuPA2Qu8NXxARETEEEVuF+c+u9PyA7rYrHQn6c7OzimmTQMICwvDwUHFlUQkc9nZmXiuZiBr327CkBZlcHeyZ8+ZSDp/u4U+32/n6IVrj7T/X3dZWtEblMxPoTyuGRGyWLu6V8he09WIiIjkJPlKgVs+iL8FYXuMjkbuI91J+hNPPMGwYcOIjIy0Lrt69Sr/93//R4sWLTI0OBGRe3FzcmBAs9Ksfbsp3eoWwd7OxOqD4bQc/w/DFu4l/NqtdO8zMdFsTdI1N3oGUmV3ERER45lMd6ZiO60aX7Ys3Un6F198wenTpylatChNmzaladOmFC9enPPnzzN27NjMiFFE5J58PZ35qH1lVg5uxBMV/Ek0w8/bQmny+VrGrTrC9Zj4NO9r28kITkfcxMPZgZYVNTd6hlFldxEREduQNC5d86XbtHQn6YUKFeLff//ls88+o0KFCgQFBTFhwgT27t1LYKDGGoqIMUr6evBtj5r88ko9qgXm4UZsAhPWHKXJF2uZszWU+ITEB+5j/g5LK/pTVQri6pTxVeNzLVV2FxERsQ1JLemhW8CcsYV3JeM81CByd3d3Xn755YyORUTkkdUunpdFr9dn+d7zfLbiEKcu3+D/Fu1lxsYQ3n2yHM3K+6Vasf16TDx/7EuaG11d3TPMzasQZfnxA7/yhoYiIiKS6wVUA3tnuHEJIk5AvpJGRySpeOhKbwcOHCA0NJTY2OSVAZ9++ulHDkpE5FGYTCbaVClIiwr+/LT1FBPXHOVYeDR9fthBneJ5+b/W5akamCfZNsv3hnEjNoHi+d2pUURzo2eY8IOWe6/C4JrH0FBERERyPQdnKFTDMld66GYl6TYq3Un6iRMn6NChA3v37sVkMmG+3U0iqWUqISEhYyMUEXlITg52vNigOM/UKMyUtceZsTGErSERtPtqI22rBvD2E2Upks8NuGtu9CDNjZ6hLuyz3Gs8erZ0+vRpTCYThQtbepds27aNOXPmUKFCBfWoExHJrgLr3E7St0D1bkZHI6lI95j0gQMHUrx4ccLDw3Fzc2P//v38888/1KxZk7Vr12ZCiCIij8bb1ZF3W5Xj77ea8EyNQphM8NueczT7ci0f/n6Af89cZWtIBCYTdKheyOhwc5bw2+PRVdk9W3rhhRf4+++/ATh//jwtWrRg27ZtDB8+nNGjRxscnYiIPJSk+dJPbzU2DrmndCfpmzdvZvTo0eTPnx87Ozvs7Ox47LHHGDNmDAMGDMiMGEVEMkShPK58+Vw1fn/jMRqWzk9cgpnpG0J4evJGAB4rlZ8AzY2esVQ0Llvbt28ftWvXBuCXX36hUqVKbNq0iZ9++olZs2YZG5yIiDycQMt5nUtH4PplY2ORVKU7SU9ISMDT0xOA/Pnzc+7cOQCKFi3K4cOHMzY6EZFMUDHAmx9fqsP3vWtTroCndbnmRs9gZvNdLelK0rOjuLg4nJ2dAVi9erW17ky5cuUICwszMjQREXlYbnkhf1nLY7Wm26R0j0mvVKkSe/bsoXjx4tSpU4fPPvsMJycnvv32W0qUKJEZMYqIZIrGZXx5rFR+fttzjovXYmhbJcDokHKWyNMQEwV2jpC/tNHRyEOoWLEiU6dOpU2bNqxatYoPP/wQgHPnzpEvXz6DoxMRkYdWpC5cOmwZm16utdHRyH+kO0l/7733uH79OgCjR4/mqaeeomHDhuTLl4958+ZleIAiIpnJ3s5Ee41DzxxJXd3zlwF7R2NjkYfyv//9jw4dOvD555/Ts2dPqlatCsDSpUut3eBFRCQbKlIXdn2vlnQble4kvWXLltbHpUqV4tChQ0RERODj46OKyCIicocqu2d7TZo04dKlS0RFReHjc2dqwpdffhk3NzcDIxMRkUdSpK7l/txuiLsFji7GxiPJpGtMelxcHA4ODuzbty/Z8rx58ypBFxGR5FTZPdu7efMmMTEx1gT91KlTjB8/nsOHD+Pn52dwdCIi8tB8ioO7HyTEWhJ1sSnpStIdHR0pUqSI5kIXEZEHU2X3bK9du3b88MMPAFy9epU6deowduxY2rdvz5QpU9K0jzFjxlCrVi08PT3x8/Ojffv2aSo0O3/+fMqVK4eLiwuVK1dm+fLlj/ReRETkLiYTFKljeXx6i7GxSArpru4+fPhw/u///o+IiIjMiEdERHKC+BjL1C6g7u7Z2K5du2jYsCEACxYswN/fn1OnTvHDDz8wceLENO1j3bp19OvXjy1btrBq1Sri4uJ44oknrPVtUrNp0ya6dOnCSy+9xO7du2nfvj3t27dP0ZNPREQeQdJ86aEal25r0j0mffLkyRw7doyAgACKFi2Ku7t7std37dqVYcGJiEg2dekImBPAxRu8VDU/u7px44Z12tWVK1fyzDPPYGdnR926dTl16lSa9vHnn38mez5r1iz8/PzYuXMnjRo1SnWbCRMm8OSTT/L2228D8OGHH7Jq1SomT57M1KlTH+EdiYiIVeDtcemnt0BiItilu/1WMkm6k/T27dtnQhgiIpKj3N3VXTVLsq1SpUqxePFiOnTowIoVKxg8eDAA4eHheHl5PdQ+IyMjAUs9m3vZvHkzQ4YMSbasZcuWLF68+J7bxMTEEBMTY30eFRX1UPGJiOQaBauAgyvcvAKXj4JvWaMjktvSnaR/8MEHmRGHiIjkJOH7Lffq6p6tjRgxghdeeIHBgwfz+OOPU6+epWvkypUrqV69err3l5iYyKBBg2jQoAGVKlW653rnz5/H398/2TJ/f3/Onz9/z23GjBnDqFGj0h2TiEiuZe8IhWvCyfUQukVJug1RnwYREcl4F5KSdFV2z86effZZQkND2bFjBytWrLAub9asGePGjUv3/vr168e+ffuYO3duRoYJwLBhw4iMjLTeTp8+neHHEBHJcQJvF48LVfE4W5LulnQ7O7v7Tremyu8iIqLK7jlHgQIFKFCgAGfOnAGgcOHC1K5dO9376d+/P7///jv//PMPhQsXfuAxL1y4kGzZhQsXKFCgwD23cXZ2xtnZOd1xiYjkakXuGpcuNiPdSfqiRYuSPY+Li2P37t18//336mYmIiJwIwKunbM89itvbCzySBITE/noo48YO3Ys0dHRAHh6evLmm28yfPhw7NJQZMhsNvPGG2+waNEi1q5dS/HixR+4Tb169VizZg2DBg2yLlu1apW1u72IiGSQwrUAE0ScgOhw8PAzOiLhIZL0du3apVj27LPPUrFiRebNm8dLL72UIYGJiEg2FX67FT1PEXB5uOJiYhuGDx/O9OnT+fTTT2nQoAEAGzZsYOTIkdy6dYuPP/74gfvo168fc+bMYcmSJXh6elrHlXt7e+Pq6gpAjx49KFSoEGPGjAFg4MCBNG7cmLFjx9KmTRvmzp3Ljh07+PbbbzPpnYqI5FKuecCvgqWWTOgWqPC00REJGTgmvW7duqxZsyajdiciItmVurrnGN9//z3fffcdr732GlWqVKFKlSq8/vrrTJs2jVmzZqVpH1OmTCEyMpImTZpQsGBB623evHnWdUJDQwkLC7M+r1+/PnPmzOHbb7+latWqLFiwgMWLF9+32JyIiDwka5d3zZduK9Ldkp6amzdvMnHiRAoVKpQRuxMRkewsXEXjcoqIiAjKlSuXYnm5cuWIiIhI0z7MZvMD11m7dm2KZZ06daJTp05pOoaIiDyCInVhx3QI3Wx0JHJbupN0Hx+fZIXjzGYz165dw83NjdmzZ2docCIikg1d0PRrOUXVqlWZPHkyEydOTLZ88uTJVKlSxaCoREQkQyVVeA/bA7E3wMnN2Hgk/Un6uHHjkiXpdnZ2+Pr6UqdOHXx8fDI0OBERyWYSEyH8oOWxurtne5999hlt2rRh9erV1qJtmzdv5vTp0yxfvtzg6EREJEPkKQKeAZair+d2QbHHjI4o10t3kt6rV69MCENERHKEyFCIjQZ7J8hX0uho5BE1btyYI0eO8NVXX3Ho0CEAnnnmGV5++WU++ugjGjZsaHCEIiLyyEwmKFIH9i+ydHlXkm64dCfpM2fOxMPDI8U4sfnz53Pjxg169uyZYcGJiEg2k1Q0zrcs2DsaG4tkiICAgBRV3Pfs2cP06dNVbV1EJKcIrHs7SVfxOFuQ7uruY8aMIX/+/CmW+/n58cknn2RIUCIikk0ljUdXV3cREZHsw1rhfZtl6JoYKt1JemhoKMWLF0+xvGjRooSGhmZIUCIikk2psruIiEj2418JHN0hJhIuHjQ6mlwv3Um6n58f//77b4rle/bsIV++fBkSlIiIZFNJ3d1V2V1ERCT7sHeAwjUtj0O3GBuLpH9MepcuXRgwYACenp40atQIgHXr1jFw4EA6d+6c4QGKiEg2EXcLLh+zPFZ392ztmWeeue/rV69ezZpAREQk6xSpByHrLEl6rZeMjiZXS3eS/uGHH3Ly5EmaNWuGg4Nl88TERHr06KEx6SIiudmlw2BOAFcf8CxgdDTyCLy9vR/4eo8ePbIoGhERyRJFbs+Xflot6UZLd5Lu5OTEvHnz+OijjwgODsbV1ZXKlStTtGjRzIhPRESyC2tX90qW6Vwk25o5c6bRIYiISFYrXAtMdnA1FKLOgVeA0RHlWulO0pOULl2a0qVLZ2QsIiKSnV3YZ7n3U9E4ERGRbMfZ0/JD+/l/LV3eK91/6JNknnQXjuvYsSP/+9//Uiz/7LPPUsydLiIiuUh4Uku6knQREZFsyToVm+ZLN1K6k/R//vmH1q1bp1jeqlUr/vnnnwwJSkREsqGk7u4qGiciIpI9JSXpqvBuqHQn6dHR0Tg5OaVY7ujoSFRUVIYEJSIi2cz1yxB93vLYr7yxsYiIiMjDCbydpJ/fCzHRxsaSi6U7Sa9cuTLz5s1LsXzu3LlUqKAujiIiuVL4fsu9TzFw9jA0FBEREXlI3oXAO9AyW8vZHUZHk2ulu3Dc+++/zzPPPMPx48d5/PHHAVizZg1z5sxhwYIFGR6giIhkA+rqLiIikjMUqQt7T0PoVijRxOhocqV0t6S3bduWxYsXc+zYMV5//XXefPNNzp49y19//UWpUqUyI0YREbF1SS3p/krSRUREsrXA2/Olh242No5c7KGmYGvTpg1t2rQBICoqip9//pm33nqLnTt3kpCQkKEBiohINnAhKUnXsCcREZFsrUg9y/2Z7ZAQD/YPPWu3PKR0t6Qn+eeff+jZsycBAQGMHTuWxx9/nC1bVAVQRCTXSYiH8IOWx+ruLiIikr35lQdnL4iNvtNTTrJUun4WOX/+PLNmzWL69OlERUXx3HPPERMTw+LFi1U0TkQkt7p4COJugJMn5NOwJxERkWzNzh4K14Ljayzj0gtWNTqiXCfNLelt27albNmy/Pvvv4wfP55z584xadKkzIxNRESyg3O7LPcB1cDuoTtoiYiIiK1I6vJ+Wj2ljZDmlvQ//viDAQMG8Nprr1G6dOnMjElERLKTszst94WCjI1DREREMkaRpOJxStKNkOYmjw0bNnDt2jWCgoKoU6cOkydP5tKlS5kZm4iIZAdnb7ekK0kXERHJGQoFgckeos7C1dNGR5PrpDlJr1u3LtOmTSMsLIxXXnmFuXPnEhAQQGJiIqtWreLatWuZGaeIiNiiuJt3KrsXqmFsLCIiIpIxnNzvjEU/vdXYWHKhdA8edHd3p3fv3mzYsIG9e/fy5ptv8umnn+Ln58fTTz+dGTGKiIitOr8XzAng4Q9ehYyORkRERDJKkbqWe82XnuUeqcJP2bJl+eyzzzhz5gw///xzRsUkIiLZRdJ49IAaYDIZG4uIiIhknMCkcelqSc9qGVKG197envbt27N06dKM2J2IiGQXKhonIiKSMyW1pIfvh1uRxsaSy2iuHBEReXjWonHVjY1DREREMpZnAfApBuZEOLPd6GhyFSXpIiLycG5egYjjlscBKhonIiKS4yTNl64u71lKSbqIiDycc7st9z7FwS2vsbGIiIhIxrOOS1fxuKykJF1ERB6OxqOLiIjkbEnj0s/uhIQ4Y2PJRZSki4jIwzl7uyVd86OLiIjkTPnLgkseiLthmXZVsoSSdBEReThqSRcREcnZ7Ozu6vK+xdhYchEl6SIikn5R5yD6PJjsoUAVo6MRERGRzFLkdpJ+Wkl6VlGSLiIi6ZfUiu5XAZzcjI1FREREMs/dFd7NZmNjySWUpIuISPpZ50fXeHS5v3/++Ye2bdsSEBCAyWRi8eLF911/7dq1mEymFLfz589nTcAiIpJcQHWwc7T0oLty0uhocgUl6SIikn7W8ehK0uX+rl+/TtWqVfnqq6/Std3hw4cJCwuz3vz8/DIpQhERuS9HVwioZnl8WvOlZwUHowMQEZFsJjHxzhzpKhonD9CqVStatWqV7u38/PzIkydPxgckIiLpV6QunNluKR5XtbPR0eR4akkXEZH0iTgOMVHg4Aq+5Y2ORnKoatWqUbBgQVq0aMHGjRsfuH5MTAxRUVHJbiIikkECb8+XrgrvWUJJuoiIpE9SV/eCVcFeHbIkYxUsWJCpU6fy66+/8uuvvxIYGEiTJk3YtWvXfbcbM2YM3t7e1ltgYGAWRSwikgsUuZ2kXzwIN68YG0suoKsrERFJHxWNk0xUtmxZypYta31ev359jh8/zrhx4/jxxx/vud2wYcMYMmSI9XlUVJQSdRGRjOKeH/KVgsvH4PQ2KNPS6IhyNLWki4hI+liLxmk8umSN2rVrc+zYsfuu4+zsjJeXV7KbiIhkoKL1LffH/zI2jlxASbqIiKRdfCyc32t5HFDd2Fgk1wgODqZgwYJGhyEikruVedJyf3i55kvPZDaRpH/11VcUK1YMFxcX6tSpw7Zt29K03dy5czGZTLRv3z5zAxQREYvw/ZAQAy55IG8Jo6ORbCA6Oprg4GCCg4MBCAkJITg4mNDQUMDSTb1Hjx7W9cePH8+SJUs4duwY+/btY9CgQfz111/069fPiPBFRCRJiabg4AJXQyH8gNHR5GiGJ+nz5s1jyJAhfPDBB+zatYuqVavSsmVLwsPD77vdyZMneeutt2jYsGEWRSoiIsnGo5tMxsYi2cKOHTuoXr061atbel4MGTKE6tWrM2LECADCwsKsCTtAbGwsb775JpUrV6Zx48bs2bOH1atX06xZM0PiFxGR25zcLIk6wKHlxsaSw5nMZmP7KtSpU4datWoxefJkABITEwkMDOSNN97g3XffTXWbhIQEGjVqRO/evVm/fj1Xr15l8eLFaTpeVFQU3t7eREZGaryaiEh6Le4HwbOh0dvw+HtGR5Nj6Lsp4+kzFRHJBDu/h98GQEANePlvo6PJVtLzvWRoS3psbCw7d+6kefPm1mV2dnY0b96czZs333O70aNH4+fnx0svvfTAY2jeVBGRDKSicSIiIrlX2VaACc7tgqgwo6PJsQxN0i9dukRCQgL+/v7Jlvv7+3P+/PlUt9mwYQPTp09n2rRpaTqG5k0VEckgMdfg4iHL4wBNvyYiIpLrePhB4ZqWx0f+MDaWHMzwMenpce3aNbp37860adPInz9/mrYZNmwYkZGR1tvp06czOUoRkRwqbA9gBq/C4On/wNVFREQkByrb2nJ/WEl6ZnEw8uD58+fH3t6eCxcuJFt+4cIFChQokGL948ePc/LkSdq2bWtdlpiYCICDgwOHDx+mZMmSybZxdnbG2dk5E6IXEcllrEXjNPWaiIhIrlW2NawZBSfWQUw0OHsYHVGOY2hLupOTE0FBQaxZs8a6LDExkTVr1lCvXr0U65crV469e/dap3IJDg7m6aefpmnTpgQHB6sru4hIZtJ4dBEREfEtCz7FLVOyHv/L6GhyJENb0sEyFUvPnj2pWbMmtWvXZvz48Vy/fp0XX3wRgB49elCoUCHGjBmDi4sLlSpVSrZ9njx5AFIsFxGRDHbudku6xqOLiIjkXiYTlGsDmydburxXeNroiHIcw5P0559/nosXLzJixAjOnz9PtWrV+PPPP63F5EJDQ7Gzy1ZD50VEcp7rl+BqKGCCgGpGRyMi/9/enYdHVZ59HP/OZE/IBiF7WAMB2XcCKLIoWxXcUGsFrbvihrZKW0VrX3HXigpqRWqtotiKC4gFJICAIhAQEELYwhKyEMi+MnPeP4YEIgkQSHJmJr/Pdc01Z848Z3I/OTN5cs+zHBERMyWMcSTpOxeD7Th4mJ5WuhWn+G1OmTKFKVOm1PhcUlLSGY+dO3du/QckIiLVVc5HD+sAvsHmxiIiIlIHv6Tn85+NB0nef4w/j7uIPq1DzQ7J9cUNBL9QKDkKB9dB60FmR+RWnCJJFxERJ6f56CIi4kKOFJbxxaZ0/rPhIL8czq/a/8inm1j80CX4enmYGJ0b8PCEDqPg53mQskhJej3TOHIRETk7zUcXEREnV37czuKtGdzxwXoGPruMZ77+hV8O5+PlYWFM10jCA33Yl1PM7BW7zQ7VPSSMcdzvWASGYW4sbkY96SIicmaGoZ50ERFxSoZhsC09n882HOSLTYc4VlxR9Vz32GCu7RPLFd2jCQ3w5uuf05nyUTJvJe1mQs8Y2oQFmBi5G4gfAR7ecHQ3HEmFlh3NjshtKEkXEZEzy02D4hywekGkrqQhIiLmyyooZUHyIf6z4RApmQVV+8MDfbiqVwzX9ImlY0RgtWPGdYvikw4HWJV6hCe/3MY/b+2HxWJp7NDdh08gtL0Edi11DHlXkl5vlKSLiMiZVS4aF9kVPH3MjUVERJqs0goby7Zn8dmGA6xMPYLN7hhi7e1p5fKLIrimTywXx4fh6VHzjF6LxcJfx3dl1GsrWbkzm0VbMhjXPaoxq+B+EsacTNKHPGR2NG5DSbqIiJyZhrqLiIhJDMNg88E8PttwgC83pZNferzquV6tQri2Tyy/6RZNsL/XOb1e27AA7hnanr8vS+WvX2/jko5hBPqe27FSg45jYOEjcGAdFGZDs5ZmR+QWlKSLiMiZpSc77rVonIiINJKMvFI+Tz7EZxsOsDu7qGp/ZJAvV/d2DGdv37LZeb32PZe2Z8GmQ6TlFPPa0lSe+M1F9RV20xMcA1E94fAmSP0Wev3O7IjcgpJ0ERGpnd0G6Zsc2+pJFxGRBlRaYWPp9kzmrz/IqtRsToxmx8fTyuiukVzbJ5ZB7cPwsF7YPHJfLw/+Or4rk+esY+6afVzTO5aLooPqoQZNVMJYR5K+Y5GS9HqiJF1ERGqXnQIVReDdDMI6mB2NiIi4GcMw2HIo78Tq7OnklZxcnb1v61Cu7RPL2O5RBNXzkPShHVsyrlsUC7cc5i8LtvDZ3YOwXmDy32QljIGkZ2H3d1BRAl5+Zkfk8pSki4hI7Srno0f3AquHubGIiIjbyC4o44tNh5i//mC11dmjgh3D2a/tE0fbBr5E2hO/uYiklCw27s/l0/UHuKF/qwb9eW4rshsEx0HeAdiTdPL66XLelKSLiEjt0k+s7B7dy9w4RETE5VXY7Hy3I4v56w+SlJLF8VNWZx/VJZLr+sQyOP7Ch7Ofq8hgXx6+rCN/W7id5xbv4PIukTQP8G6Un+1WLBZHYr7uHccq70rSL5iSdBERqZ1WdhcRkQu0/XA+n204yILkQ+QUlVft7xHnWJ39yu7nvjp7fbtlUBs+23CQHRkFzFi0nRev62FKHC6vKklfDHY7WGu+DJ6cGyXpIiJSs4pSyNzm2I7Ryu4iInLucovL+WJTOvM3HGDrofyq/WHNfE4MZ4+lY0SgiRE6eHpY+b+runLNrLXM33CQif3i6NemudlhuZ7WQ8AnCIqyHF/wx/UzOyKXpiRdRERqlrEF7MchoKVjrpmIiMgZHLfZWZV6hPkbDrD0lyzKbXYAvDwsjOgUwXV9YxnasSWeHs7Vy9qndXNu6BfHvJ8O8JfPt/L1A0PwcrIYnZ6nN8SPhG3/dQx5V5J+QZSki4hIzU4d6m7RirciIlKzjLxS/vXDPuavP0hWQVnV/ouigriubyzje8Y4/Vzvx0Z34tttGaRkFjB39T7uuKSd2SG5noSxJ5L0b2DkdLOjcWlK0kVEpGZVi8ZpqLuIiJxuy8E83vt+D1//fLhqEbhQfy/G94zhur6xdIkONjnCcxca4M20MZ35439+5tWlOxnXPYroEF1KrE46jASrJ2Rvh6N7oLm+6DhfStJFRKRmWjRORER+xWY3WPJLJnO+38u6fUer9vdv05xbBrdhZOcIvD1dc6j4tX1i+XT9AdanHeOvX/3C7JvV/tWJXyi0HgR7Vzp60xPvMzsil6UkXURETleSCzm7HNu6/JqISJNXWHacT386wNw1+9h/tBgAT6uF33SP4rYh7egW6zq95rWxWi387aqujHv9exZvy2D5jiyGdQo3OyzXkjBWSXo9UJIuIiKnS0923Ie2gYAWpoYiIiLmOXismH+u2ce8dQcoKDsOQLCfFzcNaMWkxDZEBvuaHGH96hQZxO8Ht+HdVXuZ/uU2Etu3wNfLw+ywXEfCGFj8OKStgeKj4K+V8s+HknQRETmd5qOLiDRpG9KOMef7vXyz9TAnppvTLiyAW4e05ZreMfh7u28a8dDIjny1+TD7jxbz5vJdPHJ5gtkhuY7QNhDeBbK2QeoS6HG92RG5JPf9dImIyPk7dCJJ13x0EZEm47jNzjdbM3jv+71sOpBbtX9wfAtuG9KWSzuGY7W6/9U+Anw8mX7FRdzz7428vWIPE3rF0L5lM7PDch0JYxxJespCJennSUm6iIicripJV0+6iIi7yyupYN66/fxzzT7S80oB8PawMr5nNL8f0pbOUUEmR9j4RneN5NKEliSlZPPkF1v58LYBWHQ50nPTaSysegl2LYPjZeDpY3ZELkdJuoiIVJefDgXpYLFCVA+zoxERkQay70gR76/ey/wNBykutwHQIsCb3w1sze8GtqZlYNNNriwWC3+9siuXvbqC1bty+HJzOuN7xpgdlmuI6gXNIqEwA/atgviRZkfkcpSki4hIdZW96C07g3eAubGIiEi923wglzeW72Lp9kyME/PNEyICuW1IW67sGa2F0k5o1cKf+4bF88qSnfxt4XaGdQonyNfL7LCcn9XqGPK+4X3YsUhJ+nlwzYsYiohIw0nXUHcREXe0ft9RJs1Zx/g3V7PkF0eCPiyhJR/eNoDFD13MxH5xStB/5a6h7WgXFkB2QRmv/G+n2eG4joSxjvuUb6j6JkjOmXrSRUSkukMbHPdaNE5ExOUZhsEPe47y+rJU1u7JAcDDamF8z2juvbQ98eGBJkfo3Hw8Pfjr+K787r0f+WDtPq7tE0vXGNe/JnyDa3sJeAU4ps8d3gzRPc2OyKWoJ11ERE6y209eI1096VIPVq5cyRVXXEF0dDQWi4UFCxac9ZikpCR69+6Nj48P8fHxzJ07t8HjFHE3hmGwcmc2E99ey43v/sDaPTl4eVi4oV8cyx+5lFcm9lSCfo6GdAjjih7R2A3484Kt2OzqGT4rL1+IH+7YTllkbiwuSEm6iIicdHQPlOaBpy+EX2R2NOIGioqK6NGjB2+++eY5ld+7dy/jxo1j2LBhbNq0iYceeojbb7+db7/9toEjFXEPhmGwbHsmE95aw6Q56/hp3zG8PazcPLA1SX8YxnPXdKdVC3+zw3Q5T4zrTDMfTzYfyOXjdfvNDsc1VA15V5JeVxruLiIiJ1XOR4/sDh5aHEcu3JgxYxgzZsw5l589ezZt27bl5ZdfBqBz5858//33vPrqq4waNaqhwhRxeXa7wf9+yWDmd7vYlp4PgI+nlZsGtOauoe2ICPI1OULXFh7kyyOXd+Tpr37hhcU7GN01krBmTXf1+3PSYZTjSjEZWyD3AITEmR2Ry1BPuoiInKT56GKytWvXMnJk9ZWAR40axdq1a894XFlZGfn5+dVuIk2BzW7w1eZ0xvx9FXd/uJFt6fn4e3tw1yXt+P6x4Tx5xUVK0OvJzQNb0yU6iPzS4zy7aLvZ4Ti/gBYQN9CxnfKNubG4GCXpIiJy0iGt7C7mysjIICIiotq+iIgI8vPzKSkpqfW4GTNmEBwcXHWLi1OPjbi34zY7/914kMtfXcH9HyeTkllAoI8nU4bF8/1jw5k2tnOTvs55Q/D0sPK3CV2xWOC/Gw/xw4mF+OQMEk6MpNKQ9zpRki4iIg62Csj42bGtnnRxMdOmTSMvL6/qduDAAbNDEmkQ5cftfPLTfka8soKpn25md3YRwX5ePDyyI98/PpxHRyXQPMDb7DDdVq9WodzYvxUATyzYSvlxu8kRObnKeen7vneseSPnRHPSRUTEIesXOF4KvsHQvJ3Z0UgTFRkZSWZmZrV9mZmZBAUF4efnV+txPj4++Pio11DcV9lxG/PXH2RW0m4O5TpGlTQP8Ob2i9ty88DWBPpqHZHG8tioTny7NYPUrELeXbWH+4bFmx2S8wqLh7COcGQn7FoKXa8xOyKXoCRdREQcKuejR/cGi8XcWKTJSkxMZNGi6sMilyxZQmJiokkRiZirtMLGx+v28/aKPWTklwIQ1syHuy5px00DW+HvrX/nG1uwvxd/GtuZR+Zv5rWlO7m4QxjdY0PMDst5JYxxJOkp3yhJP0ca7i4iIg5Vi8ZpPrrUn8LCQjZt2sSmTZsAxyXWNm3axP79jksYTZs2jUmTJlWVv/vuu9mzZw9//OMf2bFjB2+99RaffvopDz/8sBnhi5imuPw4767cw5Dnl/P0V7+QkV9KZJAvT11xEd8/Now7LmmnBN1EV/eOYUzXSCpsBlM+Sia/tMLskJxX5ZD31P85ptbJWemTLSIiDoeSHfeajy71aP369QwbNqzq8dSpUwGYPHkyc+fO5fDhw1UJO0Dbtm1ZuHAhDz/8MH//+9+JjY3lH//4hy6/Jk1GYdlx/rU2jXdX7eFoUTkAMSF+3DusPdf2icXH08PkCAXAYrHw3DXd+flgHvuPFvOn/25h5o29sGgk2uli+4F/GBQfgbQ10G6o2RE5PSXpIiIC5UWQfeJyMtHqSZf6c+mll2IYRq3Pz507t8ZjkpOTGzAqEeeTX1rBP1fv473Ve8ktdvQ2tmruz5Rh8VzVOwYvDw2AdTbBfl7M/G0vJs5ey9c/H2ZIfBg3nFhUTk5h9YCOo2HTh44h70rSz0qfdhERgcObwbBDYDQERZkdjYhIk5FbXM4rS3Yy+LnveHnJTnKLK2gXFsArE3vw3SNDmdgvTgm6E+vdKpRHRyUA8NRX29iZWWByRE6q6lJsC+EMX9yKg3rSRURE89FFRBrZ0aJy/rFqDx+sTaOw7DgAHcKbcf+IDozrFoWHVcOmXcWdF7djze4cVu7M5r5/b+TLKUPw89a0hGraDwNPX8jd77iaTEQXsyNyavpaTkRE4NBGx72SdBGRBpVdUMazi7Yz+LnveCtpN4Vlx+kUGchbN/Xm24cu4coe0UrQXYzVauGViT1oGehDalYhf/16m9khOR/vAGh3qWM7ZdEZi4qSdBERgVN60rVonIhIQ8jML+Xpr7Yx5PnveGflHkoqbHSLCeadm/uw6IGLGdstCquSc5cV1syH167vicUCH687wFeb080OyflUDnnfoST9bDTcXUSkqSvKgdw0x3ZUT1NDERFxN4dyS5idtJtP1h+g/LgdgJ5xITw4ogOXJrTUauBuZHB8GFOGxTPzu11M++8WuscG07pFgNlhOY+OY4AHIX0j5B/WGjhnoCRdRKSpSz8x1L1FB/ALMTUUERF3ceBoMW8l7eKzDQepsDkWyurXJpQHRnRgSHyYknM39eCIDvywJ4ef9h3j/o+T+ezuQXh7avAyAIERENMXDq2HnYuh761mR+S09I4REWnqtGiciEi92XekiD/M38ylLyXx8boDVNgMEtu14OM7BvLpXYlc3EG95+7M08PK32/oRYi/Fz8fzOOFxTvMDsm5VK3yriHvZ6KedBGRpq5q0TjNRxcROV+7sgp5c/kuvth0CPuJK0xd3CGMB0Z0oF+b5uYGJ40qOsSPF6/twR0frOcf3+9lUHwLhneKMDss59BpHHz3DOxZAWWF4NPM7IicknrSRUSaMsM42ZMerZ50EZG62plZwP0fJ3PZqyv4PNmRoA/vFM7n9w7iX7cNUILeRF12UQS3Dm4DwCOfbuZwXom5ATmLlp0gtA3YymDPcrOjcVpK0kVEmrK8A1B8BKyeENnN7GhERFzGL+n53PvvDVz+6kq+2pyOYTgSs6+mDGHOLf3o1SrU7BDFZI+P6UTXmCCOFVfw4LxN2CqHWDRlFgskjHVsa5X3WilJFxFpyip70SO6gJevubGIiLiALQfzuOOD9Yx9fRWLtmQAMKZrJAsfGMK7k/rSLTbY5AjFWfh4ejDzxt4EeHuwbu9RXl+WanZIzqEySd+5GOw2c2NxUpqTLiLSlGk+uojIOUnef4yZ3+3iux1ZgKND8Dfdo5kyLJ6EyECToxNn1TYsgGev7saD8zYx87tUBrZrQWL7FmaHZa5WieAbAiVH4cCP0HqQ2RE5HfWki4g0ZUrSRUTOaEPaUSbNWcdVb63hux1ZWC1wVa8Yljw8lJk39lKCLmc1vmcM1/WJxW7Ag/OSySksMzskc3l4QsdRjm2t8l4j9aSLiDRVdhsc3uTY1qJxIiLV/LAnh5nfpbJ6Vw4AHlYLV/WK4b5h8bQNCzA5OnE1T4/vQvKBXHZlFfLI/M3MmdwPq7UJX4ovYQz8/AmkfAOX/63ux9vtjp74omwozHLcF2VD0RHwDoDmbR0L1IW2AT/XWx9CSbqISFN1ZCeUF4JXALRMMDsaERHTGYbBmt05/H1ZKuv2HgXA02rhur6x3DM0nlYt/E2OUFyVv7cnb/y2F+PfWE1SSjbvfb+XOy5pZ3ZY5mk/AqxekLMLsndCy45wvOyUpPsIFJ1IvgsrE/AT+wuzHIveGvZz+1m+wScS9lMS98pbcJyjZ9/JOF9EIiLSOCqHukf3BKuHqaGIiJjJMAxWph7h9WWpbEg7BoC3h5WJ/WK5e2h7YkOVnMuF6xQZxJNXXMSfP9/K84t30K9tc3rGhZgdljl8g6DtJbB7GcwdC8fLoSyv7q/jFwoB4RDQEpq1BP8wKMuHY/vg6F5HYl+aB4c3O26/ZvGAkLhfJe+n9sKHXEAlz5+SdBGRpqpyZfcYDXUXkaZrQ9pR/m/hdjbuzwXA29PKb/u34q6h7YgK9jM3OHE7v+3fitW7jrBoSwb3f7yRhQ9cTJCvl9lhmaPrNY4kvSj75D6rpyPhrrw1C4eAMEcifup2QEvHtsdZfnflRXAszZG0V932nrhPc1yvvXJ/TXxDHMn6de9D88Yb+aAkXUSkqapM0jUfXUSaoH1Hinh+8Q6+2eq4jJqvl5WbBrTmrkvaER6kS1JKw7BYLMy4ujs/H8zjwNESpv1nC2/8thcWSxOcn97jRghp5bhUQsCJBNwv1PG4vngHQMRFjtuv2e1QmHGy171aIr/vRC98rmP9Ht+Q+ovpHChJFxFpiipKIXObY1sru4tIE3K0qJzXl6Xy4Q9pHLcbWC0wsW8cD1/WkQgl59IIgv28eOO3vbl21hoWbjnM4HVh/HZAK7PDanxWK7S92NyfHxTtuNV0GbiyQshNc/S4N/Lic0rSRUSaosytYK8A/xaOb7FFRNxcaYWNf67ZxxvLd1FQehyASxNaMm1MZ11GTRpdz7gQ/jg6gWcX7eDpr7bRu3UInSKDzA5LTuXTDCK6OG6NTEm6iEhTdOr10ZviEDsRaTLsdoOvfk7nhcUpHMotAaBzVBB/HtuZIR3CTI5OmrLbh7Rjze4cklKymfJRMl9OGYy/t9IzAavZAYiIiAk0H11EmoC1u3MY/+ZqHpy3iUO5JUQG+fLSdT34+v4hStDFdFarhZev60F4oA+7sgp5+stfzA5JnIS+qhERaYrST+lJFxFxM7uyCnjumx0s3Z4FQIC3B/cOi+f3g9vi561LTorzaNHMh9du6MlN//iRT9YfoENEM0Z2jiA21A9PD/WnNlVK0kVEmprMX+DITse2Lr8mIm4ku6CM15buZN5PB7DZDTysFm7sH8eDIzrSMtDH7PBEajSofRj3D+/A68tS+dvC7fxt4XY8rRZiQ/1oExZAmxYBtGnhT+sT27GhfngpgXdrStJFRJqSrf+BL6Y4tmP6Oi53IiLi4krKbbz3/R5mJe2mqNwGwMjOETw+phPx4c1Mjk7k7B4YHk9ZhY2klGz25RRRdtzOvpxi9uUUA9nVynpUJvAnkveqRD5MCby7UJIuItIU2CpgyXT44U3H47ZD4do55sYkInKBbHaD/248yMv/20lGfikA3WOD+dPYzgxs18Lk6ETOnaeHlWljOzNtbGfsdoPMglL2HSkmLaeIvTlFpB0pZl9OEftyiiitsJOWU0xaTjErfvU6HlYLMSGVPfD+xIb6EeLvTYifl+Pe34sQPy+C/b3w8dTUD2elJF1ExN0VZML8W2D/GsfjIVNh+F/AqsZZRFzXqtRsnl20g+2H8wGICfHjj6MTuKJ7NFarrlohrstqtRAV7EdUsB+J7at/2WQYBpn5ZezLKXIk8JWJ/JEi0nKKKamwsf9oMfuPFrPyLD/Hz8uDUH8vgquSeMct2O9kMl/5ODTAixA/bwJ9PfHysOJptehz1oCUpIuIuLP9P8Cnk6EwA7wD4apZ0PkKs6MSETlvWw7m8eL/Uli50zEEONDXk/uHxzMpsQ2+XvryUdybxWIhMtiXyGDf00aLGIZBVkEZ+04k7HtzijicW0JeSQW5JRXkFTvuc4vLsRtQUmGjJM9Gel7pecVitYCn1YqH1YKn1YKnhwUPq7Vq29NqwcNqwcvj1DIntz2sFnw8rcSG+tM+vBkdwpsRH96MFgHeWJr45WGVpIuIuCPDgHXvwLd/AvtxaNkJrv83hMWbHZmIyHnZmVnAK//byeJtGQB4eVj43cDWPDC8A6EB3iZHJ2I+i8VCRJAvEUG+DDjDdA+73aCg7PiJpL2c3OLKJN6xfezE/lOT+rySCnKLKzhuN06+jgHlNjvY6rceIf5exLdsRoeIZrRv6UjcO0QEEh3s22SSdyXpIiLuprwIvnoQtsx3PO5yNVw5E3y0eJKIuJ59R4p4belOvticjmGAxQITesbw4IgOtAkLMDs8EZdjtVoI9vMi2M+LVvif83GGYVBSYaPCZmCzGxy32zletW1w3GbnuL3mxxU2+yn7Hcfa7MaJ+fVFpGYVsiurkAPHisktrmB92jHWpx2r9vP9vT2qkvZTb62b+7vd5eqUpIuIuJOc3fDJzZC1DSwecPnfYOA9jv9qRURcyKHcEmYuS2X+hoPYTvTejekaycOXdaRjRKDJ0Yk0PRaLBX/vhk0fSyts7M52JOy7swqrkvd9OUUUl9vYciiPLYfyqh3j5WGhbViAI2lv2YxerUIZ2K4Fft6uO/1FSbqIiLtI+Qb+exeU5UFAOEz8J7QeZHZUIiJ1klVQylvLd/PRj/sdQ2mBYQktmXpZAt1ig02OTkQakq+XB12ig+kSXf2zXmFzrGi/K6uwKolPzSpgd1YRJRU2dmYWsjOzsKq8t6eVAW2bM7RjSy5NaEn7ls1caqi8UyTpb775Ji+++CIZGRn06NGDmTNn0r9//xrLvvvuu3zwwQds3boVgD59+vDss8/WWl5ExO3ZbZA0A1a+6HgcNxCumwtBUaaGJSJSF8eKypm9cjf/XLOP0gpHcj6wXXMevTyBvm2amxydiJjJy8NaNbz9VHa7QXpeCaknet5TMgpYszuHQ7klrEo9wqrUI/xt4XZiQvwYmtCSoR1bMqh9CwJ9vUyqybkxPUn/5JNPmDp1KrNnz2bAgAG89tprjBo1ipSUFMLDw08rn5SUxI033sigQYPw9fXl+eef5/LLL2fbtm3ExMSYUAMRERMVH4X/3Aa7v3M8HnA3XPYMeGoRJRFxDQWlFfxj1V7e+34vhWXHAegZF8IfRiUwqH0Ll+r9EpHGZbVaiA31JzbUn2EJjtzRMAx2ZxexYmc2SSlZ/Lj3KIdyS/jox/189ON+PK0W+rQO5dKEcIZ2bEnnqECn+ztjMQzDOHuxhjNgwAD69evHG2+8AYDdbicuLo7777+fxx9//KzH22w2QkNDeeONN5g0adJZy+fn5xMcHExeXh5BQUEXHL+IiGnSk+GTSZC3Hzz94MrXoftEs6OS86C2qf7pd+r8isuP88HaNGav2E1ucQUAnaOCePTyjgzvFO50/zSLiGsqKbfxw94cVqRks2JnNnuPFFV7PjzQh0tODIsfEh9GiH/DdHTUpV0ytSe9vLycDRs2MG3atKp9VquVkSNHsnbt2nN6jeLiYioqKmjevOZhUGVlZZSVlVU9zs/Pv7CgRUScwcYPYOGjYCuD0LZw/YcQ2dXsqERqVZepbXPnzuXWW2+tts/Hx4fS0vO7lq84l7LjNj7+cT9vLN/NkULH/2jtWwYw9bIExnSNxGpVci4i9cfP24NhCeFVPe1pOUWs3JlNUko2a3bnkFVQxmcbDvLZhoNYLY6RPEM7hnNpQku6xQSb8jfJ1CT9yJEj2Gw2IiIiqu2PiIhgx44d5/Qajz32GNHR0YwcObLG52fMmMHTTz99wbGKiDiFilL45o+w8Z+Oxx3HwFWzwS/E1LBEzqSuU9sAgoKCSElJqXqsXlXXV2Gz858NB3l9WSrpeY4vXGJD/XhoZEcm9Ix2u0soiYhzat0igJsTA7g5sQ1lx22s33eMpJQsVuzMZmdmIRv357Jxfy6vLt1J8wBvLu4QxtTLOtK6ReNd8tH0OekX4rnnnmPevHkkJSXh6+tbY5lp06YxderUqsf5+fnExcU1VogiIvUn9wB8erNjmDsWGP5nGPIIWPWPrTi3V155hTvuuKOqd3z27NksXLiQOXPm1Dq1zWKxEBkZ2ZhhSgOx2w2+3JzOa0t3si+nGICIIB/uH96BiX3j8PbU3zARMYePpweD48MYHB/Gn8dBem5JVS/76l1HOFpUzheb0vnz2M6NGpepSXpYWBgeHh5kZmZW25+ZmXnWhvmll17iueeeY+nSpXTv3r3Wcj4+Pvj4+NRLvCIiptm9HD77PZQcBb9QuOY9iB9hdlQiZ3W+U9sKCwtp3bo1drud3r178+yzz9KlS5day2t6m/MxDIMVO7N5fnEK2w87zkeLAG/uubQ9vxvYGl8v172GsYi4p+gQP27o34ob+reiwmYneX8uWw/lER5Uc4dwQzH1q0tvb2/69OnDsmXLqvbZ7XaWLVtGYmJirce98MILPPPMMyxevJi+ffs2RqgiIuZJXQofXu1I0KN6wp0rlKCLyzjT1LaMjIwaj0lISGDOnDl88cUXfPjhh9jtdgYNGsTBgwdr/TkzZswgODi46qZRc+bafCCX3777I7e8/xPbD+cT6OvJo5d3ZOUfh3H7xe2UoIuI0/PysNK/bXN+P6Rto/9s04e7T506lcmTJ9O3b1/69+/Pa6+9RlFRUdWQuEmTJhETE8OMGTMAeP7553nyySf56KOPaNOmTVUD36xZM5o1a1brzxERcUllhfD1Q2DYoes1MP4t8Grcb3NFGltiYmK1L+sHDRpE586defvtt3nmmWdqPEbT25zD3iNFvPRtCgu3HAbA28PK5EGtuffSeEIDdGlIEZFzYXqSfv3115Odnc2TTz5JRkYGPXv2ZPHixVXfuO/fvx/rKfMtZ82aRXl5Oddee22115k+fTpPPfVUY4YuItLwlj8LeQcgpBVcOVMJuricC5naVsnLy4tevXqxa9euWstoepu5sgpKeX1ZKvPWHeC43cBigat7xfLwZR2IDfU3OzwREZdiepIOMGXKFKZMmVLjc0lJSdUe79u3r+EDEhFxBunJ8OMsx/a4V8G78VYVFakvp05tmzBhAnByalttbf+v2Ww2tmzZwtixYxswUjkfBaUVvLtyD++u2ktJhQ2AYQkteWxMJzpF6vr0IiLnwymSdBER+RXbcfjygRPD3K+FDjVfZlLEFdR1attf//pXBg4cSHx8PLm5ubz44oukpaVx++23m1kNOUX5cTv//jGNmd/t4mhROQA94kJ4fHQnEtu3MDk6ERHXpiRdRMQZ/TgLMn4G32AYPcPsaEQuSF2nth07dow77riDjIwMQkND6dOnD2vWrOGiiy4yqwpygt1u8NXP6bz0vxQOHC0BoF1YAH8YlcDorpG6nr2ISD2wGIZhmB1EY8rPzyc4OJi8vDyCgjQMS0Sc0LE0eGsgVBQ75qH3nmR2RNLA1DbVP/1O69+q1Gye+2YH29Idl1NrGejDQyMd1zr38tC1zkVEzqQu7ZJ60kVEnIlhwMKpjgS99WDodbPZEYlIE7flYB7PL97B97uOANDMx5O7h7bj90Pa4u+tfyVFROqb/rKKiDiTrf+BXUvBwxt+8xpo6KiImCQtp4iX/reTrzanA+DlYeHmgW2YMjye5rqcmohIg1GSLiLiLEqOweLHHdsXPwItO5obj4g0SbnF5by6ZCf//nF/1eXUJvSMYeplHYlrrsupiYg0NCXpIiLOYsmTUJQNYR1hyMNmRyMiTdAv6fnc9eH6qkXhhnZsyR9HJ9AlOtjkyEREmg4l6SIizmDfatj4gWP7ir+Dp4+58YhIk/PV5nT+8NlmSivsxDX347mruzM4PszssEREmhwl6SIiZjteBl896NjuPRlaDzI3HhFpUmx2gxcW7+DtlXsAuLhDGDNv7EWIv+adi4iYQUm6iIjZvn8VclIhIBwue9rsaESkCcktLuf+j5NZlepYuf2uoe3446hOeFi1aKWIiFmUpIuImCl7J6x62bE95jnwCzU3HhFpMrYfzueuf21g/9Fi/Lw8eOHa7lzRI9rssEREmjwl6SIiZrHbHcPcbeXQ4XLocrXZEYlIE/H1z+n8Yf7PlFTYiGvux9u/68tF0UFmhyUiIihJFxExT/K/YP8a8PKHsS/pmugi0uBsdoMXv01h9ordgGP++es39CJU1z0XEXEaStJFRMxQmAVLnnBsD/szhLY2Nx4RcXu5xeU8MG8TK3dmA3DXJe34w6gEPD2sJkcmIiKnUpIuImKGxY9DaR5E9YABd5sdjYi4uR0Z+dz5gWP+ua+XlReu7cGVmn8uIuKUlKSLiDS21CWw9T9gsTquie6hP8Ui0nAWbTnMo/M3U1xuIzbUj3du1vxzERFnpv8MRUQaU3kRfD3VsT3wXojuZW48IuK2bHaDl/+XwltJjvnng+Nb8MaNvTX/XETEySlJFxFpTEkzIG8/BMfBpdPMjkZE3FRecQUPzEtmxYn553de0o4/av65iIhLUJIuItJYDm+GtW85tse9Aj7NzI1HRNxSSkYBd/5rPWk5jvnnz1/TnfE9Y8wOS0REzpGSdBGRxmC3wZcPgGGDLldBx8vNjkhE3NA3Ww7zyIn55zEhfrwzqQ9dooPNDktEROpASbqISGP48W04vAl8gmH082ZHIyJuxmY3eGVJCm8ud8w/H9S+BW/8tjfNNf9cRMTlKEkXEWlouQfgu785ti97GgIjzI1HRNxKXkkFD85LJinFMf/89iFteXxMJ80/FxFxUUrSRUQakmHAwkegoghaJULvyWZHJCJuorTCxoc/pDEraTc5ReWafy4i4iaUpIuINKRfFkDqt2D1clwT3aqeLRG5MGXHbcxbd4A3l+8iq6AMgHZhAbx+Yy+6xmj+uYiIq1OSLiLSUEpy4ZvHHNsXT4WWCaaGIyKurcJm57MNB5m5LJX0vFIAYkL8eHBEB67uHaPh7SIibkJJuohIQ1n6FBRmQosOMGSq2dGIiIuy2Q0WJB/i78tS2X+0GIDIIF+mDI9nYt84vD2VnIuIuBMl6SIiDSFtLWx437F9xWvg5WtqOCLieux2g6+3HOa1pTvZk10EQFgzH+69tD2/HdAKXy8PkyMUEZGGoCRdRKS+HS+Hrx9ybPe6GdoMMTUcEXEthmHw7bZMXlu6kx0ZBQCE+ntx19D2TEpsjb+3/n0TEXFn+isvInKhSo5B+iZIT3bcDm2E/IMQ0BIu+6vZ0YmIizAMg6SUbF5eksLWQ/kABPp6csfF7bh1cBsCfb1MjlBERBqDknQRkboozYPDm08k5Jsc98f2nl7O09exmrt/80YPUUTqT1HZcXZlFRIV4ktYgA9Wq6Xef4ZhGKzelcPLS1JI3p8LQIC3B7cObssdF7cj2F/JuYhIU6IkXUSkNmUFcPhnOLzpZC95zq6ay4a2heheEN3TcR/VA3x1KSQRV7f1UB7Xv/MDAN4eVqJCfIkO9iMqxJeYED+iK2/BvkSH+BHgU7d/rdbtPcrL/0vhx71HAfD1sjI5sQ13DW1P8wDveq+PiIg4PyXpIiIA5cWQseVkMp6eDEd2AsbpZYNbnUzGKxNy9ZiLuKWSChuRQb5kFpRSbrOTllNMWk5xreWD/byqJe2O28ntiEAfPD2sJO8/xitLdrIq9Qjg+ALgtwNace+w9oQHaqFJEZGmTEn6hVj9OmyeZ3YUIg3gRGJqGPX0uAHiM4wT979+XNf7E8eXF4JhP/1HBcX8qoe8FwS0aKB6iYizuTQhnB/+NIIKm52MvFIO55WSnlvCodwS0nNLqj0uKD1OXkkFeSUVbD+cX+PrWS2OFdqzCsoA8LRamNgvjinD4okO8WvMqomIiJNSkn4hCjMha5vZUYhIfWkWAdG9TyblUT0hMMLsqETECXh5WIlr7k9cc/9ayxSUVnA4r/RkAp97SkKfV0JGXikVNoOsgjKsFrimdywPjOhwxtcUEZGmR0n6hehzK8SPNDsKkYZhqVwcyXL64zM9V2vZeg/wVz/n1H3nce8TqIRcRC5IoK8Xgb5edIwIrPF5u93gSGEZh3JLiAjyVc+5iIjUSEn6hQiLd9xEREREzsJqtRAe5Et4kOaci4hI7axmByAiIiIiIiIiDkrSRURERERERJyEknQRERFpcG+++SZt2rTB19eXAQMGsG7dujOWnz9/Pp06dcLX15du3bqxaNGiRopURETEXErSRUREpEF98sknTJ06lenTp7Nx40Z69OjBqFGjyMrKqrH8mjVruPHGG7nttttITk5mwoQJTJgwga1btzZy5CIiIo3PYhgNdiFjp5Sfn09wcDB5eXkEBQWZHY6IiIjbt00DBgygX79+vPHGGwDY7Xbi4uK4//77efzxx08rf/3111NUVMTXX39dtW/gwIH07NmT2bNn1/gzysrKKCsrq3qcn59PXFyc2/5ORUTEtdSlrVdPuoiIiDSY8vJyNmzYwMiRJy9ZarVaGTlyJGvXrq3xmLVr11YrDzBq1KhaywPMmDGD4ODgqltcXFz9VEBERKSRKUkXERGRBnPkyBFsNhsRERHV9kdERJCRkVHjMRkZGXUqDzBt2jTy8vKqbgcOHLjw4EVEREyg66SLiIiIy/Px8cHHx8fsMERERC6YetJFRESkwYSFheHh4UFmZma1/ZmZmURGRtZ4TGRkZJ3Ki4iIuBMl6SIiItJgvL296dOnD8uWLavaZ7fbWbZsGYmJiTUek5iYWK08wJIlS2otLyIi4k403F1EREQa1NSpU5k8eTJ9+/alf//+vPbaaxQVFXHrrbcCMGnSJGJiYpgxYwYADz74IEOHDuXll19m3LhxzJs3j/Xr1/POO++YWQ0REZFGoSRdREREGtT1119PdnY2Tz75JBkZGfTs2ZPFixdXLQ63f/9+rNaTg/sGDRrERx99xF/+8hf+9Kc/0aFDBxYsWEDXrl3NqoKIiEij0XXSRURETKa2qf7pdyoiIs5E10kXERERERERcUFNbrh75cCB/Px8kyMRERFxqGyTmtjgtgal9l5ERJxJXdr6JpekFxQUABAXF2dyJCIiItUVFBQQHBxsdhhuQe29iIg4o3Np65vcnHS73U56ejqBgYFYLJYLeq38/Hzi4uI4cOCAy893U12cj7vUA9ynLu5SD3CfurhLPQzDoKCggOjo6GoLqMn5U3t/OnepB7hPXdylHqC6OCN3qQe4R13q0tY3uZ50q9VKbGxsvb5mUFCQy75Zfk11cT7uUg9wn7q4Sz3AferiDvVQD3r9UntfO3epB7hPXdylHqC6OCN3qQe4fl3Ota3X1/UiIiIiIiIiTkJJuoiIiIiIiIiTUJJ+AXx8fJg+fTo+Pj5mh3LBVBfn4y71APepi7vUA9ynLu5SD3Fu7vI+c5d6gPvUxV3qAaqLM3KXeoB71eVcNLmF40RERERERESclXrSRURERERERJyEknQRERERERERJ6EkXURERERERMRJKEkXERERERERcRJK0s/izTffpE2bNvj6+jJgwADWrVt3xvLz58+nU6dO+Pr60q1bNxYtWtRIkdZuxowZ9OvXj8DAQMLDw5kwYQIpKSlnPGbu3LlYLJZqN19f30aKuHZPPfXUaXF16tTpjMc44zlp06bNafWwWCzcd999NZZ3pvOxcuVKrrjiCqKjo7FYLCxYsKDa84Zh8OSTTxIVFYWfnx8jR44kNTX1rK9b189afThTXSoqKnjsscfo1q0bAQEBREdHM2nSJNLT08/4mufzHm3IegDccsstp8U0evTos76us50ToMbPjcVi4cUXX6z1Nc04J+J6XL29V1vvXOejkqu292rr1dY3JLX1Z6ck/Qw++eQTpk6dyvTp09m4cSM9evRg1KhRZGVl1Vh+zZo13Hjjjdx2220kJyczYcIEJkyYwNatWxs58upWrFjBfffdxw8//MCSJUuoqKjg8ssvp6io6IzHBQUFcfjw4apbWlpaI0V8Zl26dKkW1/fff19rWWc9Jz/99FO1OixZsgSA6667rtZjnOV8FBUV0aNHD958880an3/hhRd4/fXXmT17Nj/++CMBAQGMGjWK0tLSWl+zrp+1+nKmuhQXF7Nx40aeeOIJNm7cyH//+19SUlK48sorz/q6dXmP1oeznROA0aNHV4vp448/PuNrOuM5AarV4fDhw8yZMweLxcI111xzxtdt7HMirsUd2nu19c51Piq5anuvtl5tfUNSW38ODKlV//79jfvuu6/qsc1mM6Kjo40ZM2bUWH7ixInGuHHjqu0bMGCAcddddzVonHWVlZVlAMaKFStqLfP+++8bwcHBjRfUOZo+fbrRo0ePcy7vKufkwQcfNNq3b2/Y7fYan3fW8wEYn3/+edVju91uREZGGi+++GLVvtzcXMPHx8f4+OOPa32dun7WGsKv61KTdevWGYCRlpZWa5m6vkfrW031mDx5sjF+/Pg6vY6rnJPx48cbw4cPP2MZs8+JOD93bO/V1jvX+ajkiu292vrTmd2uqK0/ndnnpL6pJ70W5eXlbNiwgZEjR1bts1qtjBw5krVr19Z4zNq1a6uVBxg1alSt5c2Sl5cHQPPmzc9YrrCwkNatWxMXF8f48ePZtm1bY4R3VqmpqURHR9OuXTtuuukm9u/fX2tZVzgn5eXlfPjhh/z+97/HYrHUWs5Zz8ep9u7dS0ZGRrXfeXBwMAMGDKj1d34+nzWz5OXlYbFYCAkJOWO5urxHG0tSUhLh4eEkJCRwzz33kJOTU2tZVzknmZmZLFy4kNtuu+2sZZ3xnIhzcNf2Xm29c50PcJ/2Xm29gzO2K2rrne+cnC8l6bU4cuQINpuNiIiIavsjIiLIyMio8ZiMjIw6lTeD3W7noYceYvDgwXTt2rXWcgkJCcyZM4cvvviCDz/8ELvdzqBBgzh48GAjRnu6AQMGMHfuXBYvXsysWbPYu3cvF198MQUFBTWWd4VzsmDBAnJzc7nllltqLeOs5+PXKn+vdfmdn89nzQylpaU89thj3HjjjQQFBdVarq7v0cYwevRoPvjgA5YtW8bzzz/PihUrGDNmDDabrcbyrnJO/vnPfxIYGMjVV199xnLOeE7Eebhje6+23rnORyV3ae/V1jtnu6K23vnOyYXwNDsAaVz33XcfW7duPescjcTERBITE6seDxo0iM6dO/P222/zzDPPNHSYtRozZkzVdvfu3RkwYACtW7fm008/Padv2JzRe++9x5gxY4iOjq61jLOej6aioqKCiRMnYhgGs2bNOmNZZ3yP3nDDDVXb3bp1o3v37rRv356kpCRGjBhhSkz1Yc6cOdx0001nXVTJGc+JSENSW++c1N47N7X1zqmptvXqSa9FWFgYHh4eZGZmVtufmZlJZGRkjcdERkbWqXxjmzJlCl9//TXLly8nNja2Tsd6eXnRq1cvdu3a1UDRnZ+QkBA6duxYa1zOfk7S0tJYunQpt99+e52Oc9bzUfl7rcvv/Hw+a42pstFOS0tjyZIlZ/xmvSZne4+aoV27doSFhdUak7OfE4BVq1aRkpJS588OOOc5EfO4W3uvtt7BWc5HJXdq79XWn84Z2xW19c53TupCSXotvL296dOnD8uWLavaZ7fbWbZsWbVvOE+VmJhYrTzAkiVLai3fWAzDYMqUKXz++ed89913tG3bts6vYbPZ2LJlC1FRUQ0Q4fkrLCxk9+7dtcblrOek0vvvv094eDjjxo2r03HOej7atm1LZGRktd95fn4+P/74Y62/8/P5rDWWykY7NTWVpUuX0qJFizq/xtneo2Y4ePAgOTk5tcbkzOek0nvvvUefPn3o0aNHnY91xnMi5nGX9l5tvXOdj19zp/Zebf3pnLFdUVvvfOekTsxdt865zZs3z/Dx8THmzp1r/PLLL8add95phISEGBkZGYZhGMbNN99sPP7441XlV69ebXh6ehovvfSSsX37dmP69OmGl5eXsWXLFrOqYBiGYdxzzz1GcHCwkZSUZBw+fLjqVlxcXFXm13V5+umnjW+//dbYvXu3sWHDBuOGG24wfH19jW3btplRhSqPPPKIkZSUZOzdu9dYvXq1MXLkSCMsLMzIysoyDMN1zolhOFbQbNWqlfHYY4+d9pwzn4+CggIjOTnZSE5ONgDjlVdeMZKTk6tWQX3uueeMkJAQ44svvjB+/vlnY/z48Ubbtm2NkpKSqtcYPny4MXPmzKrHZ/usmVGX8vJy48orrzRiY2ONTZs2VfvslJWV1VqXs71HG7seBQUFxqOPPmqsXbvW2Lt3r7F06VKjd+/eRocOHYzS0tJa6+GM56RSXl6e4e/vb8yaNavG13CGcyKuxR3ae7X1znU+TuWK7b3aerX1DUlt/dkpST+LmTNnGq1atTK8vb2N/v37Gz/88EPVc0OHDjUmT55crfynn35qdOzY0fD29ja6dOliLFy4sJEjPh1Q4+3999+vKvPrujz00ENV9Y6IiDDGjh1rbNy4sfGD/5Xrr7/eiIqKMry9vY2YmBjj+uuvN3bt2lX1vKucE8MwjG+//dYAjJSUlNOec+bzsXz58hrfT5Xx2u1244knnjAiIiIMHx8fY8SIEafVsXXr1sb06dOr7TvTZ82Muuzdu7fWz87y5ctrrcvZ3qONXY/i4mLj8ssvN1q2bGl4eXkZrVu3Nu64447TGmBXOCeV3n77bcPPz8/Izc2t8TWc4ZyI63H19l5tvXOdj1O5Ynuvtl5tvVl1qdTU23qLYRjG+fbCi4iIiIiIiEj90Zx0ERERERERESehJF1ERERERETESShJFxEREREREXESStJFREREREREnISSdBEREREREREnoSRdRERERERExEkoSRcRERERERFxEkrSRURERERERJyEknQRaXQWi4UFCxaYHYaIiIg0ELX1IudPSbpIE3PLLbdgsVhOu40ePdrs0ERERKQeqK0XcW2eZgcgIo1v9OjRvP/++9X2+fj4mBSNiIiI1De19SKuSz3pIk2Qj48PkZGR1W6hoaGAY3jarFmzGDNmDH5+frRr147PPvus2vFbtmxh+PDh+Pn50aJFC+68804KCwurlZkzZw5dunTBx8eHqKgopkyZUu35I0eOcNVVV+Hv70+HDh348ssvG7bSIiIiTYjaehHXpSRdRE7zxBNPcM0117B582ZuuukmbrjhBrZv3w5AUVERo0aNIjQ0lJ9++on58+ezdOnSag3zrFmzuO+++7jzzjvZsmULX375JfHx8dV+xtNPP83EiRP5+eefGTt2LDfddBNHjx5t1HqKiIg0VWrrRZyYISJNyuTJkw0PDw8jICCg2u3//u//DMMwDMC4++67qx0zYMAA45577jEMwzDeeecdIzQ01CgsLKx6fuHChYbVajUyMjIMwzCM6Oho489//nOtMQDGX/7yl6rHhYWFBmB888039VZPERGRpkptvYhr05x0kSZo2LBhzJo1q9q+5s2bV20nJiZWey4xMZFNmzYBsH37dnr06EFAQEDV84MHD8Zut5OSkoLFYiE9PZ0RI0acMYbu3btXbQcEBBAUFERWVtb5VklEREROobZexHUpSRdpggICAk4bklZf/Pz8zqmcl5dXtccWiwW73d4QIYmIiDQ5autFXJfmpIvIaX744YfTHnfu3BmAzp07s3nzZoqKiqqeX716NVarlYSEBAIDA2nTpg3Lli1r1JhFRETk3KmtF3Fe6kkXaYLKysrIyMiots/T05OwsDAA5s+fT9++fRkyZAj//ve/WbduHe+99x4AN910E9OnT2fy5Mk89dRTZGdnc//993PzzTcTEREBwFNPPcXdd99NeHg4Y8aMoaCggNWrV3P//fc3bkVFRESaKLX1Iq5LSbpIE7R48WKioqKq7UtISGDHjh2AYzXWefPmce+99xIVFcXHH3/MRRddBIC/vz/ffvstDz74IP369cPf359rrrmGV155peq1Jk+eTGlpKa+++iqPPvooYWFhXHvttY1XQRERkSZObb2I67IYhmGYHYSIOA+LxcLnn3/OhAkTzA5FREREGoDaehHnpjnpIiIiIiIiIk5CSbqIiIiIiIiIk9BwdxEREREREREnoZ50ERERERERESehJF1ERERERETESShJFxEREREREXESStJFREREREREnISSdBEREREREREnoSRdRERERERExEkoSRcRERERERFxEkrSRURERERERJzE/wMk0qHBc4fdyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp26.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp26.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp26.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp26.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

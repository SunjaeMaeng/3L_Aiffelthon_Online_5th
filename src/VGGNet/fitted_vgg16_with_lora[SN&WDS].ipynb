{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McBYcpzkTZ9_",
    "outputId": "a2772546-3741-4002-dcd2-e9f891dcc64a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 02:54:50.009991: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 02:54:50.010032: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 02:54:50.010067: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 02:54:50.018500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3H9TbtJTO5k"
   },
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GWr9Ep7TOZi",
    "outputId": "647d0e20-3158-42a5-b511-c956818d28a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 3s 0us/step\n",
      "train data\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "test data\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('train data')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('test data')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5IyhwDy0TcOf"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리: 정규화\n",
    "x_train, x_test = x_train / 255.0,  x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1xQRMYeTg3_",
    "outputId": "4743d68e-ca60-4206-926d-01a0a4d89082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "test data\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 02:54:58.770708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18452 MB memory:  -> device: 0, name: NVIDIA RTX 4000 SFF Ada Generation, pci bus id: 0000:8b:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# scalar 형태의 레이블(0-9)을 one-hot encoding 형태로 변환합니다\n",
    "\n",
    "y_train = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
    "y_test = tf.squeeze(tf.one_hot(y_test, 10), axis=1)\n",
    "\n",
    "print('train data')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('test data')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj-DhZZZTRxC"
   },
   "source": [
    "# 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfhhV71RMn2Y",
    "outputId": "32aa266f-ad78-4d62-85da-834473b4b900"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_LJi10btMdaM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_vgg16 = load_model(\"./best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olYdP2YUM_Pi",
    "outputId": "f3da890a-cd98-4460-9266-d40bbfa76312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18918730 (72.17 MB)\n",
      "Trainable params: 18918730 (72.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoj2Gx6bfMfH"
   },
   "source": [
    "# inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJf4zX5-fGCf",
    "outputId": "9ef58926-9b3d-4572-b10f-023dbe6f759d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 02:57:09.104942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8905\n",
      "2023-11-30 02:57:09.231789: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-30 02:57:09.714775: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 7ms/step - loss: 0.5326 - accuracy: 0.8536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5325803160667419, 0.853600025177002]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "best_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv-4CTjZPIoJ"
   },
   "source": [
    "## 가중치 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1m-0r85R0TO",
    "outputId": "1b47f575-0bf4-4cbd-e6f9-bc4579a192df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 1792\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36928\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 73856\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 147584\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 295168\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 590080\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 590080\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 1180160\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 2359808\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 2101248\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 2097664\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 5130\n",
      "  Non-trainable parameters: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in best_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX5RRcHq9CDt"
   },
   "source": [
    "# [Code] LoRA\n",
    "\n",
    "아래의 lora 코드에는 scheduling factor와 noise가 포함되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UylB2lpL9Gy5"
   },
   "source": [
    "## ConvLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "npn-lPaP9Hev"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, initializers\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, Conv3D\n",
    "\n",
    "class ConvLoRALayer00_cdn2(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_conv_layer,\n",
    "        total_iteration = 1000 ,  # Total number of iterations for the decay\n",
    "        start_percent=0.1,  # The percentage of total_iteration when decay starts\n",
    "        end_percent=0.9,  # The percentage of total_iteration when decay ends\n",
    "        min_decay_factor=0,  # The minimum value that decay factor can take\n",
    "        rank=32,\n",
    "        alpha=32,\n",
    "        trainable=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Capture the original layer's configuration.\n",
    "        original_layer_config = original_conv_layer.get_config()\n",
    "        name = original_layer_config[\"name\"]\n",
    "        kwargs.pop(\"name\", None)\n",
    "\n",
    "        super().__init__(name=name, trainable=trainable, **kwargs)\n",
    "\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self._scale = alpha / rank\n",
    "\n",
    "        # The original convolutional layer is set to non-trainable to freeze its weights.\n",
    "        self.original_conv_layer = original_conv_layer\n",
    "        self.original_conv_layer.trainable = False\n",
    "\n",
    "        self.kernel = None\n",
    "        self.filters = original_conv_layer.filters #\n",
    "        self.kernel_size = original_conv_layer.kernel_size[0] #\n",
    "        self.in_channels = None\n",
    "\n",
    "        self.total_iteration = total_iteration\n",
    "        self.start_step = int(total_iteration * start_percent)\n",
    "        self.end_step = int(total_iteration * end_percent)\n",
    "        self.min_decay_factor = min_decay_factor\n",
    "\n",
    "        #trainable=False, 이 변수가 텐서플로우의 자동 미분 및 최적화 과정에 의해 업데이트되지 않는다는 뜻\n",
    "        #수동으로 업데이트될 수 있습니다. 예를 들어, 반복문 안에서 이 변수의 값을 업데이트하는 로직을 작성할 수 있음!\n",
    "        self.current_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.decay_factor = tf.Variable(1.0, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Ensure the original convolutional layer is built.\n",
    "        #if not self.original_conv_layer.built:\n",
    "        #    self.original_conv_layer.build(input_shape)\n",
    "\n",
    "        # Calculate the shape for LoRA weights A and B.\n",
    "        #self.kernel = self.original_conv_layer.kernel\n",
    "        self.in_channels = input_shape[-1]\n",
    "\n",
    "        in_channels = self.in_channels\n",
    "        out_channels = self.filters\n",
    "        kernel_size = self.original_conv_layer.kernel_size[0]\n",
    "\n",
    "        # LoRA weights A and B.\n",
    "        self.A_weight = self.add_weight(\n",
    "            name=\"lora_A_weight\",\n",
    "            shape=(self.rank*kernel_size, in_channels*kernel_size),\n",
    "            initializer=initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='uniform'),\n",
    "            trainable=self.trainable\n",
    "        )\n",
    "\n",
    "        self.B_weight = self.add_weight(\n",
    "            name=\"lora_B_weight\",\n",
    "            shape=(out_channels*kernel_size, self.rank*kernel_size),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=self.trainable\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None:\n",
    "                training = self.trainable\n",
    "\n",
    "        # Calculate the linear decay factor\n",
    "        if self.current_step < self.start_step:\n",
    "            self.decay_factor.assign(1.0)  # Decay has not started yet\n",
    "        elif self.current_step > self.end_step:\n",
    "            self.decay_factor.assign(tf.cast(self.min_decay_factor, dtype=tf.float32))  # Ensure float32 type for consistency\n",
    "        else:\n",
    "            # Linear decay between start_step and end_step\n",
    "            self.decay_factor.assign(1.0 - ((tf.cast(self.current_step, dtype=tf.float32) - self.start_step) /\n",
    "                                    (self.end_step - self.start_step) *\n",
    "                                    (1.0 - tf.cast(self.min_decay_factor, dtype=tf.float32))))\n",
    "\n",
    "        lora_BA = (self.B_weight@self.A_weight)\n",
    "\n",
    "        kernel_size = self.original_conv_layer.kernel_size[0]\n",
    "        in_channels = self.in_channels\n",
    "        out_channels = self.filters\n",
    "\n",
    "           # lora_BA의 형태 변환\n",
    "           # lora_BA가 (out_channels*kernel_size*kernel_size, in_channels*kernel_size*kernel_size) 형태라고 가정\n",
    "           # 이를 (kernel_size, kernel_size, in_channels, out_channels)로 변환\n",
    "        lora_BA_reshaped = tf.reshape(lora_BA, (out_channels, kernel_size, kernel_size, in_channels))\n",
    "        lora_BA_reshaped = tf.transpose(lora_BA_reshaped, [1, 2, 3, 0])\n",
    "        lora_output = tf.nn.conv2d(inputs, lora_BA_reshaped, strides=[1, 1, 1, 1], padding='SAME') * self._scale\n",
    "\n",
    "        # original_output = self.original_conv_layer(inputs) * self.decay_factor\n",
    "\n",
    "        if training:\n",
    "            original_output = self.original_conv_layer(inputs)\n",
    "            # 평균과 표준편차 계산\n",
    "            original_weight_matrix = self.original_conv_layer.weights[0]\n",
    "            original_mean = tf.reduce_mean(original_weight_matrix)\n",
    "            original_variance = tf.reduce_mean(tf.square(original_weight_matrix - original_mean))\n",
    "            original_stddev = tf.sqrt(original_variance)\n",
    "\n",
    "            # decay_factor가 0.3보다 작으면 noise_mean과 noise_std를 0으로 설정\n",
    "            noise_mean = tf.where(self.decay_factor < 0.3, 0.0, original_mean * (1 - self.decay_factor))\n",
    "            noise_std = tf.where(self.decay_factor < 0.3, 0.0, original_stddev * tf.sqrt(1 - tf.square(self.decay_factor)))\n",
    "            noise = tf.random.normal(tf.shape(original_weight_matrix), mean=noise_mean, stddev=noise_std)\n",
    "            noise_output = tf.nn.conv2d(inputs, noise, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            self.current_step.assign_add(1)\n",
    "\n",
    "            return original_output * self.decay_factor + noise_output + lora_output\n",
    "\n",
    "        else:\n",
    "            # 추론 모드에서는 LoRA 출력만 반환\n",
    "            return lora_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLLXZoFi9UgM"
   },
   "source": [
    "## DenseLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b3zto3tY9Wu8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow import keras\n",
    "\n",
    "class LoraLayer(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_layer,\n",
    "        total_iteration = 1000 ,  # Total number of iterations for the decay\n",
    "        start_percent=0.1,  # The percentage of total_iteration when decay starts\n",
    "        end_percent=0.9,  # The percentage of total_iteration when decay ends\n",
    "        min_decay_factor=0,  # The minimum value that decay factor can take\n",
    "        rank=32,\n",
    "        alpha=32,\n",
    "        trainable=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        original_layer_config = original_layer.get_config()\n",
    "        name = original_layer_config[\"name\"]\n",
    "        kwargs.pop(\"name\", None)\n",
    "\n",
    "        super().__init__(name=name, trainable=trainable, **kwargs)\n",
    "\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self._scale = alpha / rank\n",
    "\n",
    "        self.original_layer = original_layer\n",
    "        self.original_layer.trainable = False\n",
    "\n",
    "\n",
    "        self.total_iteration = total_iteration\n",
    "        self.start_step = int(total_iteration * start_percent)\n",
    "        self.end_step = int(total_iteration * end_percent)\n",
    "        self.min_decay_factor = min_decay_factor\n",
    "\n",
    "        #trainable=False, 이 변수가 텐서플로우의 자동 미분 및 최적화 과정에 의해 업데이트되지 않는다는 뜻\n",
    "        #수동으로 업데이트될 수 있습니다. 예를 들어, 반복문 안에서 이 변수의 값을 업데이트하는 로직을 작성할 수 있음!\n",
    "        self.current_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.decay_factor = tf.Variable(1.0, dtype=tf.float32, trainable=False)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # LoRA weights.\n",
    "        kernel_shape = self.original_layer.kernel.shape\n",
    "        self.A_weight = self.add_weight(\n",
    "            name=\"lora_A_weight\",\n",
    "            shape=(self.rank, kernel_shape[0]),\n",
    "            initializer=keras.initializers.VarianceScaling(\n",
    "                scale=math.sqrt(5), mode=\"fan_in\", distribution=\"uniform\"\n",
    "            ),\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "\n",
    "        self.B_weight = self.add_weight(\n",
    "            name=\"lora_B_weight\",\n",
    "            shape=(self.original_layer.units, self.rank),\n",
    "            initializer='zeros',\n",
    "            trainable=self.trainable,\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "            if training is None:\n",
    "                training = self.trainable\n",
    "\n",
    "            # Calculate the linear decay factor\n",
    "            if self.current_step < self.start_step:\n",
    "                self.decay_factor.assign(1.0)  # Decay has not started yet\n",
    "            elif self.current_step > self.end_step:\n",
    "                self.decay_factor.assign(tf.cast(self.min_decay_factor, dtype=tf.float32))  # Ensure float32 type for consistency\n",
    "            else:\n",
    "                # Linear decay between start_step and end_step\n",
    "                self.decay_factor.assign(1.0 - ((tf.cast(self.current_step, dtype=tf.float32) - self.start_step) /\n",
    "                                        (self.end_step - self.start_step) *\n",
    "                                        (1.0 - tf.cast(self.min_decay_factor, dtype=tf.float32))))\n",
    "\n",
    "            # Matrix multiplication for A and B weights with inputs\n",
    "            lora_A_output = tf.matmul(self.A_weight, tf.transpose(inputs))  # Ax\n",
    "            lora_output = tf.transpose(tf.matmul(self.B_weight, lora_A_output) * self._scale)  # BAx Transpose back to [batch_size, original_layer.units]\n",
    "\n",
    "            #lora_output *= (1 - self.decay_factor) # 멘토링 때 나온 의견\n",
    "\n",
    "            if training:\n",
    "                original_output = self.original_layer(inputs)\n",
    "                # 평균과 표준편차 계산\n",
    "                original_weight_matrix = self.original_layer.weights[0]\n",
    "                original_mean = tf.reduce_mean(original_weight_matrix, axis=0)\n",
    "                original_variance = tf.reduce_mean(tf.square(original_weight_matrix - original_mean), axis=0)\n",
    "                original_stddev = tf.sqrt(original_variance)\n",
    "\n",
    "                # decay_factor가 0.3보다 작으면 noise_mean과 noise_std를 0으로 설정\n",
    "                noise_mean = tf.where(self.decay_factor < 0.3, 0.0, original_mean * (1 - self.decay_factor))\n",
    "                noise_std = tf.where(self.decay_factor < 0.3, 0.0, original_stddev * tf.sqrt(1 - tf.square(self.decay_factor)))\n",
    "                noise = tf.random.normal(tf.shape(original_weight_matrix), mean=noise_mean, stddev=noise_std)\n",
    "\n",
    "                self.current_step.assign_add(1)\n",
    "\n",
    "                return original_output * self.decay_factor + (inputs @ noise) + lora_output\n",
    "\n",
    "            else:\n",
    "                # 추론 모드에서는 LoRA 출력만 반환\n",
    "                return lora_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBM9sOz3_Yt1"
   },
   "source": [
    "# LoRA 적용. Exp1: Convlora + Denselayer는 ❄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pww7eFLm30pR"
   },
   "source": [
    "## 1-1. (16, -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zuTOhngBFiYl"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BPKqW1Hk_X6m"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp11_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uFd65OKPpW9T"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp11_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP-6DUC7FopE",
    "outputId": "7f7df7a3-41ec-4649-9c9d-a600d32a3c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11442     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55362     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101506    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184450    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350466    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1290754   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20061972 (76.53 MB)\n",
      "Trainable params: 1143216 (4.36 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp11_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gdRpVfKPM3t"
   },
   "source": [
    "## 가중치 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEO3IP_PRqSl",
    "outputId": "d61fa7cb-df81-4410-8e34-1930cbc1cc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9648\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18432\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27648\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2101248\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2097664\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp11_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMG9bhGIU2ch"
   },
   "source": [
    "## 스케줄링 및 노이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Knnl1gljU8aT"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp11_lora_vgg16.layers:\n",
    "    if isinstance(layer, ConvLoRALayer00_cdn2) or isinstance(layer, LoraLayer):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ESXAgLxgZVzR"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "f70WB6oBaKLk"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PhpCpsu_aMtY"
   },
   "outputs": [],
   "source": [
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKWXrQnopKB6"
   },
   "source": [
    "##학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pnAakdZ8aRCW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp11_lora_vgg16.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQ1mcREqapIR",
    "outputId": "d4a2e3b1-70cd-4d6f-af9d-cb47a3037158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11442     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55362     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101506    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184450    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350466    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1290754   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20061972 (76.53 MB)\n",
      "Trainable params: 1143216 (4.36 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp11_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQWxiR4Qas7b",
    "outputId": "80cdb761-589a-45e6-b338-4a7cddaf5500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 02:57:26.929002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f456af717e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-30 02:57:26.929054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 4000 SFF Ada Generation, Compute Capability 8.9\n",
      "2023-11-30 02:57:26.934661: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-30 02:57:27.118875: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9288\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3033711910247803, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 71s 35ms/step - loss: 0.2236 - accuracy: 0.9288 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9385\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3033714294433594, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 55s 33ms/step - loss: 0.1933 - accuracy: 0.9385 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8978\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.3033676147460938, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.3297 - accuracy: 0.8978 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.8477\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3033244609832764, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.4846 - accuracy: 0.8477 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.8051\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.302985429763794, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.6111 - accuracy: 0.8051 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.7268 - accuracy: 0.7681\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.302887439727783, acc: 0.09929999709129333\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.7268 - accuracy: 0.7681 - val_loss: 2.3029 - val_accuracy: 0.0993\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8481 - accuracy: 0.7267\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.302459955215454, acc: 0.09989999979734421\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.8481 - accuracy: 0.7267 - val_loss: 2.3025 - val_accuracy: 0.0999\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9485 - accuracy: 0.6967\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.337024450302124, acc: 0.09989999979734421\n",
      "\n",
      "1667/1667 [==============================] - 59s 36ms/step - loss: 0.9485 - accuracy: 0.6967 - val_loss: 2.3370 - val_accuracy: 0.0999\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0714 - accuracy: 0.6565\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.3101563453674316, acc: 0.06930000334978104\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 1.0714 - accuracy: 0.6565 - val_loss: 2.3102 - val_accuracy: 0.0693\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1637 - accuracy: 0.6238\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3693463802337646, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 1.1637 - accuracy: 0.6238 - val_loss: 2.3693 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2710 - accuracy: 0.5864\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.315094232559204, acc: 0.09719999879598618\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 1.2710 - accuracy: 0.5864 - val_loss: 2.3151 - val_accuracy: 0.0972\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3582 - accuracy: 0.5533\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 6.892824172973633, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 1.3582 - accuracy: 0.5533 - val_loss: 6.8908 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.4427 - accuracy: 0.5194\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 8.358416557312012, acc: 0.0989999994635582\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 1.4427 - accuracy: 0.5194 - val_loss: 8.3616 - val_accuracy: 0.0990\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0783 - accuracy: 0.6663\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.29910945892334, acc: 0.0917000025510788\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 1.0783 - accuracy: 0.6663 - val_loss: 2.2991 - val_accuracy: 0.0917\n",
      "Epoch 15/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.7223 - accuracy: 0.7541\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.1638875007629395, acc: 0.27459999918937683\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.7223 - accuracy: 0.7541 - val_loss: 2.1639 - val_accuracy: 0.2744\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.7592\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 2.029636859893799, acc: 0.31540000438690186\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.7131 - accuracy: 0.7592 - val_loss: 2.0296 - val_accuracy: 0.3154\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.7536\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.3666104078292847, acc: 0.6037999987602234\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.7279 - accuracy: 0.7536 - val_loss: 1.3666 - val_accuracy: 0.6038\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.7510\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.906653106212616, acc: 0.7070000171661377\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.7481 - accuracy: 0.7510 - val_loss: 0.9066 - val_accuracy: 0.7070\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.7515\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.8112872838973999, acc: 0.7415000200271606\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.7506 - accuracy: 0.7515 - val_loss: 0.8113 - val_accuracy: 0.7415\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.7733\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.8543282151222229, acc: 0.7303000092506409\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.6867 - accuracy: 0.7733 - val_loss: 0.8543 - val_accuracy: 0.7300\n"
     ]
    }
   ],
   "source": [
    "history11 = exp11_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxbUXaLxfZIF"
   },
   "source": [
    "## inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fj8riYOifa42",
    "outputId": "2442e2b6-4c42-4912-8af0-75889570b57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.8543 - accuracy: 0.7303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8543282151222229, 0.7303000092506409]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp11_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xLQEo46Gbt-o",
    "outputId": "ef3d1022-1ab1-4b95-9e23-8821d952cade"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history11.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history11.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history11.history['loss'], label='Training Loss')\n",
    "plt.plot(history11.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvAH25Td4TPl"
   },
   "source": [
    "## 1-2. (32, -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oX1SFBOl4f0i"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp12_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wk9goxZs4f0i"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp12_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaPm45ig4f0i",
    "outputId": "dc71d166-374e-47d4-8021-958789640caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21090     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73794     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129154    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221314    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         405762    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401346   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21205188 (80.89 MB)\n",
      "Trainable params: 2286432 (8.72 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp12_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F77s-EYN4vcq",
    "outputId": "4db474a4-9bdc-4bcb-c999-03d70df3d99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19296\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221184\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2101248\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 2097664\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp12_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "OK4liexw4zdy"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp12_lora_vgg16.layers:\n",
    "    if isinstance(layer, ConvLoRALayer00_cdn2) or isinstance(layer, LoraLayer):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1iKvTdFN4zdy"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lL8z4Ky84zdz"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vmjY3HT-4zdz"
   },
   "outputs": [],
   "source": [
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtqOiU8844Ta"
   },
   "source": [
    "##학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pCKYMJdu44Tb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp12_lora_vgg16.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSTgDSLX44Tb",
    "outputId": "d531bcd3-8079-4760-e8b9-7ec8683817d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21090     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73794     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129154    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221314    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         405762    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401346   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21205188 (80.89 MB)\n",
      "Trainable params: 2286432 (8.72 MB)\n",
      "Non-trainable params: 18918756 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp12_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW3wKPlB44Tb",
    "outputId": "8980c3e2-5ab0-401d-eee2-7bb47a0ff31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9547\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.3033711910247803, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 66s 34ms/step - loss: 0.1456 - accuracy: 0.9547 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9646\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.3033711910247803, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 56s 34ms/step - loss: 0.1113 - accuracy: 0.9646 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9288\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.3033714294433594, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.2184 - accuracy: 0.9288 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8863\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.3033711910247803, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.3510 - accuracy: 0.8863 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8553\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3033745288848877, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.4389 - accuracy: 0.8553 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.8315\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3034613132476807, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5157 - accuracy: 0.8315 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.8003\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3035597801208496, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.6011 - accuracy: 0.8003 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.7791\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.308048725128174, acc: 0.10159999877214432\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.6805 - accuracy: 0.7791 - val_loss: 2.3080 - val_accuracy: 0.1016\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7568 - accuracy: 0.7524\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.303071975708008, acc: 0.10199999809265137\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.7568 - accuracy: 0.7524 - val_loss: 2.3031 - val_accuracy: 0.1020\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8265 - accuracy: 0.7255\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.453726053237915, acc: 0.08269999921321869\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.8265 - accuracy: 0.7255 - val_loss: 2.4536 - val_accuracy: 0.0829\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8979 - accuracy: 0.7049\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.441450595855713, acc: 0.1080000028014183\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.8979 - accuracy: 0.7049 - val_loss: 2.4411 - val_accuracy: 0.1082\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9723 - accuracy: 0.6816\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 15.386456489562988, acc: 0.08829999715089798\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.9723 - accuracy: 0.6816 - val_loss: 15.3672 - val_accuracy: 0.0883\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0353 - accuracy: 0.6594\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 4.3290696144104, acc: 0.10490000247955322\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 1.0353 - accuracy: 0.6594 - val_loss: 4.3278 - val_accuracy: 0.1049\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.7597\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.3543381690979004, acc: 0.11659999936819077\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.8385 - accuracy: 0.7597 - val_loss: 2.3544 - val_accuracy: 0.1166\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.8173\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.1840999126434326, acc: 0.181099995970726\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5358 - accuracy: 0.8173 - val_loss: 2.1841 - val_accuracy: 0.1813\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5348 - accuracy: 0.8211\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.8063833713531494, acc: 0.5558000206947327\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.5348 - accuracy: 0.8211 - val_loss: 1.8063 - val_accuracy: 0.5563\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.8170\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.2282425165176392, acc: 0.6284999847412109\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5469 - accuracy: 0.8170 - val_loss: 1.2285 - val_accuracy: 0.6285\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5724 - accuracy: 0.8085\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.795530378818512, acc: 0.739300012588501\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.5724 - accuracy: 0.8085 - val_loss: 0.7955 - val_accuracy: 0.7393\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8184\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.714350700378418, acc: 0.7706000208854675\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.5449 - accuracy: 0.8184 - val_loss: 0.7144 - val_accuracy: 0.7706\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8390\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7168959379196167, acc: 0.7718999981880188\n",
      "\n",
      "1667/1667 [==============================] - 57s 34ms/step - loss: 0.4831 - accuracy: 0.8390 - val_loss: 0.7169 - val_accuracy: 0.7720\n"
     ]
    }
   ],
   "source": [
    "history12 = exp12_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iVURdjC48v9",
    "outputId": "9047bd8d-e365-4e76-b6e0-da8c37f8c125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7169 - accuracy: 0.7719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7168959379196167, 0.7718999981880188]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp12_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "oMHh5D1X48v-",
    "outputId": "ea281e83-ef37-4b69-d805-b0538a863591"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history12.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history12.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history12.history['loss'], label='Training Loss')\n",
    "plt.plot(history12.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iiF1k-9D0hd"
   },
   "source": [
    "---\n",
    "#Experiments 2 : 모든 Convlora + dense6,7에 denselora + dense8 ❄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmYS1wIAD5x8"
   },
   "source": [
    "## 2-1. (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "GFXXUUlKFeK7"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Z2OFtKnqD4bc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=32, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp21_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GbLnmfaLELbE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp21_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aP_ss6DrEcBt",
    "outputId": "4d03c7d0-26d7-4ff8-da94-aa4e30a6c54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21090     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73794     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129154    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221314    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         405762    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401346   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2248706   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2245122   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21500104 (82.02 MB)\n",
      "Trainable params: 2581344 (9.85 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp21_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "155io3wREiB2",
    "outputId": "99a4922b-b4e4-4de1-c975-7ccb8b510041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19296\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221184\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp21_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6eHa70iQEo_N"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp21_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4vQVbHIuEsVk"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "sWlqdMvwFBdM"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Nv9o4F_-FEAb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp21_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OU9-UYR-4U1"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VH7DGSABFKfM",
    "outputId": "b050f3c7-0085-4751-dd43-3e47954bae19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9746\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 73s 38ms/step - loss: 0.0800 - accuracy: 0.9746 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9819\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9483\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.1587 - accuracy: 0.9483 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8946\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.3240 - accuracy: 0.8946 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8589\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.4330 - accuracy: 0.8589 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.8219\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3026063442230225, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5470 - accuracy: 0.8219 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.7870\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3025925159454346, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6396 - accuracy: 0.7870 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7379 - accuracy: 0.7556\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3025588989257812, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.7379 - accuracy: 0.7556 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8336 - accuracy: 0.7248\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.302647590637207, acc: 0.09989999979734421\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.8336 - accuracy: 0.7248 - val_loss: 2.3026 - val_accuracy: 0.0999\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9205 - accuracy: 0.6963\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3038337230682373, acc: 0.10050000250339508\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.9205 - accuracy: 0.6963 - val_loss: 2.3038 - val_accuracy: 0.1005\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.6686\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.301954984664917, acc: 0.10080000013113022\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.9968 - accuracy: 0.6686 - val_loss: 2.3020 - val_accuracy: 0.1008\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0699 - accuracy: 0.6419\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.325138568878174, acc: 0.1216999962925911\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.0699 - accuracy: 0.6419 - val_loss: 2.3251 - val_accuracy: 0.1217\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1345 - accuracy: 0.6210\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 4.229156970977783, acc: 0.08529999852180481\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.1345 - accuracy: 0.6210 - val_loss: 4.2295 - val_accuracy: 0.0854\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9129 - accuracy: 0.7191\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.2704052925109863, acc: 0.15860000252723694\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.9129 - accuracy: 0.7191 - val_loss: 2.2704 - val_accuracy: 0.1587\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.7899\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.20438289642334, acc: 0.34380000829696655\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6166 - accuracy: 0.7899 - val_loss: 2.2044 - val_accuracy: 0.3438\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7996\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.9322845935821533, acc: 0.5424000024795532\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5846 - accuracy: 0.7996 - val_loss: 1.9323 - val_accuracy: 0.5420\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8071\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.4937560558319092, acc: 0.5949000120162964\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.5671 - accuracy: 0.8071 - val_loss: 1.4938 - val_accuracy: 0.5947\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.8039\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7463282942771912, acc: 0.7569000124931335\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.5743 - accuracy: 0.8039 - val_loss: 0.7463 - val_accuracy: 0.7568\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5504 - accuracy: 0.8142\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7307285666465759, acc: 0.7616999745368958\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.5504 - accuracy: 0.8142 - val_loss: 0.7307 - val_accuracy: 0.7616\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.8414\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7270441651344299, acc: 0.7717999815940857\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.4706 - accuracy: 0.8414 - val_loss: 0.7270 - val_accuracy: 0.7719\n"
     ]
    }
   ],
   "source": [
    "history_exp21 = exp21_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW-llVuqfwUi",
    "outputId": "5e988700-845b-4e27-ca47-e1b0d955a824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7270 - accuracy: 0.7718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7270441651344299, 0.7717999815940857]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp21_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "cQNbKdwVPyWo",
    "outputId": "32635d44-290d-4863-cb29-faf4f70d3c82"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHWCAYAAAALjsguAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4GUlEQVR4nOzdd3hT9d/G8Xe696CFllFW2RtZsrdsBRFlyEYfFVQEFBFBwIE/AUVxoMhwMEVAFJAle68ie5a9V0tbuvP8ERqoZbTQ9qTt/bquXD09OUnuhJKcT77LZDabzYiIiIiIiIiI4eyMDiAiIiIiIiIiFirSRURERERERGyEinQRERERERERG6EiXURERERERMRGqEgXERERERERsREq0kVERERERERshIp0ERERERERERuhIl1ERERERETERqhIFxEREREREbERKtLFpvTo0YPChQs/0m1HjBiByWRK30A25sSJE5hMJqZNm5bpj20ymRgxYoT192nTpmEymThx4sRDb1u4cGF69OiRrnke529FRESyB503PJjOG+7QeYNkJSrSJVVMJlOqLqtXrzY6ao73xhtvYDKZOHr06H2PGTp0KCaTiX///TcTk6XduXPnGDFiBCEhIUZHuacDBw5gMplwcXHhxo0bRscREbEZOm/IOnTekLGSvigZO3as0VEkC3EwOoBkDb/88kuy33/++WeWL1+eYn/p0qUf63EmTZpEYmLiI932/fff5913332sx88OunTpwoQJE5gxYwbDhw+/5zEzZ86kfPnyVKhQ4ZEfp2vXrnTs2BFnZ+dHvo+HOXfuHCNHjqRw4cJUqlQp2XWP87eSXn799VcCAwO5fv06c+fOpU+fPobmERGxFTpvyDp03iBie1SkS6q8+OKLyX7fvHkzy5cvT7H/v6KionBzc0v14zg6Oj5SPgAHBwccHPQnXaNGDYoVK8bMmTPv+WG7adMmQkND+fTTTx/rcezt7bG3t3+s+3gcj/O3kh7MZjMzZsygc+fOhIaGMn36dJst0iMjI3F3dzc6hojkIDpvyDp03iBie9TdXdJNgwYNKFeuHDt27KBevXq4ubnx3nvvAfDHH3/QqlUr8uXLh7OzM8HBwXz44YckJCQku4//jhe6u4vQDz/8QHBwMM7OzlSrVo1t27Ylu+29xpaZTCb69evHggULKFeuHM7OzpQtW5a///47Rf7Vq1dTtWpVXFxcCA4O5vvvv0/1eLV169bRoUMHChYsiLOzM0FBQbz11lvcunUrxfPz8PDg7NmztG3bFg8PD3Lnzs2gQYNSvBY3btygR48eeHt74+PjQ/fu3VPdpbpLly4cPHiQnTt3prhuxowZmEwmOnXqRGxsLMOHD6dKlSp4e3vj7u5O3bp1WbVq1UMf415jy8xmMx999BEFChTAzc2Nhg0bsm/fvhS3vXbtGoMGDaJ8+fJ4eHjg5eVFixYt2L17t/WY1atXU61aNQB69uxp7RqZNK7uXmPLIiMjGThwIEFBQTg7O1OyZEnGjh2L2WxOdlxa/i7uZ8OGDZw4cYKOHTvSsWNH1q5dy5kzZ1Icl5iYyJdffkn58uVxcXEhd+7cNG/enO3btyc77tdff6V69eq4ubnh6+tLvXr1WLZsWbLMd4/tS/LfcXtJ/y5r1qzhtddeI0+ePBQoUACAkydP8tprr1GyZElcXV3x8/OjQ4cO9xwfeOPGDd566y0KFy6Ms7MzBQoUoFu3bly5coWIiAjc3d158803U9zuzJkz2NvbM3r06FS+kiKSU+m8QecNOem84WEuXbpE7969CQgIwMXFhYoVK/LTTz+lOG7WrFlUqVIFT09PvLy8KF++PF9++aX1+ri4OEaOHEnx4sVxcXHBz8+POnXqsHz58nTLKhlPXx9Kurp69SotWrSgY8eOvPjiiwQEBACWN2YPDw8GDBiAh4cH//zzD8OHDyc8PJwxY8Y89H5nzJjBzZs3+b//+z9MJhOfffYZzz77LMePH3/oN6Pr169n3rx5vPbaa3h6evLVV1/Rvn17Tp06hZ+fHwC7du2iefPm5M2bl5EjR5KQkMCoUaPInTt3qp73b7/9RlRUFK+++ip+fn5s3bqVCRMmcObMGX777bdkxyYkJNCsWTNq1KjB2LFjWbFiBePGjSM4OJhXX30VsHxoPfPMM6xfv55XXnmF0qVLM3/+fLp3756qPF26dGHkyJHMmDGDJ554Itljz5kzh7p161KwYEGuXLnCjz/+SKdOnXjppZe4efMmkydPplmzZmzdujVFV7GHGT58OB999BEtW7akZcuW7Ny5k6eeeorY2Nhkxx0/fpwFCxbQoUMHihQpwsWLF/n++++pX78++/fvJ1++fJQuXZpRo0YxfPhwXn75ZerWrQtArVq17vnYZrOZp59+mlWrVtG7d28qVarE0qVLefvttzl79ixffPFFsuNT83fxINOnTyc4OJhq1apRrlw53NzcmDlzJm+//Xay43r37s20adNo0aIFffr0IT4+nnXr1rF582aqVq0KwMiRIxkxYgS1atVi1KhRODk5sWXLFv755x+eeuqpVL/+d3vttdfInTs3w4cPJzIyEoBt27axceNGOnbsSIECBThx4gTfffcdDRo0YP/+/dbWq4iICOrWrcuBAwfo1asXTzzxBFeuXGHhwoWcOXOGSpUq0a5dO2bPns3nn3+erGVk5syZmM1munTp8ki5RSRn0XmDzhtyynnDg9y6dYsGDRpw9OhR+vXrR5EiRfjtt9/o0aMHN27csH4pvnz5cjp16kTjxo353//+B1jmx9mwYYP1mBEjRjB69Gj69OlD9erVCQ8PZ/v27ezcuZOmTZs+Vk7JRGaRR9C3b1/zf/986tevbwbMEydOTHF8VFRUin3/93//Z3ZzczNHR0db93Xv3t1cqFAh6++hoaFmwOzn52e+du2adf8ff/xhBsx//vmndd8HH3yQIhNgdnJyMh89etS6b/fu3WbAPGHCBOu+Nm3amN3c3Mxnz5617jty5IjZwcEhxX3ey72e3+jRo80mk8l88uTJZM8PMI8aNSrZsZUrVzZXqVLF+vuCBQvMgPmzzz6z7ouPjzfXrVvXDJinTp360EzVqlUzFyhQwJyQkGDd9/fff5sB8/fff2+9z5iYmGS3u379ujkgIMDcq1evZPsB8wcffGD9ferUqWbAHBoaajabzeZLly6ZnZyczK1atTInJiZaj3vvvffMgLl79+7WfdHR0clymc2Wf2tnZ+dkr822bdvu+3z/+7eS9Jp99NFHyY577rnnzCaTKdnfQGr/Lu4nNjbW7OfnZx46dKh1X+fOnc0VK1ZMdtw///xjBsxvvPFGivtIeo2OHDlitrOzM7dr1y7Fa3L36/jf1z9JoUKFkr22Sf8uderUMcfHxyc79l5/p5s2bTID5p9//tm6b/jw4WbAPG/evPvmXrp0qRkwL1myJNn1FSpUMNevXz/F7UQkZ9N5w8Ofn84bLLLbeUPS3+SYMWPue8z48ePNgPnXX3+17ouNjTXXrFnT7OHhYQ4PDzebzWbzm2++afby8krx+X63ihUrmlu1avXATGL71N1d0pWzszM9e/ZMsd/V1dW6ffPmTa5cuULdunWJiori4MGDD73fF154AV9fX+vvSd+OHj9+/KG3bdKkCcHBwdbfK1SogJeXl/W2CQkJrFixgrZt25IvXz7rccWKFaNFixYPvX9I/vwiIyO5cuUKtWrVwmw2s2vXrhTHv/LKK8l+r1u3brLnsnjxYhwcHKzfkINlLNfrr7+eqjxgGQ945swZ1q5da903Y8YMnJyc6NChg/U+nZycAEu37GvXrhEfH0/VqlXv2eXtQVasWEFsbCyvv/56sq5+/fv3T3Gss7MzdnaWt5+EhASuXr2Kh4cHJUuWTPPjJlm8eDH29va88cYbyfYPHDgQs9nMkiVLku1/2N/FgyxZsoSrV6/SqVMn675OnTqxe/fuZN30fv/9d0wmEx988EGK+0h6jRYsWEBiYiLDhw+3vib/PeZRvPTSSynG/t39dxoXF8fVq1cpVqwYPj4+yV7333//nYoVK9KuXbv75m7SpAn58uVj+vTp1uv27t3Lv//++9AxpyIiSXTeoPOGnHDekJosgYGByc4rHB0deeONN4iIiGDNmjUA+Pj4EBkZ+cCu6z4+Puzbt48jR448di4xjop0SVf58+e3vnnfbd++fbRr1w5vb2+8vLzInTu39UQ+LCzsofdbsGDBZL8nffBev349zbdNun3SbS9dusStW7coVqxYiuPute9eTp06RY8ePciVK5d1vFj9+vWBlM8vaVzy/fKAZexw3rx58fDwSHZcyZIlU5UHoGPHjtjb2zNjxgwAoqOjmT9/Pi1atEh24vLTTz9RoUIF67il3Llzs2jRolT9u9zt5MmTABQvXjzZ/ty5cyd7PLB8sH/xxRcUL14cZ2dn/P39yZ07N//++2+aH/fux8+XLx+enp7J9ifNHJyUL8nD/i4e5Ndff6VIkSI4Oztz9OhRjh49SnBwMG5ubsmK1mPHjpEvXz5y5cp13/s6duwYdnZ2lClT5qGPmxZFihRJse/WrVsMHz7cOvYu6XW/ceNGstf92LFjlCtX7oH3b2dnR5cuXViwYAFRUVGAZQiAi4uL9WRORORhdN6g84accN6QmizFixdP8WX9f7O89tprlChRghYtWlCgQAF69eqVYlz8qFGjuHHjBiVKlKB8+fK8/fbbNr90nqSkIl3S1d3fDCe5ceMG9evXZ/fu3YwaNYo///yT5cuXW8fSpGY5jPvNBmr+z8Qe6X3b1EhISKBp06YsWrSIwYMHs2DBApYvX26dqOS/zy+zZjbNkycPTZs25ffffycuLo4///yTmzdvJhsr/Ouvv9KjRw+Cg4OZPHkyf//9N8uXL6dRo0YZukzJJ598woABA6hXrx6//vorS5cuZfny5ZQtWzbTlkd51L+L8PBw/vzzT0JDQylevLj1UqZMGaKiopgxY0a6/W2lxn8nDkpyr/+Lr7/+Oh9//DHPP/88c+bMYdmyZSxfvhw/P79Het27detGREQECxYssM5237p1a7y9vdN8XyKSM+m8QecNqZGVzxvSU548eQgJCWHhwoXW8fQtWrRINvdAvXr1OHbsGFOmTKFcuXL8+OOPPPHEE/z444+ZllMenyaOkwy3evVqrl69yrx586hXr551f2hoqIGp7siTJw8uLi4cPXo0xXX32vdfe/bs4fDhw/z0009069bNuv9xZtEsVKgQK1euJCIiItm34ocOHUrT/XTp0oW///6bJUuWMGPGDLy8vGjTpo31+rlz51K0aFHmzZuXrKvZvbpnpyYzwJEjRyhatKh1/+XLl1N8yzx37lwaNmzI5MmTk+2/ceMG/v7+1t/T0t27UKFCrFixgps3byb7VjypW2RSvsc1b948oqOj+e6775JlBcu/z/vvv8+GDRuoU6cOwcHBLF26lGvXrt23NT04OJjExET279//wAl3fH19U8zSGxsby/nz51Odfe7cuXTv3p1x48ZZ90VHR6e43+DgYPbu3fvQ+ytXrhyVK1dm+vTpFChQgFOnTjFhwoRU5xERuRedN6SdzhssbPG8IbVZ/v33XxITE5O1pt8ri5OTE23atKFNmzYkJiby2muv8f333zNs2DBrT45cuXLRs2dPevbsSUREBPXq1WPEiBE2u1SspKSWdMlwSd883v1NY2xsLN9++61RkZKxt7enSZMmLFiwgHPnzln3Hz16NMV4pPvdHpI/P7PZnGw5jLRq2bIl8fHxfPfdd9Z9CQkJaS6A2rZti5ubG99++y1Llizh2WefxcXF5YHZt2zZwqZNm9KcuUmTJjg6OjJhwoRk9zd+/PgUx9rb26f45vm3337j7NmzyfYlre2dmiVkWrZsSUJCAl9//XWy/V988QUmkynV4wQf5tdff6Vo0aK88sorPPfcc8kugwYNwsPDw9rlvX379pjNZkaOHJnifpKef9u2bbGzs2PUqFEpWgPufo2Cg4OTjRME+OGHH+7bkn4v93rdJ0yYkOI+2rdvz+7du5k/f/59cyfp2rUry5YtY/z48fj5+aXb6ywiOZfOG9JO5w0WtnjekBotW7bkwoULzJ4927ovPj6eCRMm4OHhYR0KcfXq1WS3s7Ozo0KFCgDExMTc8xgPDw+KFStmvV6yBrWkS4arVasWvr6+dO/enTfeeAOTycQvv/ySqd2DHmbEiBEsW7aM2rVr8+qrr1rftMuVK0dISMgDb1uqVCmCg4MZNGgQZ8+excvLi99///2xxii1adOG2rVr8+6773LixAnKlCnDvHnz0jzuysPDg7Zt21rHl/13WazWrVszb9482rVrR6tWrQgNDWXixImUKVOGiIiIND1W0rqto0ePpnXr1rRs2ZJdu3axZMmSFC3OrVu3ZtSoUfTs2ZNatWqxZ88epk+fnuybdLAUpj4+PkycOBFPT0/c3d2pUaPGPcdbt2nThoYNGzJ06FBOnDhBxYoVWbZsGX/88Qf9+/dPNtnLozp37hyrVq1KMclMEmdnZ5o1a8Zvv/3GV199RcOGDenatStfffUVR44coXnz5iQmJrJu3ToaNmxIv379KFasGEOHDuXDDz+kbt26PPvsszg7O7Nt2zby5ctnXW+8T58+vPLKK7Rv356mTZuye/duli5dmuK1fZDWrVvzyy+/4O3tTZkyZdi0aRMrVqxIsXTM22+/zdy5c+nQoQO9evWiSpUqXLt2jYULFzJx4kQqVqxoPbZz58688847zJ8/n1dfffWhSxuJiDyMzhvSTucNFrZ23nC3lStXEh0dnWJ/27Ztefnll/n+++/p0aMHO3bsoHDhwsydO5cNGzYwfvx4a0t/nz59uHbtGo0aNaJAgQKcPHmSCRMmUKlSJev49TJlytCgQQOqVKlCrly52L59O3PnzqVfv37p+nwkg2XCDPKSDd1vKZWyZcve8/gNGzaYn3zySbOrq6s5X7585nfeece6hNOqVausx91vKZV7LVvBf5b2uN9SKn379k1x2/8uW2U2m80rV640V65c2ezk5GQODg42//jjj+aBAweaXVxc7vMq3LF//35zkyZNzB4eHmZ/f3/zSy+9ZF2a4+5lQLp37252d3dPcft7Zb969aq5a9euZi8vL7O3t7e5a9eu5l27dqV6KZUkixYtMgPmvHnz3nOJr08++cRcqFAhs7Ozs7ly5crmv/76K8W/g9n88KVUzGazOSEhwTxy5Ehz3rx5za6uruYGDRqY9+7dm+L1jo6ONg8cONB6XO3atc2bNm0y169fP8XyXX/88Ye5TJky1mVtkp77vTLevHnT/NZbb5nz5ctndnR0NBcvXtw8ZsyYZEu7JD2X1P5d3G3cuHFmwLxy5cr7HjNt2jQzYP7jjz/MZrNluZoxY8aYS5UqZXZycjLnzp3b3KJFC/OOHTuS3W7KlCnmypUrm52dnc2+vr7m+vXrm5cvX269PiEhwTx48GCzv7+/2c3NzdysWTPz0aNH77sE27Zt21Jku379urlnz55mf39/s4eHh7lZs2bmgwcP3vN5X7161dyvXz9z/vz5zU5OTuYCBQqYu3fvbr5y5UqK+23ZsqUZMG/cuPG+r4uI5Gw6b0hO5w0W2f28wWy+8zd5v8svv/xiNpvN5osXL1o/o52cnMzly5dP8e82d+5c81NPPWXOkyeP2cnJyVywYEHz//3f/5nPnz9vPeajjz4yV69e3ezj42N2dXU1lypVyvzxxx+bY2NjH5hTbIvJbLahryVFbEzbtm21jIXIQ7Rr1449e/akaiymiEh2pvMGEUkPGpMuctutW7eS/X7kyBEWL15MgwYNjAkkkgWcP3+eRYsW0bVrV6OjiIhkKp03iEhGUUu6yG158+alR48eFC1alJMnT/Ldd98RExPDrl27UqzhKZLThYaGsmHDBn788Ue2bdvGsWPHCAwMNDqWiEim0XmDiGQUTRwnclvz5s2ZOXMmFy5cwNnZmZo1a/LJJ5/og1bkHtasWUPPnj0pWLAgP/30kwp0EclxdN4gIhlFLekiIiIiIiIiNkJj0kVERERERERshIp0ERERERERERuR48akJyYmcu7cOTw9PTGZTEbHERERwWw2c/PmTfLly4ednb4/Tw/6vBcREVuSls/6HFeknzt3jqCgIKNjiIiIpHD69GkKFChgdIxsQZ/3IiJii1LzWZ/jinRPT0/A8uJ4eXkZnEZERATCw8MJCgqyfkbJ49PnvYiI2JK0fNbnuCI9qcubl5eXPrRFRMSmqFt2+tHnvYiI2KLUfNZr4JuIiIiIiIiIjVCRLiIiIiIiImIjVKSLiIiIiIiI2AhDx6SvXbuWMWPGsGPHDs6fP8/8+fNp27btA2+zevVqBgwYwL59+wgKCuL999+nR48emZJXRDKO2WwmPj6ehIQEo6OIpDt7e3scHBw05tyG6D1HMor+v4vI4zK0SI+MjKRixYr06tWLZ5999qHHh4aG0qpVK1555RWmT5/OypUr6dOnD3nz5qVZs2aZkFhEMkJsbCznz58nKirK6CgiGcbNzY28efPi5ORkdJQcT+85ktH0/11EHoehRXqLFi1o0aJFqo+fOHEiRYoUYdy4cQCULl2a9evX88UXX6hIF8miEhMTCQ0Nxd7ennz58uHk5KTWB8lWzGYzsbGxXL58mdDQUIoXL46dnUabGUXvOZKR9P9dRNJDllqCbdOmTTRp0iTZvmbNmtG/f//73iYmJoaYmBjr7+Hh4RkVT0QeQWxsLImJiQQFBeHm5mZ0HJEM4erqiqOjIydPniQ2NhYXFxejI+VYes+RjKb/7yLyuLLUV3sXLlwgICAg2b6AgADCw8O5devWPW8zevRovL29rZegoKDMiCoiaaSWBsnu9DduW/TvIRlJf18i8jiy/TvIkCFDCAsLs15Onz5tdCQRERERERGRe8pS3d0DAwO5ePFisn0XL17Ey8sLV1fXe97G2dkZZ2fnzIgnIiIiIiIi8liyVEt6zZo1WblyZbJ9y5cvp2bNmgYlEhFJX4ULF2b8+PGpPn716tWYTCZu3LiRYZlEJPvSe46IiO0xtEiPiIggJCSEkJAQwLLEWkhICKdOnQIsXdW7detmPf6VV17h+PHjvPPOOxw8eJBvv/2WOXPm8NZbbxkRX0RyMJPJ9MDLiBEjHul+t23bxssvv5zq42vVqsX58+fx9vZ+pMd7FKVKlcLZ2ZkLFy5k2mOK5HQ57T1HXwaISE5maHf37du307BhQ+vvAwYMAKB79+5MmzaN8+fPWwt2gCJFirBo0SLeeustvvzySwoUKMCPP/6o5ddEJNOdP3/euj179myGDx/OoUOHrPs8PDys22azmYSEBBwcHv6Wmzt37jTlcHJyIjAwME23eRzr16/n1q1bPPfcc/z0008MHjw40x77XuLi4nB0dDQ0g0hmyKnvOSIiOZGhLekNGjTAbDanuEybNg2AadOmsXr16hS32bVrFzExMRw7dowePXpkeu70YDabuRgezZbjV5mz/TRjlh6k74ydtP9uI18sP0x0XILREUUMYzabiYqNN+RiNptTlTEwMNB68fb2xmQyWX8/ePAgnp6eLFmyhCpVquDs7Mz69es5duwYzzzzDAEBAXh4eFCtWjVWrFiR7H7/2/XUZDLx448/0q5dO9zc3ChevDgLFy60Xv/f1qZp06bh4+PD0qVLKV26NB4eHjRv3jzZCX58fDxvvPEGPj4++Pn5MXjwYLp3707btm0f+rwnT55M586d6dq1K1OmTElx/ZkzZ+jUqRO5cuXC3d2dqlWrsmXLFuv1f/75J9WqVcPFxQV/f3/atWuX7LkuWLAg2f35+PhYPxNOnDiByWRi9uzZ1K9fHxcXF6ZPn87Vq1fp1KkT+fPnx83NjfLlyzNz5sxk95OYmMhnn31GsWLFcHZ2pmDBgnz88ccANGrUiH79+iU7/vLlyzg5OaUYYiXZk95zxlt/t7X3nPu5fv063bp1w9fXFzc3N1q0aMGRI0es1588eZI2bdrg6+uLu7s7ZcuWZfHixdbbdunShdy5c+Pq6krx4sWZOnXqI2eRLOLMDvi5LVzYY3QSkYfKUhPHZTUJiWbOh93i5NUoTlyN5NTtnyevRnHyahS37lOI7zh5nb/+Pcf/2legauFcmZxaxHi34hIoM3ypIY+9f1Qz3JzS563x3XffZezYsRQtWhRfX19Onz5Ny5Yt+fjjj3F2dubnn3+mTZs2HDp0iIIFC973fkaOHMlnn33GmDFjmDBhAl26dOHkyZPkynXv94eoqCjGjh3LL7/8gp2dHS+++CKDBg1i+vTpAPzvf/9j+vTpTJ06ldKlS/Pll1+yYMGCZD2b7uXmzZv89ttvbNmyhVKlShEWFsa6deuoW7cuYBnCVL9+ffLnz8/ChQsJDAxk586dJCYmArBo0SLatWvH0KFD+fnnn4mNjbWeNKf1dR03bhyVK1fGxcWF6OhoqlSpwuDBg/Hy8mLRokV07dqV4OBgqlevDliGT02aNIkvvviCOnXqcP78eQ4ePAhAnz596NevH+PGjbNONPrrr7+SP39+GjVqlOZ8kvXoPSc5W3nPeZAePXpw5MgRFi5ciJeXF4MHD6Zly5bs378fR0dH+vbtS2xsLGvXrsXd3Z39+/dbexsMGzaM/fv3s2TJEvz9/Tl69Oh9l/KVbGTHVDi+CnZNhxafGp1G5IFUpD+muIREzl6/laz4Pnk1khNXIzl97RaxCYn3va2dCQr4ulHIz3Ip7OeOs4MdX648yrHLkXT4fhPdaxbm7WYlcXfWP5VIVjNq1CiaNm1q/T1XrlxUrFjR+vuHH37I/PnzWbhwYYqW3Lv16NGDTp06AfDJJ5/w1VdfsXXrVpo3b37P4+Pi4pg4cSLBwcEA9OvXj1GjRlmvnzBhAkOGDLG2Yn/99depKpZnzZpF8eLFKVu2LAAdO3Zk8uTJ1iJ9xowZXL58mW3btllP5osVK2a9/ccff0zHjh0ZOXKkdd/dr0dq9e/fn2effTbZvkGDBlm3X3/9dZYuXcqcOXOoXr06N2/e5Msvv+Trr7+me/fuAAQHB1OnTh0Ann32Wfr168cff/zB888/D1haB3v06IHJZEpzPhGjZLf3nPtJKs43bNhArVq1AJg+fTpBQUEsWLCADh06cOrUKdq3b0/58uUBKFq0qPX2p06donLlylStWhWw9CaQHODG7SG0YVqOWWyfKr/HMOrP/fy06QQJiffvquZobyIolxuFcrlRyM+dwn5uFPJ3p7CfO/l9XHFySDni4OmK+flo0X5+23GGaRtPsHz/RT5uV44GJfNk5NMRsRmujvbsH2XMXBOujvbpdl9JJ4BJIiIiGDFiBIsWLeL8+fPEx8dz69atZHNv3EuFChWs2+7u7nh5eXHp0qX7Hu/m5mY9WQbImzev9fiwsDAuXrxobWEGsLe3p0qVKtYW7/uZMmUKL774ovX3F198kfr16zNhwgQ8PT0JCQmhcuXK921tCwkJ4aWXXnrgY6TGf1/XhIQEPvnkE+bMmcPZs2eJjY0lJiYGNzc3AA4cOEBMTAyNGze+5/25uLhYu+8///zz7Ny5k7179ybr4ivZm95zkrOV95z7OXDgAA4ODtSoUcO6z8/Pj5IlS3LgwAEA3njjDV599VWWLVtGkyZNaN++vfV5vfrqq7Rv356dO3fy1FNP0bZtW2uxL9nYjZPJf4rYMBXpj8HTxYGERDPODna3W8NvF+F+liK8kJ8b+XxcsbdLW0uMt5sjYzpU5OlK+Rgybw9nrt+ix9RtPPtEfoa1KoOvu1MGPSMR22AymdKt+6eR3N3dk/0+aNAgli9fztixYylWrBiurq4899xzxMbGPvB+/jsxmslkeuDJ7b2OT+241/vZv38/mzdvZuvWrckmi0tISGDWrFm89NJLuLq6PvA+Hnb9vXLGxcWlOO6/r+uYMWP48ssvGT9+POXLl8fd3Z3+/ftbX9eHPS5YurxXqlSJM2fOMHXqVBo1akShQoUeejvJHvSek5wtvOc8rj59+tCsWTMWLVrEsmXLGD16NOPGjeP111+nRYsWnDx5ksWLF7N8+XIaN25M3759GTt2rKGZJQMlJkDYGcv2DbWki+3LUuuk25quNQuxeUhjDoxqzrK36jOpW1WGtirDi08Wok5xf4JyuaW5QL9b3eK5WfZWPXrVLoLJBPN2nqXpF2v4699zhn/4iUjabdiwgR49etCuXTvKly9PYGAgJ06cyNQM3t7eBAQEsG3bNuu+hIQEdu7c+cDbTZ48mXr16rF7927r0pkhISEMGDCAyZMnA5bWt5CQEK5du3bP+6hQocIDJ2LLnTt3ssmmjhw5QlRU1EOf04YNG3jmmWd48cUXqVixIkWLFuXw4cPW64sXL46rq+sDH7t8+fJUrVqVSZMmMWPGDHr16vXQxxWxdVn5PedBSpcuTXx8fLJJKa9evcqhQ4coU6aMdV9QUBCvvPIK8+bNY+DAgUyaNMl6Xe7cuenevTu//vor48eP54cffnjkPJIFhJ+DxHjLdvQNiA43NI7Iw2T9r40N5O/hnOGP4ebkwPA2ZWhdMS+D5/7LkUsR9Juxiz/KnOOjtuUI8HLJ8Awikj6KFy/OvHnzaNOmDSaTiWHDhj1yd8/H8frrrzN69GiKFStGqVKlmDBhAtevX7/v+Ou4uDh++eUXRo0aRbly5ZJd16dPHz7//HP27dtHp06d+OSTT2jbti2jR48mb9687Nq1i3z58lGzZk0++OADGjduTHBwMB07diQ+Pp7FixdbW+YbNWrE119/Tc2aNUlISGDw4MGpWl6tePHizJ07l40bN+Lr68vnn3/OxYsXrSfrLi4uDB48mHfeeQcnJydq167N5cuX2bdvH7179072XPr164e7u3uyWedFsqqs+p5ztz179uDp6Wn93WQyUbFiRZ555hleeuklvv/+ezw9PXn33XfJnz8/zzzzDGCZu6JFixaUKFGC69evs2rVKkqXLg3A8OHDqVKlCmXLliUmJoa//vrLep1kUzf+M8Qj7DS4lDUmi0gqqCU9i3iioC9/vVGHNxsXx9HexPL9F2ny+Rpmbj2lVnWRLOLzzz/H19eXWrVq0aZNG5o1a8YTTzyR6TkGDx5Mp06d6NatGzVr1sTDw4NmzZrh4nLvL/0WLlzI1atX71m4li5dmtKlSzN58mScnJxYtmwZefLkoWXLlpQvX55PP/0Ue3vLmNsGDRrw22+/sXDhQipVqkSjRo3YunWr9b7GjRtHUFAQdevWpXPnzgwaNMg6rvxB3n//fZ544gmaNWtGgwYNCAwMTLG007Bhwxg4cCDDhw+ndOnSvPDCCynG2Hbq1AkHBwc6dep039dCJCvJqu85d6tXrx6VK1e2XqpUqQLA1KlTqVKlCq1bt6ZmzZqYzWYWL15s/WIvISGBvn37Urp0aZo3b06JEiX49ttvActa70OGDKFChQrUq1cPe3t7Zs2alXEvgBjvv0X6f38XsTEmcw6r8MLDw/H29iYsLAwvLy+j4zySgxfCGTz3X3afCQOgZlE/Rj9bnsL+7g+5pYjtiY6OJjQ0lCJFiqgwMkhiYiKlS5fm+eef58MPPzQ6jmFOnDhBcHAw27Zty5BC5kF/69nhs8nW3O811XuO8XLCe47+zmzM6k9h9eg7v7cYAzVeNi6P5Ehp+axXS3oWVCrQi3mv1eb9VqVxcbRj0/GrNP9yLT+sPUb8A5Z8ExEBOHnyJJMmTeLw4cPs2bOHV199ldDQUDp37mx0NEPExcVx4cIF3n//fZ588klDWhpFsjO954jhklrOTbdXU9AM72LjVKRnUfZ2JvrULcqy/vWpFexHdFwinyw+yLPfbeTAeU2GISL3Z2dnx7Rp06hWrRq1a9dmz549rFixIseOydywYQN58+Zl27ZtTJw40eg4ItmO3nPEcNdvF+X5Klt+aq10sXGaOC6LK+jnxvQ+NZiz/TQfLTrAv2fCaDNhPa81CKZvo2I4O6Tf+qsikj0EBQWxYcMGo2PYjAYNGmhuD5EMpPccMVxSS3rh2nB2u8aki81TS3o2YDKZeKFaQVYMqM9TZQKITzTz1T9HafXVenacvPdSSCIiIiIi2V5CHITfXiO9cF3LT62VLjZORXo2EuDlwvddq/Btlyfw93Dm6KUInpu4idFLDqiVSERERERynvCzYE4Ee2coUNWyL+oKxEYam0vkAVSkZzMmk4mW5fOyYkA9nqtSALMZvl9znJF/7lehLiIiIiI5S1LXdp8gcPUFZ2/L72FnjMsk8hAq0rMpHzcnxnaoyJjnKgAwbeMJ/vf3IRXqIiIiIpJzJE0a51Po9s8gy0+NSxcbpiI9m+tQNYiP2pYDYOKaY3y58ojBiUREREREMom1Jb1g8p8q0sWGqUjPAV58shDDWpcBYPyKI0xcc8zgRCIiIqn36aefYjKZ6N+/v9FRRCSrSVoTPak491ZLutg+Fek5RO86RXi7WUkAPl1ykGkbQg1OJCJgWf7r7sKjcOHCjB8//oG3MZlMLFiw4LEfO73uRyQjbdu2je+//54KFSoYHSVb0HuO5DhJxbhvUnf328W61koXG6YiPQfp27AYbzQqBsCIP/czc6u+QRR5VG3atKF58+b3vG7dunWYTCb+/fffNN/vtm3bePnllx83XjIjRoygUqVKKfafP3+eFi1apOtj3c+tW7fIlSsX/v7+xMTEZMpjStYXERFBly5dmDRpEr6+vg88NiYmhvDw8GSX7ETvOakzbdo0fHx8MvQxJIuxdnfXmHTJOlSk5zBvNS3BS3WLAPDe/D3M36WZLUUeRe/evVm+fDlnzqT8PzR16lSqVq36SC1/uXPnxs3NLT0iPlRgYCDOzs6Z8li///47ZcuWpVSpUoa3pJnNZuLj4w3NIKnTt29fWrVqRZMmTR567OjRo/H29rZegoKCMiFh5tF7jsgjiI+B8HOWbZ//tKRrrXSxYSrScxiTycR7LUvTrWYhzGYYOGc3i/ecNzqWSHJms2X9UiMuqVwBoXXr1uTOnZtp06Yl2x8REcFvv/1G7969uXr1Kp06dSJ//vy4ublRvnx5Zs6c+cD7/W/X0yNHjlCvXj1cXFwoU6YMy5cvT3GbwYMHU6JECdzc3ChatCjDhg0jLi4OsLQqjRw5kt27d2MymTCZTNbM/+16umfPHho1aoSrqyt+fn68/PLLREREWK/v0aMHbdu2ZezYseTNmxc/Pz/69u1rfawHmTx5Mi+++CIvvvgikydPTnH9vn37aN26NV5eXnh6elK3bl2OHbszf8aUKVMoW7Yszs7O5M2bl379+gFw4sQJTCYTISEh1mNv3LiByWRi9erVAKxevRqTycSSJUuoUqUKzs7OrF+/nmPHjvHMM88QEBCAh4cH1apVY8WKFclyxcTEMHjwYIKCgnB2dqZYsWJMnjwZs9lMsWLFGDt2bLLjQ0JCMJlMHD169KGviTzYrFmz2LlzJ6NHj07V8UOGDCEsLMx6OX06DSfges+x/p5d3nPu59SpUzzzzDN4eHjg5eXF888/z8WLF63X7969m4YNG+Lp6YmXlxdVqlRh+/btAJw8eZI2bdrg6+uLu7s7ZcuWZfHixY+cRTJB2BnADI5u4O5v2ed9u0iPuABx0YZFE3kQB6MDSOYzmUyMaFOW6LgE5mw/wxszd+Fkb0eTMgFGRxOxiIuCT/IZ89jvnQMn94ce5uDgQLdu3Zg2bRpDhw7FZDIB8Ntvv5GQkECnTp2IiIigSpUqDB48GC8vLxYtWkTXrl0JDg6mevXqD32MxMREnn32WQICAtiyZQthYWH3nDjL09OTadOmkS9fPvbs2cNLL72Ep6cn77zzDi+88AJ79+7l77//thag3t7eKe4jMjKSZs2aUbNmTbZt28alS5fo06cP/fr1S1YUrFq1irx587Jq1SqOHj3KCy+8QKVKlXjppZfu+zyOHTvGpk2bmDdvHmazmbfeeouTJ09SqJClVePs2bPUq1ePBg0a8M8//+Dl5cWGDRusrd3fffcdAwYM4NNPP6VFixaEhYWxYcOGh75+//Xuu+8yduxYihYtiq+vL6dPn6Zly5Z8/PHHODs78/PPP9OmTRsOHTpEwYKWk7hu3bqxadMmvvrqKypWrEhoaChXrlzBZDLRq1cvpk6dyqBBg6yPMXXqVOrVq0exYsXSnE/uOH36NG+++SbLly/HxcUlVbdxdnZ+9FZavecA2ec950HPL6lAX7NmDfHx8fTt25cXXnjB+qVely5dqFy5Mt999x329vaEhITg6OgIWHp2xMbGsnbtWtzd3dm/fz8eHh5pziGZ6O5J427/n8EtFzi6Q1wkhJ8Fv2Dj8onch4r0HMrOzsToZysQE5/IHyHneG36Tib3qErd4rmNjiaSZfTq1YsxY8awZs0aGjRoAFiKtPbt21u73N5dwL3++ussXbqUOXPmpOqEecWKFRw8eJClS5eSL5+lgPjkk09SjOl8//33rduFCxdm0KBBzJo1i3feeQdXV1c8PDxwcHAgMDDwvo81Y8YMoqOj+fnnn3F3txQMX3/9NW3atOF///sfAQGWL/F8fX35+uuvsbe3p1SpUrRq1YqVK1c+8IR5ypQptGjRwjqmuFmzZkydOpURI0YA8M033+Dt7c2sWbOsJ8MlSpSw3v6jjz5i4MCBvPnmm9Z91apVe+jr91+jRo2iadOm1t9z5cpFxYoVrb9/+OGHzJ8/n4ULF9KvXz8OHz7MnDlzWL58ubW7ddGiRa3H9+jRg+HDh7N161aqV69OXFwcM2bMSNG6Lmm3Y8cOLl26xBNPPGHdl5CQwNq1a/n666+JiYnB3t7ewITG0HtO6t5z7mflypXs2bOH0NBQ63CIn3/+mbJly7Jt2zaqVavGqVOnePvttylVqhQAxYsXt97+1KlTtG/fnvLlywPJ3w/ERv13+TWwFOs+QXD5oKWIV5EuNkhFeg5mb2diXIeKxMQl8ve+C7z083am9azOk0X9jI4mOZ2jm6V1yajHTqVSpUpRq1YtpkyZQoMGDTh69Cjr1q1j1KhRgKWo+OSTT5gzZw5nz54lNjaWmJiYVI//PHDgAEFBQdaTZYCaNWumOG727Nl89dVXHDt2jIiICOLj4/Hy8kr180h6rIoVK1pPlgFq165NYmIihw4dsp4wly1bNllxlDdvXvbs2XPf+01ISOCnn37iyy+/tO578cUXGTRoEMOHD8fOzo6QkBDq1q1rLdDvdunSJc6dO0fjxo3T9HzupWrVqsl+j4iIYMSIESxatIjz588THx/PrVu3OHXKclIXEhKCvb099evXv+f95cuXj1atWjFlyhSqV6/On3/+SUxMDB06dHjsrDld48aNU/xd9ezZk1KlSjF48OD0L9D1ngNkj/echz1mUFBQsvkKypQpg4+PDwcOHKBatWoMGDCAPn368Msvv9CkSRM6dOhAcLCliHvjjTd49dVXWbZsGU2aNKF9+/ZadcDW3atIT/r98kGNSxebpTHpOZyDvR1fdapMo1J5iI5LpPe0bew4ed3oWJLTmUyW7p9GXJK6w6VS7969+f3337l58yZTp04lODjYWtSNGTOGL7/8ksGDB7Nq1SpCQkJo1qwZsbGx6fZSbdq0iS5dutCyZUv++usvdu3axdChQ9P1Me7230LaZDKRmJh43+OXLl3K2bNneeGFF3BwcMDBwYGOHTty8uRJVq5cCYCrq+t9b/+g6wDs7CwfY+a7xvXeb7zq3cUAwKBBg5g/fz6ffPIJ69atIyQkhPLly1tfu4c9NkCfPn2YNWsWt27dYurUqbzwwguZNglXdubp6Um5cuWSXdzd3fHz86NcuXLp/4B6z0k1W3/PeVwjRoxg3759tGrVin/++YcyZcowf/58wPL//fjx43Tt2pU9e/ZQtWpVJkyYkGFZJB1cT+ruXij5fq2VLjZORbrg5GDHt12eoE4xfyJjE+gxdSt7z4YZHUskS3j++eexs7NjxowZ/Pzzz/Tq1cs6VnTDhg0888wzvPjii1SsWJGiRYty+PDhVN936dKlOX36NOfP35nccfPmzcmO2bhxI4UKFWLo0KFUrVqV4sWLc/LkyWTHODk5kZCQ8NDH2r17N5GRkdZ9GzZswM7OjpIlS6Y6839NnjyZjh07EhISkuzSsWNH6wRyFSpUYN26dfcsrj09PSlcuLC1oP+v3LktQ3Tufo3unkTuQTZs2ECPHj1o164d5cuXJzAwkBMnTlivL1++PImJiaxZs+a+99GyZUvc3d357rvv+Pvvv+nVq1eqHlvkUek959ElPb+7JxXcv38/N27coEyZMtZ9JUqU4K233mLZsmU8++yzTJ061XpdUFAQr7zyCvPmzWPgwIFMmjQpQ7JKOnlQSzporXSxWSrSBQAXR3t+6FaF6oVzcTM6nhcnb+HQhZtGxxKxeR4eHrzwwgsMGTKE8+fP06NHD+t1xYsXZ/ny5WzcuJEDBw7wf//3f8lmEX6YJk2aUKJECbp3787u3btZt24dQ4cOTXZM8eLFOXXqFLNmzeLYsWN89dVX1lafJIULFyY0NJSQkBCuXLlyz3XKu3TpgouLC927d2fv3r2sWrWK119/na5du1q7nabV5cuX+fPPP+nevXuKVtFu3bqxYMECrl27Rr9+/QgPD6djx45s376dI0eO8Msvv3Do0CHA0rI1btw4vvrqK44cOcLOnTutrVeurq48+eSTfPrppxw4cIA1a9YkGy/7IMWLF2fevHmEhISwe/duOnfunKyFrnDhwnTv3p1evXqxYMECQkNDWb16NXPmzLEeY29vT48ePRgyZAjFixe/Z9dgSR+rV69ONgt5TqX3nIdLSEhI8cXggQMHaNKkCeXLl6dLly7s3LmTrVu30q1bN+rXr0/VqlW5desW/fr1Y/Xq1Zw8eZINGzawbds2SpcuDUD//v1ZunQpoaGh7Ny5k1WrVlmvExuVNHGc739a0rVWutg4Feli5ebkwOQeVakU5MONqDi6/LiZY5cjHn5DkRyud+/eXL9+nWbNmiUby/n+++/zxBNP0KxZMxo0aEBgYCBt27ZN9f3a2dkxf/58bt26RfXq1enTpw8ff/xxsmOefvpp3nrrLfr160elSpXYuHEjw4YNS3ZM+/btad68OQ0bNiR37tz3XJLJzc2NpUuXcu3aNapVq8Zzzz1H48aN+frrr9P2YtwlaUKoe40nb9y4Ma6urvz666/4+fnxzz//EBERQf369alSpQqTJk2ydnPt3r0748eP59tvv6Vs2bK0bt2aI0eOWO9rypQpxMfHU6VKFfr3789HH32Uqnyff/45vr6+1KpVizZt2tCsWbNkE5WBZWb55557jtdee41SpUrx0ksvJWv5A8u/f2xsLD179kzrSyTySPSe82ARERFUrlw52aVNmzaYTCb++OMPfH19qVevHk2aNKFo0aLMnj0bsHzpdvXqVbp160aJEiV4/vnnadGiBSNHjgQsxX/fvn0pXbo0zZs3p0SJEnz77bePnVcySNwtiLj9JdV/u7sn/a4x6WKjTGZzKhfozCbCw8Px9vYmLCwszZOc5BRhUXF0mrSZ/efDCfRyYc7/1aSgn8ZYSsaIjo4mNDSUIkWKpHqpJRFbsm7dOho3bszp06cf2AL4oL91fTalv/u9pnrPkcygvzMbcPkwfFMNnDxgyJnk8z/cvAjjSoDJDt6/BPYpJy4VSW9p+axXS7qk4O3myC+9q1M8jwcXwqPpNGkz527cMjqWiIhNiYmJ4cyZM4wYMYIOHTo8dhddERFJR9bx6IVSTtDokQccXMCcaFkrXcTGqEiXe/LzcGb6SzUo4u/O2Ru36DxpM5fCo42OJSJiM2bOnEmhQoW4ceMGn332mdFxRETkbknj0f87aRxYinbvAreP07h0sT0q0uW+8ni6ML1PDQr4unLiahRdftzC1YiUk7+IiOREPXr0ICEhgR07dpA/f36j44iIyN3uN2lckqTiXePSxQapSJcHyufjysyXniTQy4UjlyJ4cfJWwqLuvQaxiIiIiIhNuN/ya0m0VrrYMBXp8lBBudyY8VIN/D2cOXA+nK5TtmiMuqS7HDaHpeRA+hu3Lfr3kIykvy8bcP0B3d3v3q+10sUGqUiXVCma24PpfWrg6+bIv2fCaDZ+LQt2ndWHkDy2pGW2oqKiDE4ikrGS/saT/ubFGHrPkcyg/+824O6J4+7F2t1dLeliexyMDiBZR8lAT+a9Vpv+s0PYffoG/WeHsGz/BT5qW55c7k5Gx5Msyt7eHh8fHy5dugRY1s41/XcWVpEszGw2ExUVxaVLl/Dx8cHe3t7oSDma3nMkI+n/u42IjYSoK5bth7Wkq0gXG6QiXdKkiL87v79Sk+9WH+PLlUdYvOcC205c53/ty9OolJYfkkcTGBgIYD1pFsmOfHx8rH/rYiy950hG0/93gyUV3i7e4Opz72OSxqSHn4XEBLDTFypiO1SkS5o52NvxeuPiNCyVh7dmh3DkUgS9pm2nU/UghrYqg4ez/qwkbUwmE3nz5iVPnjzExWliQsl+HB0d1aJmQ/SeIxlJ/99twMMmjQPwDAQ7R0iMg5vn7yzJJmIDVE3JIyuX35s/X6/D2KWHmLwhlJlbT7P+6BXGdahE9SK5jI4nWZC9vb1ObEQk0+g9RySbsk4ad5/x6GBpOffOD9dPWIp6FeliQzRxnDwWF0d73m9dhhl9niS/jyunr93ihR82MXrxAWLiE4yOJyIiIiI5zY1UFOmgcelis1SkS7qoGezH3/3r8nzVApjN8P3a4zw9YQP7zoUZHU1EREREcpLUdHcH8E4q0rUMm9gWFemSbjxdHPnsuYpM6lYVfw8nDl28SdtvNvDNqqPEJyQaHU9EREREcoKklnTf1Lakn8zYPCJppCJd0l3TMgEs7V+PZmUDiEswM2bpIZ7/fhMnrkQaHU1EREREsrvUtqT73J7hPUwt6WJbVKRLhvDzcGbii1UY16Eins4O7Dx1gxZfruPXzScxm81GxxMRERGR7Cg6HG5dt2w/tEjXmHSxTSrSJcOYTCbaVynA32/Vo2ZRP27FJfD+gr10n7qNC2HRRscTERERkewmqeB2zQXOng8+Nmmt9LAzkKihmWI7VKRLhsvv48r0PjUY3roMzg52rD18mWbj17Jw9zmjo4mIiIhIdmKd2f0hregAXvnBZA8JsRBxMWNziaSBinTJFHZ2JnrVKcKiN+pQPr83YbfieGPmLvrN2MmNqFij44mIiIhIdpDUkv6wSeMA7B3AK59lW+PSxYaoSJdMVSyPJ/Neq8WbjYtjb2fir3/P89QXa1l7+LLR0UREREQkq0vtpHFJNC5dbJCKdMl0jvZ2vNW0BPNerUXR3O5cuhlDtylb+fCv/cTEJxgdT0RERESyqutJ3d1T0ZIOd8alq0gXG6IiXQxTMciHRa/XpeuTljfRyetDafvNRo5cvGlwMhERERHJkqwt6aks0tWSLjZIRboYytXJng/blmNy96rkcnfiwPlwWk9Yzy+bTmipNhERERFJPbP5zsRxqRmTDlorXWySinSxCY1LB/B3/7rUK5GbmPhEhv2xj5d+3s7ViBijo4mIiIhIVhB9A2LCLdtJ3dgfRi3pYoNUpIvNyOPpwrQe1RjWugxO9nasOHCJZuPXsUaTyomIiIjIwyQV2u65wcktdbexjkk/bWmJF7EBKtLFptjZmehdpwh/9KtN8TweXImIofuUrYz6cz/RcZpUTkRsR3h0HBfCoo2OISIiSdI6aRyAdwHABPG3IPJKhsQSSSsV6WKTSuf14s/X69C9puVNdsqGUNp+s4HDmlRORAwWHZfA92uOUe+zVYxYuM/oOCIikiSty68BODiDZ6BlO0xd3sU2qEgXm+XiaM/IZ8oxpUdV/NydOHjhJm0mrOdnTSonIgaIS0jk180nqT9mFaOXHORGVBxHL0cQGRNvdDQREYG0TxqXROPSxcaoSBeb16hUAH/3r0eDkpZJ5Yb/sY/eP23niiaVE5FMkJBoZsGuszQet4b3F+zlYngM+X1cGduhIkv718Pd2cHoiCIiAo/Wkn738Tc0w7vYBp1ZSJaQ29OZqT2qMW3jCUYvOcg/By/RfPw6xnaoQIOSeYyOJyLZkNlsZsWBS4xdeohDt4fa+Hs40a9hMTrVKIizg73BCUVEJJlHLdKtk8epJV1sg4p0yTJMJhM9axehZrAfb8zcxeGLEfSYuo2etQszuHkpXBx1wiwi6WPjsSuMWXqIXaduAODl4sD/1Q+mZ+3CuDnpo1NExOaYzXdNHFc4bbdNKuq1VrrYCJ1pSJZTKtCLhf3q8OmSg0zbeIKpG06w6dhVvuxYmZKBnkbHE5EsbPfpG4xddoh1Rywz/Lo62tOzdmH+r14w3m6OBqcTEZH7iroGcZGWbe8Cabutj1rSxbaoSJcsycXRnhFPl6V+idy8PXe3ZVK5r9cztGVputUshMlkMjqiiGQhRy7eZOyyQyzddxEAR3sTnasXpG+jYuTxdDE4nYiIPNSNE5afnnnBMY3v20lLtiWtla7zSDGYinTJ0hqWysOSN+vxztzdrDp0mQ8W7mP1oUt89lxFcns6Gx1PRGzc6WtRfLHiMAt2nSXRDHYmaFe5AP2bFCcol5vR8UREJLUedTw63Gl5j70Jt66DW670yyXyCFSkS5aX29OZKT2q8dPGE3yy5CCrDl3mqS/W8FHb8rSqkNfoeCJigy7djObrf44yc+sp4hIsSzo2LxvIwKdKUDxAw2ZERLIc63j0NC6/BuDoCu55IPKSZVy6inQxmIp0yRZMJhM9ahehZrA//WeHcOB8OH1n7GTJ3ryMeqYcudydjI4oIjYgLCqOiWuPMXVDKNFxiQDULe7PoKdKUjHIx9hwIiLy6B6nJR0s49IjL1nuJ2/F9Msl8ghUpEu2UjLQkz/61ubrf47wzepj/PXveTYfv8on7crzVNlAo+OJiAHiEhI5cjGClQcu8sO649yMjgegckEf3m5WklrB/gYnFBGRx/bYRXpBOLtDa6WLTVCRLtmOk4MdA54qSZMyAQycs5sjlyJ4+ZcdPFs5Px+0KasZmkWysbiERA5fvMnes2HsORvGnrPhHDwfTkx8ovWYkgGeDGpWkial82iSSRGR7OLG7e7uvo/Q3R20VrrYFBXpkm1VKODDn6/XYfyKI/yw9hjzdp1lw7ErfPpsBRqWymN0PBF5TLHxyQvyvWfDOHDhJrF3FeRJPJwdKJffi47VCtKmYj7s7VSci4hkG2Zz+rSkg9ZKF5tgeJH+zTffMGbMGC5cuEDFihWZMGEC1atXv+/x48eP57vvvuPUqVP4+/vz3HPPMXr0aFxctESOpOTiaM+7LUrxVNkABs3ZzfErkfScto3nqxbg/dZl8HJRq7rIozCbzVyOiOHElShOXInk+JVIImPi8XJ1wMvFES9Xx9s/7/7dAU8XR5wc7NL8eEkF+Z67CvKD528Sm5CyIPd0caBcPm/KF/CmXH5vyuf3plAuN+xUmIuIZE8RlyA+Gkx24JXGNdKTJBXpSS3yIgYytEifPXs2AwYMYOLEidSoUYPx48fTrFkzDh06RJ48KVs6Z8yYwbvvvsuUKVOoVasWhw8fpkePHphMJj7//HMDnoFkFU8U9GXxm3UZs/QQUzaEMmf7GdYfucJnz1WkTnGNRxW5n+uRsRy/EsmJK5GcuBpJ6BXL5eTVKCJi4h/pPl0c7ZIV7vcu6B1JNJvZdy6cvWfDOHTh/gV5+duFeFJBXlAFuYhIzpLUiu6ZDxwecbJga5GulnQxnqFF+ueff85LL71Ez549AZg4cSKLFi1iypQpvPvuuymO37hxI7Vr16Zz584AFC5cmE6dOrFly5ZMzS1Zk4ujPcNal6FZ2UDenrubk1ejeHHyFrrUKMh7LUvj7mx4xxIRQ4RHx3HidvF94koUoVciCL1qaSEPuxV339uZTJDfx5Ui/u4U8XfHx9WR8Oh4wqPjCL+V9DOOm9Hxlp+3i/rouESi42K4dDMmTTm9XByStY4nFeQaVy4iksMltX4/ald3uDMmPfoGRIeDi9djxxJ5VIZVJbGxsezYsYMhQ4ZY99nZ2dGkSRM2bdp0z9vUqlWLX3/9la1bt1K9enWOHz/O4sWL6dq1630fJyYmhpiYOyeC4eHh6fckJEuqXiQXS96sy6dLDvLzppNM33KKtUcuM+a5ijxZ1M/oeCIZ5mZ0HAfO3+TA+XD2nwvn2OUITlyN5EpE7ANvF+jlQhF/dwr7u1PE343Cfu4Uze1OUC43nB3sU/34CYlmIm4X8WG34lIU8+G3i/mk/QmJiZQM9LIW5EG5XFWQi4hISo87aRyAswe45oJb1yzj0l3Kpk82kUdgWJF+5coVEhISCAgISLY/ICCAgwcP3vM2nTt35sqVK9SpUwez2Ux8fDyvvPIK77333n0fZ/To0YwcOTJds0vW5+bkwKhnytG8bCBvz/2X09du0fGHzfSoVZjBzUvh6pT6wkPE1pjNZs6FRXPgXDj7bxfk+8+Hc+pa1H1v4+/hbC3AC/u7U/R2UV7Izw03p/T5qLC3M+Ht5oi3myNB6XKPIiIiPP6kcUl8gixF+o1TEKAiXYyTpfr3rl69mk8++YRvv/2WGjVqcPToUd58800+/PBDhg0bds/bDBkyhAEDBlh/Dw8PJyhIp4diUauYP3/3r8sniw8wc+tppm08wepDlxj3fEWqFMpldDyRh4pLSOTopQhrIZ70837d1PN6u1Amrxdl8nlRLI8HRf09KOzvhqcmURQRkazqelJ398doSQdLkX9+t8ali+EMK9L9/f2xt7fn4sWLyfZfvHiRwMDAe95m2LBhdO3alT59+gBQvnx5IiMjefnllxk6dCh2dilnDHZ2dsbZ2Tn9n4BkG54ujox+tgLNy+Vl8Nx/OXE1iucmbuKlukUZ0LQELo5qVRfbEHYrztpVff/5cA6cD+fIxYh7TqjmYGeiWB4Pa0FeJq8XpfN64ev+iBPqiIiI2Kr0akn31gzvYhsMK9KdnJyoUqUKK1eupG3btgAkJiaycuVK+vXrd8/bREVFpSjE7e0tBZTZbM7QvJL91S+Rm6Vv1WPUn/v5fecZflh7nJUHLjLu+UpUCvIxOp7kYIcu3OSNmbs4dPHmPa/3dHag9O1CPKkgLx7gkabx4iIiIllSYuKdtc0fZ0w6aK10sRmGdncfMGAA3bt3p2rVqlSvXp3x48cTGRlpne29W7du5M+fn9GjRwPQpk0bPv/8cypXrmzt7j5s2DDatGljLdZFHoe3qyPjnq9I83KBvDd/D8cuR9L+u428VLcobzQulm5jc0VSKyo2nlen7+D45UjAMpt6mf8U5AV8NaGaiIjkUBEXICEWTPaWJdgeh8/tIbFJLfMiBjG04njhhRe4fPkyw4cP58KFC1SqVIm///7bOpncqVOnkrWcv//++5hMJt5//33Onj1L7ty5adOmDR9//LFRT0GyqaZlAqhayJcPFu5j4e5zTFxzjD93n2N4mzI8VSZABZFkmhEL93H8ciQBXs780bcOgd4uRkcSERGxHUkFtXd+sH/M0kZrpYuNMJlzWD/x8PBwvL29CQsLw8tL6x/Kwy3bd4GRf+7n7I1bADQsmZuRT5ejoJ+bwckku/sj5CxvzgrBZILpfWpQK9jf6EiSQfTZlP70morkELtnw/yXoXBd6PHX493XrRvwv9td5t87B07ujx1PJElaPpdSzrQmIsk8VTaQFQPq07dhMI72JlYdukyTL9bw5YojRMclGB1PsqmTVyMZOn8vAK83LKYCXURE5F6sk8Y95nh0AFcfcPa2bIedefz7E3lEKtJFUsHVyZ63m5ViyZv1qF3Mj9j4RL5YcZhm49ey+tAlo+NJNhMbn8gbM3cRERNPtcK+vNG4uNGRREREbFPSTOyPO2lcEo1LFxugIl0kDYrl8eDX3jWY0KkyeTydOXk1ih5Tt/HKLzs4d7s7vMjjGrfsELvPhOHt6sj4jpVxsNdbtc3KWSPGRERsT1KR/rjLryWxjktXkS7G0VTVImlkMploUzEfDUrmZvyKI0zbeIK/911g7ZHLvNG4OL1qF8HJQUWVPJo1hy/z/drjAPyvfQXy+7ganEis4m7BxX1wbhecD4Fzu8G7AHSeZXQyEZGcK73WSE/irZZ0MZ6KdJFH5OniyLDWZXiuSgGGLdjL9pPX+XTJQebuOMOHz5SjZrCf0REli7l0M5qBc0IAePHJgjQvF2hsoJwsNgou7oVzIXB+t6Uov3QAzP+Zh+LmeUtrulZ8EBHJfIkJd8aOp8eYdFBLutgEFekij6l0Xi/m/F9Nft95hk+XHOTopQg6TdpM20r5eK9VafJ4asksebjERDMD5+zmSkQspQI9eb9VGaMj5RyxkXBh7+3W8RDLz8uHUhbkAG7+kK8S5K1056eIiBgj/BwkxoOdI3im0xfbSWPSw7QMmxhHRbpIOrCzM9GhahBPlQlkzLKDTN9yigUh51h54BIDnyrBi08W0rhieaDv1x5n3ZEruDjaMaFTZVwc7Y2OlD3FRMCFPckL8iuHwZyY8lj3PCkLcq98ajUXEbEV1vHoQWCXTp+bakkXG6AiXSQdebs58lHb8jxfNYhhC/ay+0wYI/7cz5ztZ/ioXTmeKOhrdESxQbtOXWfcskMAjGhTluIBngYnyoISEyHqKkRchMhLEHHJsh1x13b4Obh6FLjHZG8egbcL8Yp3inLPvCrIRURsWXqPRwfwvn1fERchLhoc1SNSMp+KdJEMUKGAD/Neq83MracYs/QQ+8+H8+y3G3mhahCDW5Qil7uT0RHFRoRHx/H6zF3EJ5ppVSEvL1QLMjqS7TCbIfoGRFy+XXDfLrqTFeEXLddHXr539/R78cybvHU8X6X06yYpIiKZJyOKdLdc4OgOcZGW8e7+xdLvvkVSSUW6SAaxtzPx4pOFaFEukE+XHOS3HWeYvf00S/dfYHDzUrxQNQg7O7XS5WRms5n35u3hzPVbFPB1ZfSz5TGp5dZiyw+wfDjEp3FpQzc/8AgAjzyWn+65b/9+e1+eMuAZkDGZRUQkc11P6u6eTpPGgaUHlU8QXD4IYadUpIshVKSLZDA/D2fGdKjIC9WCeH/BXg5euMmQeXuYtfUUI58pR6UgH6MjikHmbD/NX/+ex97OxFedKuPl4mh0JNuQmAjrv7hToDt73ym6PXL/pwjPc9e2P9jrNRQRyTGsLenpWKSDpWX+8kGNSxfDqEgXySRVC+fir9fr8NOmk4xffpjdZ8Jo+80Gnq9agHeal8Lfw9noiJKJjl66yQcL9wEw8KkSmq/gbud2wc1zlu6GAw+Ci5fRiURExBYlTRznm85FunWtdM3wLsbQdNMimcjB3o7edYqwclB92j9RAIA528/QcOxqpm0IJT7hHjNMS7YTHZdAvxm7iI5LpE4xf16pF2x0JNtyYKHlZ4mnVKCLiMi9JcRB+FnLdnqOSb/7/tSSLgZRkS5igDyeLox7viK/v1qTsvm8uBkdz4g/99N6wnq2HL9qdDzJYB8vOsDBCzfx93Di8xcqam6Cu5nNcOBPy3bpNsZmERER2xV+1rJ8poOLZchTetJa6WIwFekiBqpSKBcL+9Xho7bl8HFz5OCFm7zww2b6z9rFxfBoo+NJBvh77wV+2Wzpnjfu+Urk8dTSLslcPgjXjoG9ExRranQaERGxVUmTxnkHpf9ymUlj3NWSLgZRkS5isKRZ4FcNbEDnGgUxmWBByDkajV3N92uOERuvLvDZxdkbtxj8+78AvFyvKPVL5DY4kQ1KakUv2lBd3UVE5P4yYvm1JElj0m+eh/jY9L9/kYdQkS5iI3zdnfikXXkW9q1D5YI+RMYmMHrJQZp/uZZ1Ry4bHU8eU3xCIv1n7SLsVhwVC3gz6KmSRkeyTUnj0dXVXUREHiSjJo0Dy6ohDi6W7vRJ495FMpGKdBEbU76AN7+/Uosxz1XA38OJ45cj6Tp5K6/8soMz16OMjieP6Kt/jrLtxHU8nB34qlNlnBz09pvC9RNwYQ+Y7KBkS6PTiIiILcvIlnSTCbwtE/xqXLoYQWeJIjbIzs5Eh6pBrBzYgJ61C2NvZ+LvfRdo8vkavlp5hOi4BKMjShpsPn6Vr/85AsDH7cpRyM/d4EQ26sBflp+FaoO7n7FZRETEtmXUGulJNMO7GEhFuogN83Z15IM2ZVn0Rh1qFMlFdFwiny8/zFNfrGXF/ouYzWajI8pDXI+Mpf+sEBLN0KFKAZ6plN/oSLZLs7qLiEhqJU0cl1FFutZKFwOpSBfJAkoFejHr5SeZ0KkygV4unLoWRZ+ft9Nr2jZCr0QaHU/uw2w28/bc3VwIj6ZobndGPlPW6Ei26+YFOL3Fsl2qlbFZRETEtsXHWCZ1g4zp7n73/aolXQygIl0kizCZTLSpmI+VA+vzSv1gHO1NrDp0mWZfrOWzvw8SERNvdET5j2kbT7DiwCWc7O2Y0Kkybk4ORkeyXQcXAWbIX+XOOEDJsb777jsqVKiAl5cXXl5e1KxZkyVLlhgdS0RsRdgZwAyObuDunzGPkVSka0y6GEBFukgW4+7swLstSvF3/3rULe5PbEIi364+RoMxq/l180niE7Rkmy3YezaM0YsPAvBey1KUzedtcCIbp67ucpcCBQrw6aefsmPHDrZv306jRo145pln2Ldvn9HRRMQWJM3s7lMw/ddIT2JtST+ZMfcv8gAq0kWyqODcHvzcqzrfd61CYT83rkTE8P6CvTQbv5blGq9uqMiYeN6YuYvYhESalA6ge63CRkeybbeuw4l1lu1SKtIF2rRpQ8uWLSlevDglSpTg448/xsPDg82bNxsdTURsQUaPR4c7Y9LDz0GCeitK5lKRLpKFmUwmmpUNZNlb9RnRpgy+bo4cuxzJSz9v54UfNrP79A2jI+ZIY5Ye4viVSAK9XBjzXAVMGfUtf3ZxeCkkxkPu0uBfzOg0YmMSEhKYNWsWkZGR1KxZ877HxcTEEB4enuwiItlURi6/lsQzEOwcLZ9PSePfRTKJinSRbMDJwY4etYuw5p2GvNogGGcHO7aGXuOZbzbw+sxdnL6m9dUzy+lrUUzfYvmGf0yHCvi6OxmcKAtQV3e5hz179uDh4YGzszOvvPIK8+fPp0yZMvc9fvTo0Xh7e1svQUFBmZhWRDJVUpHum4Et6Xb24H17RRaNS5dMpiJdJBvxcnFkcPNSrBrUgGefyI/JBH/uPkfjcWv46K/93IiKNTpitvfF8sPEJZipW9yfusVzGx3H9sVGwtEVlm0V6XKXkiVLEhISwpYtW3j11Vfp3r07+/fvv+/xQ4YMISwszHo5fVon1SLZ1t1j0jOSZngXg6hIF8mG8vm48vnzlfjr9TrUKWaZXO7H9aHU+2wVk9YeJyY+weiI2dKhCzeZH3IWgLeblTQ4TRZxdAXER1vGFQaWNzqN2BAnJyeKFStGlSpVGD16NBUrVuTLL7+87/HOzs7W2eCTLiKSTWVGd3cA76QiXV/6SeZSkS6SjZXN580vvaszrWc1SgV6Eh4dz8eLD9B43Br+CDlLYqIml0tPY5YewmyGFuUCqVDAx+g4WcPdXd01dl8eIDExkZiYGKNjiIjR4m5BxEXLdkZOHAea4V0Mo0V7RbI5k8lEg5J5qFs8N7/vOMO45Yc4c/0Wb84KYfL6UN5rWZoni/oZHTPL23HyOisOXMTOBAOfUit6qsTHWiaNAyj9tLFZxKYMGTKEFi1aULBgQW7evMmMGTNYvXo1S5cuNTqaiBgtqVXbyRNcfTP2sXxuz22hMemSyVSki+QQ9nYmnq8WROuKeZm8LpSJa47x75kwOv6wmSal8/Bui1IUy+NpdMwsyWw289nfljXRn6tSgGJ5PAxOlEWEroWYcPAIgALVjE4jNuTSpUt069aN8+fP4+3tTYUKFVi6dClNmzY1OpqIGO3uSeMyugeWxqSLQVSki+Qwbk4OvN64OB2rF+TLlYeZufU0Kw5cYtWhy7xQLYj+TYqTx9PF6JhZytojV9gSeg0nezvebFLC6DhZx4GFlp+lWoGdRl/JHZMnTzY6gojYqhsnLD8zejw63FkrPewMJCbqs0oyjf7SRHKo3J7OfNS2PEv716NpmQASEs3M2HKKBmNWM37FYSJj4o2OmCUkJpoZs9TSit61ZiHy+7ganCiLSEyAg4ss25rVXUREUiuzJo0D8MoPJntIiL0zDl4kE6hIF8nhiuXxYFK3qsz5v5pUDPIhKjaB8SuOUH/Man7ZdIK4hESjI9q0JXsvsPdsOO5O9rzWINjoOFnHqc0QdQVcvKFwXaPTiIhIVnE9afm1DJ40DsDeAbzyWbY1Ll0ykYp0EQGgepFcLHitFl93rkzBXG5ciYhh2B/7aPK5ZoK/n/iERMYtOwRAn7pF8fNwNjhRFnLwL8vPki3B3tHYLCIiknVkZkv63Y+jcemSiVSki4iVyWSidYV8rBhQnw+fKYu/hzMnr0bx5qwQ2ny9njWHL2M2q1hPMnfHGY5fiSSXuxN96hYxOk7WYTbfWXqtVGtjs4iISNZy98RxmSFpXLqKdMlEKtJFJAUnBzu61izMmrcbMLBpCTycHdh3LpzuU7bS5cct7D59w+iIhouOS+DLlUcAeK1BMJ4uag1OtfMhlm6Djm4Q3MjoNCIiklXERFiGSoFa0iVbU5EuIvfl7myZCX7tOw3pXacITvZ2bDx2lWe+2cBr03dw7HKE0REN8+vmk5wPiyaftwsvPplJ3+ZnF0mt6MWagJObsVlERCTrSBoX7uJjmdMkM2itdDGAinQReahc7k4Ma12GfwbVp/0TBTCZYPGeCzz1xVqGzPuXC2HRRkfMVDej4/hm1VEA3mxSHBdHe4MTZTFJRXrpp43NISIiWYt10rhMakW/+7HUki6ZSEW6iKRaAV83xj1fkb/frEeT0nlISDQzc+tpGoxdxadLDhIWFWd0xEwxaV0o16PiKJrbnfZPFDA6TtZy+RBcOQx2jlDiKaPTiIhIVpLZk8bBXWPST1vmVBHJBCrSRSTNSgZ68mP3avz2Sk2qFvIlOi6RiWuOUW/MKiauOUZ0XILRETPM1YgYJq87DsCgp0riYK+30TRJakUv2iDzuiqKiEj2cON2S7pv4cx7TO8CgAnib0Hklcx7XMnRdHYpIo+sWuFc/PZKTX7sVpUSAR6E3Yrj0yUHaTBmNbO2niI+G66x/s2qY0TGJlA+vzctygUaHSfrsXZ116zuIiKSRjcM6O7u4Ayetz/vw9TlXTKHinQReSwmk4kmZQJY8mY9xnaoSH4fVy6ER/PuvD00G7+Wv/eezzbLtp25HsWvmy0nCO80L4nJZDI4URZz45RlZndMULKV0WlERCSrsXZ3z+QJWzUuXTKZinQRSRf2diaeq1KAlQPr836r0vi6OXLsciSv/LqTdt9uZOOxrN9F7MsVR4hNSKRmUT/qFPM3Ok7Wc+Avy89CtcAjt7FZREQk6zFi4jhIPi5dJBOoSBeRdOXiaE+fukVZ805DXm9UDFdHe0JO36DzpC10nrSZHSevGx3xkRy9dJPfd54B4G21oj+ag7eL9NJtjM0hIiJZT3QYRN+wbGd2ka6WdMlkKtJFJEN4uTgy8KmSrHmnAd1qFsLR3sTGY1dp/91Gek7dyt6zYUZHTJOxSw+TaIanygTwREFfo+NkPRGX4ORGy3YpjUcXEZE0SiqQ3fzA2SNzHztprXQV6ZJJVKSLSIbK4+nCqGfKsWpQAzpWC8LezsSqQ5dpPWE9r/yyg0MXbhod8aF2n77B3/suYDLBoGYljY6TNR1aDJghb6U7JzsiIiKpZcTya0mSHjNM3d0lc6hIF5FMUcDXjU/bV2DlgPq0q5wfkwn+3neB5l+u5c1Zuwi9Eml0xPsas/QQAO0q56dEgKfBabIo66zu6uouIiKPwKhJ4wC87+runk0mwxXbpiJdRDJVYX93vnihEsv616Nl+UDMZvgj5BxNPl/DO3N3c/palNERk9lw9Arrj17B0d7EW01KGB0na7p1A46vsWyXftrQKCIikkUZNWkc3OkBFhsBt7Lm3DqStahIFxFDFA/w5NsuVVj0Rh2alM5DQqKZOdvP0GjcaoYt2MuFsGijI2I2m/nsdit6lxqFCMrlZnCiLOrIMkiMA/+SkFtfdIiIyCNIakn3NaAl3dEV3HMnzyGSgVSki4ihyubz5sfu1Zj/Wi3qFvcnLsHML5tPUm/MKj78az9XImIMy7Z030V2n76Bm5M9fRsWMyxHlqeu7iIi8rhuJLWkG1Ckg8alS6ZSkS4iNqFyQV9+6V2DWS8/SbXCvsTGJzJ5fSj1PlvFZ38f5EZUbKbmSUg0M3aZpRW9V+0i5PZ0ztTHzzZio+DoCst2ac3qLiIij8BsNnbiOLhrrXS1pEvGU5EuIjblyaJ+zPm/mvzcqzoVC3gTFZvAt6uPUfd/q/hyxRFuRsdlSo55O89w9FIEPm6OvFy/aKY8ZrZ07B+Ii7Kc3OStZHQaERHJiqJvQEy4ZduoIt26Vrpa0iXjqUgXEZtjMpmoVyI3C/rWZlK3qpQK9ORmTDxfrDhM3c9WMXHNMaJi4zPs8WPiExi/4ggAr9YPxsvFMcMeK9u7u6u7yWRsFhERyZqSJo1zz2MZH24En7tmeBfJYCrSRcRmmUwmmpYJYPEbdfm6c2WCc7tzIyqOT5ccpNan//DhX/s5eiki3R93xpZTnL1xiwAvZ7rXKpzu959jJMTB4SWWbY1HFxGRR2XkpHFJrGPSVaRLxnMwOoCIyMPY2ZloXSEfLcrl5Y+Qs4xfcYRT16KYvD6UyetDqVEkF51rFKR5uUCcHewf67EiYuL5+p+jALzZuAQujo93fznaiXUQHWaZETeohtFpREQkq7ph4PJrSdSSLplIRbqIZBn2diaefaIAz1TKz9rDl5m+5RT/HLzIltBrbAm9Ri53J56rUoBO1QtSxN/9kR5jyvpQrkbGUtjPjQ5VC6TzM8hhkrq6l2oFdvqyQ0REHpHRk8bBnYnjosMsFxdv47JItqciXUSyHHs7Ew1L5aFhqTycu3GL2dtOM3vbaS6ER/PD2uP8sPY4tYL96FS9IM3KBuLkkLqRPdcjY5m09jgAA54qiaO9RgQ9ssQEOPCXZbuUurqLiMhjuG7w8msAzh7gmgtuXbNMHheoIl0yjop0EcnS8vm48lbTErzeqBirDl1mxpaTrD58mY3HrrLx2FX83J14rmoBOlcvSCG/B7euf7fmGDdj4imT14vW5fNm0jPIps5sg8hL4OwFReoZnUZERLIyW2hJB/AJshTpYachsJyxWSRbU5EuItmCg70dTcsE0LRMAGeuR1lb1y/djOH7Ncf5fs1x6hTzp3ONgjQtE5Cilfx82C2mbTwBwNvNS2Jnp5nIH0tSV/cSzcHBydgsIiKSdd29RrpvYUOj4FMQzu/WuHTJcCrSRSTbKeDrxsCnSvJm4+KsPHiJ6VtOse7IZdYfvcL6o1fw93Dm+aqWsetBudwA+GrlEWLjE6leOBcNSuQ2+BlkcWZz8qXXREREHlXUVYiLtGx7GzxXjLcmj5PMoSJdRLItB3s7mpUNpFnZQE5fi2Lm1lPM2X6GKxExfLv6GN+tOUbd4rlpVjaAOdvPAPBO85KYtJ7347mwxzITr4MrFGtsdBoREcnKkmZ298wLDs7GZtEM75JJVKSLSI4QlMuNd5qX4q2mJVi+/yIztpxi/dErrD18mbWHLwPQuFQeqhbOZXDSbCCpFb1YY3B6tFn2RUREANuYNC6Jz+0Z3sNOG5tDsj0V6SKSozja29GyfF5als/LiSuRzNx2irnbzxAdl8A7zUsZHS97UFd3ERFJL7YyadzdGdSSLhlMRbqI5FiF/d0Z0qI0g54qSVxCIm5Oekt8bFeOwuUDYOcAJZoZnUZERLI666RxNtCSnrRWetRViI1UbzHJMFoEWERyPEd7OxXo6eXg7Vb0IvXA1dfYLCIikvUljUm3hZZ0Vx9wvr0++g11eZeMoyJdRETSj7q6i4hIerJ2d7eBlnTQuHTJFIYX6d988w2FCxfGxcWFGjVqsHXr1gcef+PGDfr27UvevHlxdnamRIkSLF68OJPSiojIfYWdgbM7ABOUbGV0GhERyeruXiPdFlrS4a5x6SeNzSHZmqH9O2fPns2AAQOYOHEiNWrUYPz48TRr1oxDhw6RJ0+eFMfHxsbStGlT8uTJw9y5c8mfPz8nT57Ex8cn88OLiEhyBxdZfgbVAM8AY7OIiEjWF3EJ4qPBZGf8GulJksalq7u7ZKA0t6QXLlyYUaNGcerU489q+Pnnn/PSSy/Rs2dPypQpw8SJE3Fzc2PKlCn3PH7KlClcu3aNBQsWULt2bQoXLkz9+vWpWLHiY2cREZHHpK7uIiKSnpJa0b3yg72jsVmSaIZ3yQRpLtL79+/PvHnzKFq0KE2bNmXWrFnExMSk+YFjY2PZsWMHTZo0uRPGzo4mTZqwadOme95m4cKF1KxZk759+xIQEEC5cuX45JNPSEhIuO/jxMTEEB4enuwiIiLpLPIqnNxg2S7d2tgsIiKSPdjSpHFJNCZdMsEjFekhISFs3bqV0qVL8/rrr5M3b1769evHzp07U30/V65cISEhgYCA5F0iAwICuHDhwj1vc/z4cebOnUtCQgKLFy9m2LBhjBs3jo8++ui+jzN69Gi8vb2tl6CgoFRnFBGRVDq0GMyJEFgBfAsbnUZERLIDa5FuI5PGgVrSJVM88sRxTzzxBF999RXnzp3jgw8+4Mcff6RatWpUqlSJKVOmYDab0zMnAImJieTJk4cffviBKlWq8MILLzB06FAmTpx439sMGTKEsLAw6+X0aX3rJSKS7vYvsPws/bShMUREJBu5boMt6d63s0RchLhoY7NItvXIE8fFxcUxf/58pk6dyvLly3nyySfp3bs3Z86c4b333mPFihXMmDHjvrf39/fH3t6eixcvJtt/8eJFAgMD73mbvHnz4ujoiL29vXVf6dKluXDhArGxsTg5OaW4jbOzM87Ozo/4LEVE5KHWjYOjKyzbZVSki4hIOrG1md0B3HKBozvERVpWNfEvZnQiyYbS3JK+c+fOZF3cy5Yty969e1m/fj09e/Zk2LBhrFixgvnz5z/wfpycnKhSpQorV6607ktMTGTlypXUrFnznrepXbs2R48eJTEx0brv8OHD5M2b954FuoiIZLANX8LKUZbtxh9A7pLG5hERkewjqbu7rw11dzeZ7hqXri7vkjHSXKRXq1aNI0eO8N1333H27FnGjh1LqVKlkh1TpEgROnbs+ND7GjBgAJMmTeKnn37iwIEDvPrqq0RGRtKzZ08AunXrxpAhQ6zHv/rqq1y7do0333yTw4cPs2jRIj755BP69u2b1qchIiKPa9M3sHy4ZbvhUKg7wNg8IiKSfSQm3lnmzJZa0kHj0iXDpbm7+/HjxylU6MHfZrm7uzN16tSH3tcLL7zA5cuXGT58OBcuXKBSpUr8/fff1snkTp06hZ3dne8RgoKCWLp0KW+99RYVKlQgf/78vPnmmwwePDitT0NERB7Hlu9h6XuW7fqDof47xuYREZHsJeICJMaBnQN45jM6TXJaK10yWJqL9EuXLnHhwgVq1KiRbP+WLVuwt7enatWqabq/fv360a9fv3tet3r16hT7atasyebNm9P0GCIiko62/QhLbhfldQdCgyEPPl5ERCStkiaN88oP9o88jVbGUEu6ZLA0d3fv27fvPWdIP3v2rLqdi4hkdzumwaKBlu1ab0CjYZbxeSIiIukpqQC2pfHoSbRWumSwNBfp+/fv54knnkixv3Llyuzfvz9dQomIiA3a9Sv8+aZl+8m+0HSUCnQREckYN2xw+bUkSeu2qyVdMkiai3RnZ+cUy6YBnD9/HgcHG+uKIiIi6WP3LPjj9tCk6v8HzT5WgS4iIhnHWqTbYEt60pj0m+chPtbYLJItpbmqfuqppxgyZAh//PEH3t7eANy4cYP33nuPpk2bpntAEREx2L+/wYJXATNU7Q0t/qcCXUREHk1sJNy8ABGXLJPD3bwIEXddbl607I+8YjneFot0jzzg4ALx0RB+FnIVMTqRZDNpLtLHjh1LvXr1KFSoEJUrVwYgJCSEgIAAfvnll3QPKCIiBto7D+a/DOZEeKI7tByrAl1ylpibdyawkuwvPd/fzObUHpiG+zNbfpoTb29zj31JxyXe5zbmO7c1ASa7h1xMqT8mJuLeBXfEpTuFeezN1L+G7rmhcO3UH59ZTCbwLgBXj1rGpatIl3SW5iI9f/78/Pvvv0yfPp3du3fj6upKz5496dSpE46OjhmRUUREjLD/D/i9j+XErtKL0Ho82KV5lJRI1nZ6C/za3ugUItmLoxt4BIBnoKVV2iMQPAMs++7edvMDO3uj096bT0FLka5x6ZIBHmkQubu7Oy+//HJ6ZxEREVtxcBHM7QXmBKjQEZ7+SgW65Ez2TuCex+gUkiUlNVWnQqpb8E13Wq4x3W7Bvnvb7s52imPv3uZOtqRW9vte0nC9o8t/Cu7bF8/bxXfStrNnWl5I26S10iUDPfJMb/v37+fUqVPExiafLOHpp59+7FAiImKgQ3/DnO6QGA/lO0Dbb223JUMkoxWpB28fMTqFiNiapFnnz++2dPN39jA2j2QraS7Sjx8/Trt27dizZw8mkwnz7fE2ptvfACYkJKRvQhERyTxHVsCcrpAYB2XbQduJKtAlTU6fPo3JZKJAgQIAbN26lRkzZlCmTBn1whOR7CNpHPrhJfC/whBUA4IbQnAjyFtJvc/ksaT5r+fNN9+kSJEiXLp0CTc3N/bt28fatWupWrUqq1evzoCIIiKSKY79A7M6Q0IslG4Dz04Cey2tKWnTuXNnVq1aBcCFCxdo2rQpW7duZejQoYwaNcrgdCIi6aREC3jyNcvs84lxcHI9/PMhTGoIY4Lht56w8xcIO2t0UsmCTGZzqqeeBMDf359//vmHChUq4O3tzdatWylZsiT//PMPAwcOZNeuXRmVNV2Eh4fj7e1NWFgYXl5eRscREbENx9fAjOcty8mUbAkdfgIHJ6NT5RjZ6bPJ19eXzZs3U7JkSb766itmz57Nhg0bWLZsGa+88grHjx/PlBzZ6TUVERt37bjli+5jqyyfp/+dwd6/pKWFPbiRZbZ6J3djcoqh0vK5lOYmkoSEBDw9LZM9+Pv7c+7cOUqWLEmhQoU4dOjQoyUWERHjnFgPMztaCvTizaDDNBXo8sji4uJwdnYGYMWKFda5akqVKsX58+eNjCYikjFyFbVcqvWBhDg4u+N20f6PZfvKIctly3eWySgLPnmnaA8or67xkkKai/Ry5cqxe/duihQpQo0aNfjss89wcnLihx9+oGjRohmRUUREMsrJTTD9eYiLgmJN4PmfwcHZ6FSShZUtW5aJEyfSqlUrli9fzocffgjAuXPn8PPzMzidiEgGs3e0FOEFn4SG70HUNQhde6doDztt+T10LawYAW7+d8ayF20IXnmNfgZiA9JcpL///vtERkYCMGrUKFq3bk3dunXx8/Nj9uzZ6R5QREQyyOmtMP05iIuEog3ghV8ty+eIPIb//e9/tGvXjjFjxtC9e3cqVqwIwMKFC6levbrB6UREMplbLijb1nIxm+HqsTsF+4l1EHUF9vxmuYBlyNlzU/V5nMOleUz6vVy7dg1fX1/rDO+2TGPURESAMzvgl7YQEw6F60LnOeDkZnSqHCu7fTYlJCQQHh6Or6+vdd+JEydwc3MjT57MWXM8u72mIpINxcfCmW13ivZzuwAzlGlrKdTVDT5bScvnUpr+5ePi4nBwcGDv3r3J9ufKlStLFOgiIgLcug7T21sK9EK1ofNsFeiSbm7dukVMTIy1QD958iTjx4/n0KFDmVagi4hkCQ5OlonkGg+Dl1dB94WWMev7F8CyoUanEwOlqUh3dHSkYMGCWgtdRCQrO7bKUqj7Frndgq5ZZiX9PPPMM/z8888A3Lhxgxo1ajBu3Djatm3Ld999Z3A6EREbVqQetL39Prn5W9j4tbF5xDBp7kMxdOhQ3nvvPa5du5YReUREJKOFrrH8LNkCnD2MzSLZzs6dO6lbty4Ac+fOJSAggJMnT/Lzzz/z1VdfGZxORMTGlX8Omlom3GTZUNj7u7F5xBBpnjju66+/5ujRo+TLl49ChQrh7p68BWbnzp3pFk5ERDLA8dtFepH6xuaQbCkqKsq6VOuyZct49tlnsbOz48knn+TkyZMGpxMRyQJqvQ7hZ2HLRJj/CrjngSJ1jU4lmSjNRXrbtm0zIIaIiGSKG6fgeiiY7KFQLaPTSDZUrFgxFixYQLt27Vi6dClvvfUWAJcuXdIEbiIiqWEyQbNPIPwcHFgIs7pAr78hoIzRySSTpLlI/+CDDzIih4iIZIakVvT8VcBFBZOkv+HDh9O5c2feeustGjVqRM2aNQFLq3rlypUNTicikkXY2cOzP8DPl+D0ZsuSqX1WgFc+o5NJJtC8/iIiOUnSePQi9YzNIdnWc889x6lTp9i+fTtLly617m/cuDFffPGFgclERLIYR1foNBP8S1i6v//6HESHGZ1KMkGai3Q7Ozvs7e3vexERERtlNkPoWst2UY1Hl4wTGBhI5cqVOXfuHGfOnAGgevXqlCpVyuBkIiJZjFsu6DIXPALg0j6Y/aJlfXXJ1tLc3X3+/PnJfo+Li2PXrl389NNPjBw5Mt2CiYhIOrt8ECIugoMLFKhudBrJphITE/noo48YN24cERERAHh6ejJw4ECGDh2KnZ068YmIpIlvIUuhPrWF5cv2P16Ddj+A3k+zrTQX6c8880yKfc899xxly5Zl9uzZ9O7dO12CiYhIOktqRS/4JDi6GJtFsq2hQ4cyefJkPv30U2rXrg3A+vXrGTFiBNHR0Xz88ccGJxQRyYLyVoDnf4YZz8Oe3yxj05uOMjqVZJA0F+n38+STT/Lyyy+n192JiEh609Jrkgl++uknfvzxR55++mnrvgoVKpA/f35ee+01FekiIo+qWGN4egIseBU2fAleBaCG6q/sKF36SNy6dYuvvvqK/Pnzp8fdiYhIekuIhxPrLdsajy4Z6Nq1a/cce16qVCmuXbtmQCIRkWykUmdo9L5le8k7sH+hsXkkQ6S5SPf19SVXrlzWi6+vL56enkyZMoUxY8ZkREYREXlc53dDTBi4eEPeSkankWysYsWKfP311yn2f/3111SoUCFV9zF69GiqVauGp6cnefLkoW3bthw6dCi9o4qIZE11B0GVnoAZ5r0EpzYbnUjSWZq7u3/xxReYTCbr73Z2duTOnZsaNWrg6+ubruFERCSdhK62/Cxc17L2qkgG+eyzz2jVqhUrVqywrpG+adMmTp8+zeLFi1N1H2vWrKFv375Uq1aN+Ph43nvvPZ566in279+Pu7t7RsYXEbF9JhO0HAs3L8DhJTCzI/RaBrlLGJ1M0onJbDabjQ6RmcLDw/H29iYsLAwvLy+j44iIZI6fnraskd5ijMav2aDs9tl07tw5vvnmGw4ePAhA6dKlefnll/noo4/44Ycf0nx/ly9fJk+ePKxZs4Z69eql6jbZ7TUVEUkhNgp+agNnt4NPQei9AjwDjE4l95GWz6U0t6RPnToVDw8POnTokGz/b7/9RlRUFN27d0/rXYqISEaKi4bTWyzbGo8umSBfvnwpJojbvXs3kydPfqQiPSwsDIBcuXLd95iYmBhiYmKsv4eHh6f5cUREshQnN+g8GyY3hWvHYfpz0HMxOHsanUweU5rHpI8ePRp/f/8U+/PkycMnn3ySLqFERCQdnd4C8dHgEQj+6gonWUtiYiL9+/endu3alCtX7r7HjR49Gm9vb+slKCgoE1OKiBjE3R9e/B3c/OHCvzCnOyTEGZ1KHlOai/RTp05RpEiRFPsLFSrEqVOn0iWUiIiko9DbS68VrW8ZxyaShfTt25e9e/cya9asBx43ZMgQwsLCrJfTp09nUkIREYPlKgpd5oCjGxxbCQvfgJw1ojnbSXORnidPHv79998U+3fv3o2fn1+6hBIRkXRkXR89dWN5RWxFv379+Ouvv1i1ahUFChR44LHOzs54eXklu4iI5Bj5q0CHaWCyh90zYNXHD72J2K40j0nv1KkTb7zxBp6entbJW9asWcObb75Jx44d0z2giIg8hugwOLfTsl1E49El4zz77LMPvP7GjRupvi+z2czrr7/O/PnzWb169T178ImIyH+UaAatv4A/34C1Y8ArH1TtZXQqeQRpLtI//PBDTpw4QePGjXFwsNw8MTGRbt26aUy6iIitObEBzImWrnA+GqMrGcfb2/uh13fr1i1V99W3b19mzJjBH3/8gaenJxcuXLDeh6ur62NnFRHJtqp0h/CzsOZ/sGggeOaDks2NTiVp9MhLsB05coSQkBBcXV0pX748hQoVSu9sGUJLsohIjrJkMGyZCFV6QpvxRqeR+9BnU3Km+8ydMHXqVHr06JGq+9BrKiI5ltkMf/SDkF8t49Rf3WD5sl4MlaFLsCUpXrw4xYsXf9Sbi4hIZghda/mppdckC3nE9gMREQHLJLFtxsP1UDi5AVaOsoxXlywjzRPHtW/fnv/9738p9n/22Wcp1k4XEREDRVyCS/st24U1aZyIiEiOYe8ILT4DTLBvPpzZbnQiSYM0F+lr166lZcuWKfa3aNGCtWvXpksoERFJB0mt6IHlwV2rb4iIiOQogeWgUmfL9rL3tSxbFpLmIj0iIgInJ6cU+x0dHQkPD0+XUCIikg6Or7b81KzuIiIiOVPDoeDgAqc2waHFRqeRVEpzkV6+fHlmz56dYv+sWbMoU6ZMuoQSEZF0EHp7ffSiDQyNISIiIgbxzg9PvmbZXv4BJMQZm0dSJc0Txw0bNoxnn32WY8eO0ahRIwBWrlzJjBkzmDt3broHFBGRR3AtFG6cAjsHKFjT6DQiIiJilDr9YedPcPWI5We1PkYnkodIc0t6mzZtWLBgAUePHuW1115j4MCBnD17ln/++YdixYplREYREUmrpFb0AtXA2cPYLCIiImIcF2+o/65le/WnEHPT2DzyUGku0gFatWrFhg0biIyM5Pjx4zz//PMMGjSIihUrpnc+ERF5FMdvF+kajy4iIiJVe0KuYIi8DBu+NDqNPMQjFelgmeW9e/fu5MuXj3HjxtGoUSM2b96cntlERORRJCZqfXQRERG5w94Rmnxg2d74NYSfNzaPPFCaxqRfuHCBadOmMXnyZMLDw3n++eeJiYlhwYIFmjRORMRWXNoPUVfA0Q3yVzU6jYiIiNiC0k9DUA04vQVWfQzPfG10IrmPVLekt2nThpIlS/Lvv/8yfvx4zp07x4QJEzIym4iIPIqk8egFa4JDyiUzRUREJAcymaDph5btkOlwcb+xeeS+Ul2kL1myhN69ezNy5EhatWqFvb19RuYSEZFHlTQeXV3dRURE5G4Fa1ha1M2JsHy40WnkPlJdpK9fv56bN29SpUoVatSowddff82VK1cyMpuIiKRVQhyc3GDZ1qRxIiIi8l9NRliWaD26HI6vNjqN3EOqi/Qnn3ySSZMmcf78ef7v//6PWbNmkS9fPhITE1m+fDk3b2oqfxERw53dCbER4OoLgRWMTiMiIiK2xi8YqvaybC8bZplwVmxKmmd3d3d3p1evXqxfv549e/YwcOBAPv30U/LkycPTTz+dERlFRCS1kmZ1L1wX7B55AQ8RERHJzuoPBmcvuPAv7PnN6DTyH491BleyZEk+++wzzpw5w8yZM9Mrk4iIPKpQjUcXERGRh3D3hzr9Ldv/fAhx0YbGkeTSpZnF3t6etm3bsnDhwvS4OxEReRSxUZZlVQCKNDAyiYiIiNi6J18Dr/wQdhq2TDQ6jdxFfSFFRLKL05shIdbygesXbHQaERERsWWOrtBwqGV73ecQdc3YPGKlIl1EJLtIWnqtSH3LWqgiIiIiD1KxIwSUg5gwWDvG6DRym4p0EZHsQuPRRUREJC3s7KHpKMv21klw7bixeQRQkS4ikj3cug7nQizbReoZGkVERESykGKNIbgRJMbBylFGpxFUpIuIZA8n1gNm8CsOXvmMTiMiIiJZSdNRgAn2zYcz241Ok+OpSBcRyQ6Oq6u7iIiIPKLA8lCxk2V72TAwm43Nk8OpSBcRyQ5C75o0TkRERCStGr0PDi5waiMcWmx0mhxNRbqISFYXfg6uHAZMULiO0WlEREQkK/LOb1k7HWD5B5AQZ2yeHExFuohIVhe61vIzb0Vwy2VsFhEREcm66vQHNz+4egR2/mR0mhxLRbqISFan8egiIiKSHly8of5gy/bqTyHmprF5cigV6SIiWZnZfKclXePRRURE5HFV6Qm5ikLkZdjwldFpciQV6SIiWdm14xB+BuydoGBNo9OIiIhIVufgBE1GWLY3fQ3h5w2NkxOpSBcRycqOr7b8LFAdnNwMjSIiIiLZROmnLecWcVGw6mOj0+Q4KtJFRLKyUI1HFxERkXRmMsFTH1m2Q6bDxf3G5slhbKJI/+abbyhcuDAuLi7UqFGDrVu3pup2s2bNwmQy0bZt24wNKCJiixITIXSdZVvj0UVERCQ9FawBpduAORFWfGB0mhzF8CJ99uzZDBgwgA8++ICdO3dSsWJFmjVrxqVLlx54uxMnTjBo0CDq1q2bSUlFRGzMxT1w6xo4eUD+J4xOIyIiItlNk5Fg5wBHlt1ZTUYynOFF+ueff85LL71Ez549KVOmDBMnTsTNzY0pU6bc9zYJCQl06dKFkSNHUrRo0Qfef0xMDOHh4ckuIiLZQtKHZaHaYO9obBYRERHJfvyCoWovy/ay9y29+CTDGVqkx8bGsmPHDpo0aWLdZ2dnR5MmTdi0adN9bzdq1Cjy5MlD7969H/oYo0ePxtvb23oJCgpKl+wiIoZLGo9epJ6xOURERCT7qj8YnDzhwr+w5zej0+QIhhbpV65cISEhgYCAgGT7AwICuHDhwj1vs379eiZPnsykSZNS9RhDhgwhLCzMejl9+vRj5xYRMVx8LJzcaNnWpHEiIiKSUdz9oU5/y/Y/H0JctKFxcgLDu7unxc2bN+natSuTJk3C398/VbdxdnbGy8sr2UVEJMs7u92yLIqbH+Qpa3QaERERyc6efA0880HYadg9w+g02Z6DkQ/u7++Pvb09Fy9eTLb/4sWLBAYGpjj+2LFjnDhxgjZt2lj3Jd4eF+Hg4MChQ4cIDg7O2NAiIrbg+F1d3e2y1PetIiIiktU4uUGN/7PM8r7/jzvj1CVDGHpm5+TkRJUqVVi5cqV1X2JiIitXrqRmzZopji9VqhR79uwhJCTEenn66adp2LAhISEhGm8uIjmHdTy6urqLiIhIJih9u6E0dB1EXTM2SzZnaEs6wIABA+jevTtVq1alevXqjB8/nsjISHr27AlAt27dyJ8/P6NHj8bFxYVy5colu72Pjw9Aiv0iItlWTASc2WbZ1nh0ERERyQx+wRBQDi7uhUOLofKLRifKtgwv0l944QUuX77M8OHDuXDhApUqVeLvv/+2TiZ36tQp7NSVU0TkjlObITEevAuCbxGj04iIiEhOUfppS5F+4E8V6RnI8CIdoF+/fvTr1++e161evfqBt502bVr6BxIRsWWhqy0/i9YDk8nQKCIiIpKDlHkaVn8Cx/6B6HBw0aTcGUFN1CIiWY110rgGRqYQERGRnCZ3KfArBgmxcGSZ0WmyLRXpIiJZSdQ1uLDHsl2knrFZREREJGcxmSxd3gEOLDQ2SzamIl1EJCsJXQuYIXdp8AwwOo2IiIjkNEmzvB9ZDnG3jM2STalIFxHJSpKWXtOs7iIiImKEfJXBOwjiouDoyocfL2mmIl1EJCs5rvXRRURExEAm053W9AN/Gpslm1KRLiKSVYSdgWvHwGQHhWoZnUZERERyqqRx6YeWQHyssVmyIRXpIiJZRVIrer7K4OpjaBQRERHJwYJqgEcAxITdni9H0pOKdBGRrCJUXd1FRETEBtjZQalWlm3N8p7uVKSLiGQFZvOdlnRNGiciIiJGS+ryfnARJCYYmyWbUZEuIpIVXDkMERfA3tnSxUxERETESIXrgIsPRF2BU5uMTpOtqEgXEckKklrRC9YAR1djs4iIiIjYO97p8r5fXd7Tk4p0EZGsQOPRRURExNYkdXk/8CckJhqbJRtRkS4iYusSE+DEOst20QaGRhERERGxKtoAnDzg5jk4t9PoNNmGinQREVt3fjdEh4GzF+StZHQaEREREQtHFyjRzLK9/w9js2QjKtJFRGzd8VWWn4XrgL2DsVlERERE7la6jeXngT8tq9HIY1ORLiJi646utPwMbmRsDhEREZH/KtYUHFzgeihc3Gt0mmxBRbqIiC2LDofTWyzbxZoYm0VERETkv5w9ILixZfvAn8ZmySZUpIuI2LLQtZAYD7mKQq4iRqcRERERSanM7VnetRRbulCRLiJiy46usPxUK7qIiIjYqhLNwc4BLh+AK0eMTpPlqUgXEbFVZjMcuz0eXUW6iIiI2CpXHyhS37J9QK3pj0tFuoiIrbp6FG6cAnsny8zuIiIiIrZKXd7TjYp0ERFbldTVvWBNcHI3NouIiIjIg5RsBSY7OB9iaWSQR6YiXUTEVh1VV3cRERHJIjxyQ8Falm3N8v5YVKSLiNiiuFtwYr1lu1hjY7OIiIhkcXEJiZy+FoXZbDY6SvaW1OVdRfpjcTA6gIiI3MPJjRB/CzzzQp4yRqcRERHJUsxmM8cuR7L+yGXWH73K5uNXiYiJ5/mqBfikXXkc7NVWmSFKtYYl78CpzXDzIngGGJ0oS1KRLiJii479Y/lZrDGYTMZmERERyQIu34xh47ErrDtyhQ1Hr3A+LDrFMXO2n+F6VBwTOlXGxdHegJTZnHd+yF8Vzm6Hg39Btd5GJ8qSVKSLiNiipEnjgtXVXURE5F5uxSawJfQqG45aCvODF24mu97JwY5qhX2pUyw3dYr5c/bGLd6YtYvl+y/SfcpWJnWvipeLo0Hps7HSbSxF+oGFKtIfkYp0ERFbE3YGLh+0zJBatIHRaURERGxCQqKZPWfDbhfll9l58gaxCYnJjimbz4s6xfypU9yfaoVzJWstL1/Am597Veeln7azJfQaHb/fzE+9qpPb0zmzn0r2VuZpWPEBhK6DqGvglsvoRFmOinQREVuTNKt7/ir6YBMRkRzt5NVIa/f1jceuEnYrLtn1+X1crUV5rWA//DweXHA/WdSPmS8/SY+pW9l/PpwOEzfyS+8aBOVyy8inkbPkKgoB5eHiHji0BCp3MTpRlqMiXUTE1iR1ddfSayIiksPExCew6dhVVh64xOrDlzh97Vay6z1dHKhZ1I+6xf2pUzw3hf3cMKVx7pZy+b357ZVadJ28hRNXo2j/3UZ+7l2dUoFe6flUcrbSbSxF+oGFKtIfgYp0ERFbkhAPx9dYtlWki4hIDnA1IoZVhy6zYv9F1h25TGRsgvU6R3sTlQv6UreYP7WL+1Mhv3e6zMxexN+d31+tRbfJWzl08SbPT9zElB7VqFpYPdjSRZmnYfUnlolwY26Cs6fRibIUFekiIrbk7HaICQNXX8hX2eg0IiIi6c6yPFoEy/dfYuWBi+w4dZ27ly8P8HKmcekAGpfKw5NF/XB3zpiSJcDLhTn/V5NeP21jx8nrvDh5C992eYJGpbRs2GPLXQr8isHVo3B4KZR/zuhEWYqKdBERW5LU1b1oQ7DT0jCSc61du5YxY8awY8cOzp8/z/z582nbtq3RsUTkEcUlJLLtxDVWHrjEigMXOXk1Ktn1ZfN50bh0AE1LB1Auv1eau7A/Km83R37tXYPXpu9g1aHLvPTzDsZ2qEC7ygUy5fGzLZMJSj8N6z+HA3+qSE8jFekiIrYkadI4dXWXHC4yMpKKFSvSq1cvnn32WaPj/H97dx4fVXX/f/w1k2Wyb4SsJOwga0CWGFCLmLK4gRtIqeBSrBRsLe2v1raKfvvtD7eqvyriUoFaN0QFcQEEBBcMIqvssoSELQkQyL7O3N8fQwYiCRBIcm+S9/PxmMfce+6dm8/JmcnJZ+6954jIRcgrqeDLH92Xsa/alUN+aaVnm6+XnZSOrUjt7j5jHhfmb1qc/r5evDqhP396/wcWbDzE7+dt5kRRBfdc2d60mJqFbje6k/Tdy6CiBHzMa+OmRkm6iIhVFB2Dwxvdyx2HmhuLiMlGjhzJyJEjzQ5DROoo83gxy3Zks2JHNmvTc6l0nb6OPSLQl6GXRZHaLYorO7cmqIEuY78YPl52/nl7EmEBPsxZvZ//+WQ7uUXl/GFYl0Y7q9/sxPWF0ETIy3Tfm37Z9WZH1GRY55MhItLS7V0JGBDdE0JizY5GpEkpKyujrKzMs56fn29iNCIth2EY/HAwj6Xbsli+I5sfswurbe8cFeS+jL17FH0SwvGyWzfhtdttPHpDd1oF+vLM5z/y4so95BaX8/dRPS0dt2XZbO6z6WtmwvZFStLrQEm6iIhV7K261P1ac+MQaYJmzJjB448/bnYYIi1CpdPF2vRclmzL4vNt2WTll3q2edltDGwXQWr3aFK7RdG2VaCJkdadzWZj6tDOhAf68reFW3n7u0xOFpfz3Ng+OLw1VkydVSXpuxZDZTl4+5odUZOgJF1ExApcrtP3o3dUki5SVw8//DDTpk3zrOfn55OQkGBiRCLNS2mFk69+PMrSbdms2JnNyeIKz7ZAXy+GdI1iWI9ohnSJIjTAx8RI68f45LaE+fvy4LyNfLYli7yS73nlzv6WukS/SUhIhqBoKMyG/V9pzJ0LpHeZiIgVZG+BohzwCYTEK8yORqTJcTgcOBwOs8MQaVbyiiv4Ylc2S7dm8+WPRympOD1/eUSgL6ndohjeI4bBnSLx82l+Z5mv7x1LqL8P9/13Hav3HOcXr61h7t0DiQjU2eALZre7L3NfN9t9ybuS9AuiJF1ExAqqzqK3vxq8lWiIiIg5svNL+XxbFp9vzyZt7/FqA7/Fh/kzrEc0w3vE0L9tON5edhMjbRxXdo7knUlXcNectfxwMI/bXv6W/96bTLyJo9E3Od1ucifpOz+FG57TFLMXQEm6iIgV7NH96CJnKiwsZM+ePZ719PR0Nm3aREREBImJiSZGJtL87DtayNJt2SzdlsWmAyerbesSHcTwHjEM7xFDj7jGm7/cSpISwph//yAmvP4d+44Wcdusb/nvvQPpFBVsdmhNQ7srwT8cio9BZpp7Xc5JSbqIiNlK8+HAGveyknQRANatW8c111zjWa+633zixInMnTvXpKhEmgfDMNh2OJ8lW7NYui2L3TnVR2TvmxjmSczbRzatgd8aSqeoIN6fPIgJs9eyJ6eQ215OY85dA+ibGG52aNbn5QNdr4NNb8GOj5WkXwAl6SIiZtv/NbgqIbw9RHQwOxoRSxgyZAiGYZx/RxG5YAdyi1m0+TALNh5izxmJubfdRkrHVgzrEcOw7tFEh/iZGKV1xYX5M//XKdw193s2HzjJ+H9/x2sT+jO4U6TZoVlft5tOJ+nDZ7jvVZdaKUkXETHbnuXuZw2mIiIi9SyvuILPth5hwYZDrN2f6yn39bZzTdfWjOgZw9Cu0c1iRPbGEB7oy9u/Sub+N9fz9e5j/Pq/61k4ZZAufT+fDkPANwjyD8HhDdCmv9kRWZqSdBERMxmGknQREalXZZVOVu06ysKNh1ixI4dypwsAmw2uaN+Km/vGM6JXDCF+SswvRqDDm39P7M+d/17L2v25THpjPQt/M1hfdJyLjx90GQ5bP4Adi5Skn4eSdBERMx3fCyczwe6je7REROSiGYbB+owTLNh4iE9+OEJeyel5zLtEB3Fz3zaM6hNHnEYlrxcOby9e+uXl3PTCN6QfK+KBdzcy564BeNlb3sB6F6zbje4kffsiSH3c/a2R1EhJuoiImarOordNAUeQubGIiEiTs+9oIQs3HmLBpkMcyC3xlEcFOxjVJ46b+7ahW2xwixyVvaFFBjl4dUJ/bnv5W7768ShPLdnJw9d1Mzss6+r0c/D2gxPpkL0NYnqaHZFlKUkXETHT3qqp13Spu4iIXJhjhWV8svkwCzYdZvMZU6YF+noxomcsN/eNJ6VjK53VbQQ940N5+rYkHnhnI698tY9usSGM7htvdljW5Ahy/7+z8xP3Je9K0mulJF1ExCwVpZD+tXu5o6ZeExGR2pWUO1m2I5sFGw7y1e5jOF3u2Q+87Dau7hzJ6L7x/Lx7NAG++ve+sd2YFMeOI/m8tGovD33wAx1aB9K7TZjZYVlTtxtPJekfwzV/MTsay9KnWETELJnfQmUJBMVAdA+zoxEREQvacjCPt9dm8vHmwxSWVXrKk9qEMrpvPDf0jqN1sMPECAXgD8O6sjOrgC925nDfG+tZ9MBgooI1ld1ZuowAuzfkbIdjeyCyk9kRWZKSdBERs+w541J33SsoIiKn5JdW8NGmw7y7NpNth/M95W3C/bm5bzyj+sTTKUrjmFiJl93G83f04eaZq9l7tIjJb27g7UnJOLy9zA7NWvzDoP3P3Lf77fgIrvqD2RFZkpJ0ERGzeJL0oebGISIipjMMg40HTvLu2kw+3nyEkgonAL5edkb2iuGOAYlc0SFCA8BZWIifD69N6M+omatZn3GCRxdu44lbe6nNfqr7TaeS9I+VpNdCSbqIiBnyDsLRHWCzQ4drzI5GRERMkldcwYKNB3n3+wPszCrwlHeKCmLcwERu6RtPeKCviRFKXXRoHcQL4/pyz9zvmbfuAN3jQpg4qJ3ZYVlL1+vhk9/D4Y3uaWjDEs2OyHKUpIuImGHvF+7nuMshIMLcWEREpFEZhsG6jBO8810mn245QlmlCwCHt53re8cybmAi/duG6wxsEzWkaxQPjbiMGYt38j+fbKdzdBCDOkaaHZZ1BLWGxEGQ8Q3s+ARSfmN2RJajJF1ExAxV86Nr6jURkRbjRFE5H2xwnzXfk1PoKb8sJphxAxMZ3See0AAfEyOU+nLf1R3YcSSfhZsOM+WtDSyaeiUJEQFmh2Ud3W86laQvUpJeAyXpIiKNzVkJe1e5l5Wki4g0a4ZhsGZfLu+szWTJ1izKne6z5v4+XtyY5D5r3ichTGfNmxmbzcYTt/Zm79EithzKY9Ib6/hg8iACHUq/ALjsBlj8J8hcAwXZEBxtdkSWoneJiEhjO7QeyvLALwziLzc7GhERaQDHCsv4YL37rHn6sSJPeY+4EMYNTGRUnziC/XTWvDnz8/Hi1Qn9uPGF1ezMKuCP8zcz8xeXY7frCxlC4yG+PxxaBx//DmJ7g1+o+38jv1D3KPBnLvsGtaiZcJSki4g0tqpL3TteA3ZNzSIi0lxUnTV/87sMPt+WRYXTACDQ14ub+sTzi4GJ9GoTanKU0phiQ/15+ZeXM+61NSzemsWLK/fw22s7mx2WNfS42Z2k/7jY/TgXm9epJL6GBP6nyb23v3sudrvXqeczl88sq2Hd5lXzPo38BYGSdBGRxqb70UVEmpW84gre33CQt77LYN/R02fNkxLCGDcggRuT4nSZcwvWv10E/zu6Jw99sIVnl/3IZTHBDOsRY3ZY5hvwK/Dxg/zDUJoHJSfdz6Unqy87y8FwQkmu+3HChFh/vw1C2zTaj9NfCxGRxlR03D3lCEBHzY8uItJUGYbB5oN5vLkmg483H/aM0B7g68XovvGMT06kR5zOmovb2AGJbD+cz3/SMvj9vE0smDKYLtHBZodlLh8/d6J+LoYBlaWnkvaT507mq7Y5y8BVeerhPGO5at1Zy/aK2uOwN27arCRdRKQx7VsJGBDVA0LizI5GRETqqKisko82Heat7zLYdjjfU35ZTDC/vKKt7jWXWv3thu7syi5gzb5cJr2xjo+mDCYswNfssKzNZgMff/cjJLbhf57LdTppN5ynE3n/8Ib/2WdQki4i0pg8l7pfa24cIiJSJzuz8nlrTSYLNh6isKwSAF9vOzf0imX8FW25PFEjtMu5+XjZeWl8P2568Rsyjhcz9e2NzL17AN5edrNDkyp2O9h9AXO/PFGSLiLSWFwu2LPCvawkXUTE8kornCzeeoS31mSyLuP0jbDtWgUwPrktt/VrQ3igzoTKhYsI9OW1Cf255aVv+WbPMWYs3skjN3Q3OyyxGCXpIiKNJXsrFOWATwAkppgdjYiI1GL/sSLeXpvJ/HUHOFHsvk/Vy25jWPdofnlFW1I6tNI0WnLRusWG8OyYJCa/tYHXv0mnW2wIt/VrvEHJxPqUpIuINJaqS93bXw3eDnNjERGRaiqcLlbsyOat7zL5evcxT3lcqB/jBiYyZkAC0SF+JkYozcnIXrH8dmgn/vXFHv6yYAsdWwfSN7Fx73sW61KSLiLSWPZ+4X7uqEvdRUSsIvN4MfPXH+C9dQfIzi8D3GNV/axLa36Z3JYhXVvrnmFpEA+mdmFHVgHLtmfz6/+u5+MHrtQXQQIoSRcRaRxlBZCZ5l7W/egiIqYqrXCyZGsW874/QNq+457yVoG+jBmQwC8GJpIQEWBihNIS2O02nhvbh1teWs2P2YX8+r/refe+K/Dz8TI7NDGZJb4WnDlzJu3atcPPz4/k5GTWrl1b676vvfYaV111FeHh4YSHh5OamnrO/UVELCH9K/c0HuHtoFVHs6MREWlxDMPgh4Mn+euCLQz4x3IenLeJtH3Hsdngqs6RvDCuL2kPX8tDIy5Tgi6NJsjhzWsT+hPq78OmAyf5xWtr+L+f7eC/azL48sejpB8rorzSZXaY0shMP5M+b948pk2bxssvv0xycjLPP/88w4cPZ9euXURFRZ21/6pVqxg3bhyDBg3Cz8+PJ598kmHDhrFt2zbi4+NNqIGIyAXwjOqeam4cIiItTG5ROQs2HmL+ugPszCrwlLcJ9+f2fgnc2i+eNuFKysU8bVsFMvMXlzNxzlo2ZJ5kQ+bJatttNogL9Schwp/EiAASwgNIbBVAQkQAiREBtAr01fR/zYzNMAzDzACSk5MZMGAAL774IgAul4uEhAQeeOAB/vznP5/39U6nk/DwcF588UUmTJhw1vaysjLKyso86/n5+SQkJJCXl0dISEj9VUREpDaGAf8vCU5mwLh3oetIsyMSi8nPzyc0NFR9Uz3S77Rlc7oMvtp9lPnrDrBsezYVTve/u77edkb2jGFM/wSN0C6WszMrnzV7j5OZW0JmbjEHcovJzC2mpMJ5ztcF+Hq5k/dTSXvVIyHCn7gwf/x9vJTEW0Bd+iVTz6SXl5ezfv16Hn74YU+Z3W4nNTWVtLS0CzpGcXExFRUVRERE1Lh9xowZPP744/USr4jIRcnd507Q7T7Q7iqzoxERabYyjhcxf91B3l9/kKz8Uk95z/gQxvZP4KakeEIDfEyMUKR2l8WEcFlM9eTNMAyOFZZXS9qrHgdyi8nKL6W43MnOrIJqV4qcydfbTniAD2H+voQF+BAe4H4OC/B1l59aDvP3ITzw1DZ/X3y96+/OaKfLoKzSSVmFi3Kn69Szk/JKg7AAH1oHO/DRAI0epibpx44dw+l0Eh0dXa08OjqanTt3XtAxHnroIeLi4khNrfkS0ocffphp06Z51qvOpIuINJqqqdcSrwBHkLmxiIg0MyXlThZvPcJ76w6wZl+upzwswIfRfeK5vX8besSFmhihyMWz2Wy0DnbQOthBv7ZnT9FWVunk0ImSGpL4EjKPF1FU7qS80kV2fpln9oILFejr5U7eTyX2oQE+BDu8qXC6E+7yShdlla5qyzWVlVW6cLrOf/F2q0BfWgc7iA7xIyrYQVTI6eXWwX5Eh7h/Dw7v5j+wnun3pF+KJ554gnfffZdVq1bh51fzdAUOhwOHQ/MRi4iJqpJ03Y8uIlIvDMNg88E83lt3gI83HaagrBLg1CBwrRnTvw0/7x7dIv6Zl5bN4e1Fh9ZBdGh99kkAwzAoLKvkZHEFeSUVnCgu50RxBXmnnk8WV3CyuJwTxeWcLHGvnyguJ6+kAsOAonInReUlHDpZUq8xe9tt+HrbcXjb8bLbySspp8JpcLyonONF5bVeEVAlPMCHqGA/okIcZzyfTui7xgQT7Ne0r5gxNUmPjIzEy8uL7OzsauXZ2dnExMSc87XPPPMMTzzxBMuXL6d3794NGaaIyMWrKIX937iXNfWaiMglqXS6+OSHI7zy1T52HMn3lLcJ92dM/wRu7deG+DB/EyMUsQ6bzUawnw/Bfj7U5Tpil8sgv/R00n6yuIKTJeWcKKqgsKwSX287vl52HD52HN5enoTb/Ti97udjx9fL69R+ds/rvH9yWbvLZXCiuJycgjKy80vJKSjjaNVyfhnZBe7nowVllDtdnCiu4ERxBbuya7m838vO1V0iGdkzltTu0YT6N72E3dQk3dfXl379+rFixQpGjx4NuAeOW7FiBVOnTq31dU899RT/+Mc/WLp0Kf3792+kaEVELkJmGlQUQ1A0RPc0OxoRkSaptMLJ/PUHefWrvRzIdZ/Vc5wxCNwVGgROpN7Y7bZTl7n70o7ARvl5rYIctApy0C229gHVDMPgZHFFtWQ+51QCX/V86GQJR/JKWb4jh+U7cvDxsnFV59aM7BnDsO4xTWZMCtMvd582bRoTJ06kf//+DBw4kOeff56ioiLuvvtuACZMmEB8fDwzZswA4Mknn+TRRx/l7bffpl27dmRlZQEQFBREUJDu9RQRiznzUneNrCoiUicFpRW8uSaT179J51ih+37aiEBf7hncjjuvaNdk/uEWkUtns9kID/QlPNCXrjHBNe5jGAY/Zhfy2ZYjfLblCLtzCvliZw5f7MzhL15bGNwpkut6xjKsRzRhAb6NXIMLZ3qSPnbsWI4ePcqjjz5KVlYWffr0YcmSJZ7B5DIzM7HbT18SMWvWLMrLy7ntttuqHWf69Ok89thjjRm6iMj57f3C/dxxqLlxiIg0IccKy5izOp030jIoKHXfbx4f5s+kq9ozdkAi/r6611xEzmaz2egaE0zXmGB+//Mu7M4u4NNTCfuP2YWs2nWUVbuO8pcFNgZ1iuT6Xu4z7OGB1krYTZ8nvbFp3lQRaTR5h+C57oAN/rQPAmqeKlJEfVP90++0aTp4opjXvtrHvHUHKK1wAdCxdSCTh3RiVJ84TdEkIhdtT04Bn23J4rMtR6oNTudltzGoYyuu6xXLsO7RtApqmEHHm8w86SIizdreFe7n+MuVoIuInMPu7AJmfbmXRZsOU3lqqqakNqFMHtKJYd2jdb+5iFyyTlHB/PbaYH57bWf2Hi1k8ZYjfLolix1H8vl69zG+3n2Mvy3cyhUdIriuVyzDe8QQ2UAJ+/koSRcRaSh7TiXpmnpNRKRGmw6c5KWVe/h8++mZfgZ3asVvhnRiUMdW2DSWh4g0gI6tg5g6tDNTh3Ym/ViR5x72bYfzWb3nOKv3HOeRhVtJbt+K63rHcmPv2Ea9h11JuohIQ3BWwr6V7mUl6SIiHoZhsHrPcWZ9uYfVe457yof3iOY3QzqRlBBmXnAi0uK0jwxkyjWdmHJNJ/YfK2LxVvcl8VsO5ZG27zhp+44zoF24knQRkSbv0HoozQO/UIi73OxoRERM53IZfL49m1mr9rD5YB4A3nYbo/rEM3lIBzpF1Txas4hIY2kXGcjkIR2ZPKQjmceLWbz1CD8cyqNrdOP+fVKSLiLSEKruR+9wDXjpT62ItFzllS4WbT7My1/uZU9OIQB+PnbuGJDIr65qT5vwAJMjFBE5W2KrAH79s46m/Gz95ygi0hDOnB9dRKQFyiup4J21mcxZnU52vnuO82A/byamtOPuwe0abARlEZGmTkm6iEh9KzoOhza4lzU/uoi0MAdPFDP7m/3M+z6TonInAFHBDu65sj3jkxMJ9vMxOUIREWtTki4iUt/2rQQMiOoOofFmRyMi0ih+OHiS175O57MtR3Cemkata3Qwk67uwI1JsTi8vUyOUESkaVCSLiJSn5yVsPZV97LOootIM+dyGazclcNrX+9jzb5cT/mVnSKZdHUHru4cqWnURETqSEm6iEh9Wv0cHPgOfINh4CSzoxERaRClFU4WbjzEa1/vY+/RIsA9UvtNSXHce1V7esSFmhyhiEjTpSRdRKS+HFoPq55wL1/3FIS3MzUcEZH6lltUzptrMngjbT/HCssBCHZ484vkRO4a3I7YUH+TIxQRafqUpIuI1IeyQvhgErgqoftoSBpndkQiIvVm/7EiXv8mnfnrD1Ba4QIgLtSPe65sz9gBCRoMTkSkHilJFxGpD0v/Arl7ITgObngOdA+miDQD6zNyee2rdJZuz8JwjwVHz/gQJl3Vget6xeLjZTc3QBGRZkhJuojIpdrxCWz4D2CDm1+GgAizIxIRuWgul8Hn27N49at9bMg86Sm/pmtrJl3dgZQOrTQYnIhIA1KSLiJyKQqyYNED7uVBU6HDz8yNR0TkEmQeL+aP8zezdr97pHZfLzs3943nV1e1p3N0sMnRiYi0DErSRUQulssFC38DJbkQ0wuGPmJ2RCIiF8UwDN5Ze4D//XQ7xeVOAn29uHtweyYMaktUsJ/Z4YmItChK0kVELtbaV2HvCvD2g1v+Dd4OsyMSEamz7PxSHvrgB1btOgrAwPYR/PP2JBIiAkyOTESkZVKSLiJyMbK3w7JH3cs//ztEXWZuPCIiF2HR5sM8snAreSUV+Hrb+dPwrtwzuD12u+45FxExi5J0EZG6qiyDDyeBsww6pcLASWZHJCJSJyeKynnko6188sMRAHrFh/LsmCTddy4iYgFK0kVE6mrF/0D2VghoBaNe0nRrItKkrNyZw58++IGjBWV42W1MvaYTU4d20nRqIiIWoSRdRKQu9q6EtBfdyze9CMHR5sYjInKBCssq+cen23ln7QEAOrYO5LmxfejdJszcwEREpBol6SIiF6o4FxZOdi/3uwsuu87UcERELtR3+47zx/c3cyC3BJsN7hncnv8zvCt+Pl5mhyYiIj+hJF1Emo6CLNj4X9j4JjhCYNRMiO3dOD/bMODj30HBEWjVCYb/38b5uSIil6C0wsk/P9/Fv79JxzAgPsyfZ25PIqVjK7NDExGRWihJFxFrc7kgfRWsmw27FoOr8vS214bC0L/BoAfA3sBngza9DTsWgd0bbnkNfAMb9ueJiFyirYfy+P28TezOKQRgTP82PHJDd4L9fEyOTEREzkVJuohYU+FR2PQmrJ8LJ/afLk9IhssnuBP2nZ/A8umwexncPAvCEhsmltx9sPhP7uUhD0P85Q3zc0RE6kGl08VLq/byrxW7qXQZRAY5eOKWXqR21xgaIiJNgZJ0EbEOw4D9X8O6ObDjY3BVuMsdIZB0h/s+8Oge7rI+492Xvi/+M2R8A7MGw/X/hF631+9o685K+PDXUF4IiYPgyt/X37FFROrZnpxC/vDeJjYfzAPgul4x/O/oXkQE+pocmYiIXCgl6SJivuJc2PSW+6z58T2ny+P7Qb+7oectZ19ebrO5z6i3u9KdRB9c6567fNdiuOFZ8A+vn9i+fsZ9bEcI3PJKw19WLyJyEVwug7nf7ufJJTspq3QR4ufN30f35KakOGyaJlJEpElRki4i5jAMyExznzXf/hE4y9zlvkHus+H974bYpPMfJ6ID3L0YvnkWVj0B2z6EzDXuy987DLm0GA98D18+5V6+/p8Ndzm9iMgl2H+siIc/3ELavuMAXNU5kqdu601sqL/JkYmIyMVQki4ijavkBGyeB+vnwNGdp8tjekP/e6DXbeAIrtsxvbzhZ3+Cjte6z6bn7oU3RsEVU+DaR8HHr+5xlhXAh78Cwwk9b4PeY+p+DBGRBuJyGXy95xhvfLufL3blYBjg7+PFX67vxi+TE3X2XESkCVOSLiINzzDg4Dp3Yr71Q6gscZf7BEDPW91nzeMuv/R7ydv0g/u/hs//5h4Nfs1M2LfSPRp7TM+6HWvxn90D1oUmuM+ii4hYQF5JBe+vP8h/0/az/3ixp3xI19Y8dmMP2kVq5gkRkaZOSfql+PFzOLDG7CikyTuVmHoS1ItZN8DldJ/1NVynl12uU8/OnzzXVO6qfgzPw3A/w0/WjXOsG9XXy4sgL/N0laN6uBPz3mPAL7R+f52+gXDDc9BlBHw0BXK2w2vXwNBHIGUq2O3nP8b2j9wjy2ODm18G/7D6jVFEpI52ZuXzRloGCzYcoqTCCUCww5vb+rfhziva0qF1kMkRiohIfVGSfinSv4S0F82OQqRp8PaDHje7B4JLGFi/I7DXpMtwmJwGH/8Wdn0Gyx6B3Z+7k+7QNrW/Lv8wLPqte/nKB90D04mImKDC6eLzbdn8J20/a9NzPeVdo4O5M6UtN/eNJ9Chf+VERJob/WW/FIkp7jOPIhfNOPVkXNo6gM3LPfK4zX5q2X5G2ZnPNZXbz163ebkTadupM882+xnrthrWf7p8xrrdyz11Wn2NuH6hglrDHW/Dhv/Akr+4p3d7aZB79Pdet529v8sFC+6H0pPuQeuG/KVx4xURAXIKSnnnuwO8vTaD7Hz3oJpedhvDe0QzIaUdye0jdM+5iEgzpiT9UnS7wf0QEeuy2dzzq7e7Cj68Dw6tgw/udU/Vdv0z1b84WPOS+woZb3+45d/grXmFRaRxGIbB+owTvJGWweKtR6hwur+EjQzy5RcDExmXnKjR2kVEWggl6SLSMrTqCPcsdc97/uVTsPV99xRwN78M7a+GrC2w4nH3vsP/Aa27mBuviFjCzqx8Hl24jdbBjtOPoNPLUcEOIgJ98fa6gPEualBS7mTR5kP859sMth/J95T3axvOhJS2jOgZg8Pbq76qIyIiTYCSdBFpOby8YcifoVPqqana9sF/boKUKbBnBTjL3QPO9b/H7EhFxCIO5pawdn/uOfex2aBVoC+R1ZJ3vxqT+hA/b2w2GxnHi3hzTQbvrTtIXkkFAA5vO6P6xDEhpR094+t5UE0REWkybIZhGOffrfnIz88nNDSUvLw8QkJCzA5HRMxSVgif/xXWzz1dFtjaPdhcUGvTwpKWSX1T/auv32lOfilr9+dytKDs9KPw9PKxwjJcdfhPyuFtJzLIweG8Es/wIgkR/tx5RVtu75dAeKBusxERaY7q0i/pTLqItEyOILjx/52aqm0qlJyAUTOVoItINVEhftzQO67W7U6XQW5R+VnJ++n1UnJOrReUVlJW6eLQyRIAftalNRNS2jKkaxRedg0EJyIibkrSRaRl6zoSfrcJio9DeDuzoxGRM8ycOZOnn36arKwskpKSeOGFFxg4cKDZYVXjZbd5LmU/n9IKpyd5bx3kICEioBEiFBGRpubiRjkREWlOHMFK0EUsZt68eUybNo3p06ezYcMGkpKSGD58ODk5OWaHdtH8fLxIiAjg8sRwJegiIlIrJekiIiJiOc8++yyTJk3i7rvvpnv37rz88ssEBAQwe/Zss0MTERFpUErSRURExFLKy8tZv349qampnjK73U5qaippaWk1vqasrIz8/PxqDxERkaZISbqIiIhYyrFjx3A6nURHR1crj46OJisrq8bXzJgxg9DQUM8jISGhMUIVERGpd0rSRUREpMl7+OGHycvL8zwOHDhgdkgiIiIXRaO7i4iIiKVERkbi5eVFdnZ2tfLs7GxiYmJqfI3D4cDhOP8I6yIiIlanM+kiIiJiKb6+vvTr148VK1Z4ylwuFytWrCAlJcXEyERERBqezqSLiIiI5UybNo2JEyfSv39/Bg4cyPPPP09RURF333232aGJiIg0KCXpIiIiYjljx47l6NGjPProo2RlZdGnTx+WLFly1mByIiIizY2SdBEREbGkqVOnMnXqVLPDEBERaVS6J11ERERERETEIpSki4iIiIiIiFiEknQRERERERERi1CSLiIiIiIiImIRStJFRERERERELKLFje5uGAYA+fn5JkciIiLiVtUnVfVRcunU34uIiJXUpa9vcUl6QUEBAAkJCSZHIiIiUl1BQQGhoaFmh9EsqL8XERErupC+3ma0sK/tXS4Xhw8fJjg4GJvNdknHys/PJyEhgQMHDhASElJPEZpDdbGe5lIPaD51aS71gOZTl+ZSD8MwKCgoIC4uDrtdd6LVB/X3Z2su9YDmU5fmUg9QXayoudQDmkdd6tLXt7gz6Xa7nTZt2tTrMUNCQprsm+WnVBfraS71gOZTl+ZSD2g+dWkO9dAZ9Pql/r52zaUe0Hzq0lzqAaqLFTWXekDTr8uF9vX6ul5ERERERETEIpSki4iIiIiIiFiEkvRL4HA4mD59Og6Hw+xQLpnqYj3NpR7QfOrSXOoBzacuzaUeYm3N5X3WXOoBzacuzaUeoLpYUXOpBzSvulyIFjdwnIiIiIiIiIhV6Uy6iIiIiIiIiEUoSRcRERERERGxCCXpIiIiIiIiIhahJF1ERERERETEIpSkn8fMmTNp164dfn5+JCcns3bt2nPuP3/+fC677DL8/Pzo1asXn332WSNFWrsZM2YwYMAAgoODiYqKYvTo0ezateucr5k7dy42m63aw8/Pr5Eirt1jjz12VlyXXXbZOV9jxTZp167dWfWw2WxMmTKlxv2t1B5fffUVN954I3FxcdhsNhYuXFhtu2EYPProo8TGxuLv709qaiq7d+8+73Hr+lmrD+eqS0VFBQ899BC9evUiMDCQuLg4JkyYwOHDh895zIt5jzZkPQDuuuuus2IaMWLEeY9rtTYBavzc2Gw2nn766VqPaUabSNPT1Pt79fXWao8qTbW/V1+vvr4hqa8/PyXp5zBv3jymTZvG9OnT2bBhA0lJSQwfPpycnJwa9//2228ZN24c9957Lxs3bmT06NGMHj2arVu3NnLk1X355ZdMmTKFNWvWsGzZMioqKhg2bBhFRUXnfF1ISAhHjhzxPDIyMhop4nPr0aNHtbi++eabWve1apt8//331eqwbNkyAG6//fZaX2OV9igqKiIpKYmZM2fWuP2pp57iX//6Fy+//DLfffcdgYGBDB8+nNLS0lqPWdfPWn05V12Ki4vZsGEDjzzyCBs2bODDDz9k165d3HTTTec9bl3eo/XhfG0CMGLEiGoxvfPOO+c8phXbBKhWhyNHjjB79mxsNhu33nrrOY/b2G0iTUtz6O/V11urPao01f5efb36+oakvv4CGFKrgQMHGlOmTPGsO51OIy4uzpgxY0aN+48ZM8a4/vrrq5UlJycbv/71rxs0zrrKyckxAOPLL7+sdZ85c+YYoaGhjRfUBZo+fbqRlJR0wfs3lTb53e9+Z3Ts2NFwuVw1brdqewDGggULPOsul8uIiYkxnn76aU/ZyZMnDYfDYbzzzju1Hqeun7WG8NO61GTt2rUGYGRkZNS6T13fo/WtpnpMnDjRGDVqVJ2O01TaZNSoUcbQoUPPuY/ZbSLW1xz7e/X11mqPKk2xv1dffzaz+xX19Wczu03qm86k16K8vJz169eTmprqKbPb7aSmppKWllbja9LS0qrtDzB8+PBa9zdLXl4eABEREefcr7CwkLZt25KQkMCoUaPYtm1bY4R3Xrt37yYuLo4OHTowfvx4MjMza923KbRJeXk5b775Jvfccw82m63W/azaHmdKT08nKyur2u88NDSU5OTkWn/nF/NZM0teXh42m42wsLBz7leX92hjWbVqFVFRUXTt2pXJkydz/PjxWvdtKm2SnZ3Np59+yr333nvefa3YJmINzbW/V19vrfaA5tPfq693s2K/or7eem1ysZSk1+LYsWM4nU6io6OrlUdHR5OVlVXja7Kysuq0vxlcLhcPPvgggwcPpmfPnrXu17VrV2bPns1HH33Em2++icvlYtCgQRw8eLARoz1bcnIyc+fOZcmSJcyaNYv09HSuuuoqCgoKaty/KbTJwoULOXnyJHfddVet+1i1PX6q6vdal9/5xXzWzFBaWspDDz3EuHHjCAkJqXW/ur5HG8OIESN44403WLFiBU8++SRffvklI0eOxOl01rh/U2mT//znPwQHB3PLLbeccz8rtolYR3Ps79XXW6s9qjSX/l59vTX7FfX11muTS+FtdgDSuKZMmcLWrVvPe49GSkoKKSkpnvVBgwbRrVs3XnnlFf7+9783dJi1GjlypGe5d+/eJCcn07ZtW957770L+obNil5//XVGjhxJXFxcrftYtT1aioqKCsaMGYNhGMyaNeuc+1rxPXrHHXd4lnv16kXv3r3p2LEjq1at4tprrzUlpvowe/Zsxo8ff95BlazYJiINSX29Nam/tzb19dbUUvt6nUmvRWRkJF5eXmRnZ1crz87OJiYmpsbXxMTE1Gn/xjZ16lQ++eQTVq5cSZs2ber0Wh8fH/r27cuePXsaKLqLExYWRpcuXWqNy+ptkpGRwfLly/nVr35Vp9dZtT2qfq91+Z1fzGetMVV12hkZGSxbtuyc36zX5HzvUTN06NCByMjIWmOyepsAfP311+zatavOnx2wZpuIeZpbf6++3s0q7VGlOfX36uvPZsV+RX299dqkLpSk18LX15d+/fqxYsUKT5nL5WLFihXVvuE8U0pKSrX9AZYtW1br/o3FMAymTp3KggUL+OKLL2jfvn2dj+F0OtmyZQuxsbENEOHFKywsZO/evbXGZdU2qTJnzhyioqK4/vrr6/Q6q7ZH+/btiYmJqfY7z8/P57vvvqv1d34xn7XGUtVp7969m+XLl9OqVas6H+N871EzHDx4kOPHj9cak5XbpMrrr79Ov379SEpKqvNrrdgmYp7m0t+rr7dWe/xUc+rv1defzYr9ivp667VJnZg7bp21vfvuu4bD4TDmzp1rbN++3bjvvvuMsLAwIysryzAMw7jzzjuNP//5z579V69ebXh7exvPPPOMsWPHDmP69OmGj4+PsWXLFrOqYBiGYUyePNkIDQ01Vq1aZRw5csTzKC4u9uzz07o8/vjjxtKlS429e/ca69evN+644w7Dz8/P2LZtmxlV8PjDH/5grFq1ykhPTzdWr15tpKamGpGRkUZOTo5hGE2nTQzDPYJmYmKi8dBDD521zcrtUVBQYGzcuNHYuHGjARjPPvussXHjRs8oqE888YQRFhZmfPTRR8YPP/xgjBo1ymjfvr1RUlLiOcbQoUONF154wbN+vs+aGXUpLy83brrpJqNNmzbGpk2bqn12ysrKaq3L+d6jjV2PgoIC449//KORlpZmpKenG8uXLzcuv/xyo3PnzkZpaWmt9bBim1TJy8szAgICjFmzZtV4DCu0iTQtzaG/V19vrfY4U1Ps79XXq69vSOrrz09J+nm88MILRmJiouHr62sMHDjQWLNmjWfbz372M2PixInV9n/vvfeMLl26GL6+vkaPHj2MTz/9tJEjPhtQ42POnDmefX5alwcffNBT7+joaOO6664zNmzY0PjB/8TYsWON2NhYw9fX14iPjzfGjh1r7Nmzx7O9qbSJYRjG0qVLDcDYtWvXWdus3B4rV66s8f1UFa/L5TIeeeQRIzo62nA4HMa11157Vh3btm1rTJ8+vVrZuT5rZtQlPT291s/OypUra63L+d6jjV2P4uJiY9iwYUbr1q0NHx8fo23btsakSZPO6oCbQptUeeWVVwx/f3/j5MmTNR7DCm0iTU9T7+/V11urPc7UFPt79fXq682qS5WW3tfbDMMwLvYsvIiIiIiIiIjUH92TLiIiIiIiImIRStJFRERERERELEJJuoiIiIiIiIhFKEkXERERERERsQgl6SIiIiIiIiIWoSRdRERERERExCKUpIuIiIiIiIhYhJJ0EREREREREYtQki4ijc5ms7Fw4UKzwxAREZEGor5e5OIpSRdpYe666y5sNttZjxEjRpgdmoiIiNQD9fUiTZu32QGISOMbMWIEc+bMqVbmcDhMikZERETqm/p6kaZLZ9JFWiCHw0FMTEy1R3h4OOC+PG3WrFmMHDkSf39/OnTowPvvv1/t9Vu2bGHo0KH4+/vTqlUr7rvvPgoLC6vtM3v2bHr06IHD4SA2NpapU6dW237s2DFuvvlmAgIC6Ny5M4sWLWrYSouIiLQg6utFmi4l6SJylkceeYRbb72VzZs3M378eO644w527NgBQFFREcOHDyc8PJzvv/+e+fPns3z58mod86xZs5gyZQr33XcfW7ZsYdGiRXTq1Knaz3j88ccZM2YMP/zwA9dddx3jx48nNze3UespIiLSUqmvF7EwQ0RalIkTJxpeXl5GYGBgtcc//vEPwzAMAzDuv//+aq9JTk42Jk+ebBiGYbz66qtGeHi4UVhY6Nn+6aefGna73cjKyjIMwzDi4uKMv/71r7XGABh/+9vfPOuFhYUGYCxevLje6ikiItJSqa8Xadp0T7pIC3TNNdcwa9asamURERGe5ZSUlGrbUlJS2LRpEwA7duwgKSmJwMBAz/bBgwfjcrnYtWsXNpuNw4cPc+21154zht69e3uWAwMDCQkJIScn52KrJCIiImdQXy/SdClJF2mBAgMDz7okrb74+/tf0H4+Pj7V1m02Gy6XqyFCEhERaXHU14s0XbonXUTOsmbNmrPWu3XrBkC3bt3YvHkzRUVFnu2rV6/GbrfTtWtXgoODadeuHStWrGjUmEVEROTCqa8XsS6dSRdpgcrKysjKyqpW5u3tTWRkJADz58+nf//+XHnllbz11lusXbuW119/HYDx48czffp0Jk6cyGOPPcbRo0d54IEHuPPOO4mOjgbgscce4/777ycqKoqRI0dSUFDA6tWreeCBBxq3oiIiIi2U+nqRpktJukgLtGTJEmJjY6uVde3alZ07dwLu0VjfffddfvOb3xAbG8s777xD9+7dAQgICGDp0qX87ne/Y8CAAQQEBHDrrbfy7LPPeo41ceJESktLee655/jjH/9IZGQkt912W+NVUEREpIVTXy/SdNkMwzDMDkJErMNms7FgwQJGjx5tdigiIiLSANTXi1ib7kkXERERERERsQgl6SIiIiIiIiIWocvdRURERERERCxCZ9JFRERERERELEJJuoiIiIiIiIhFKEkXERERERERsQgl6SIiIiIiIiIWoSRdRERERERExCKUpIuIiIiIiIhYhJJ0EREREREREYtQki4iIiIiIiJiEf8fA/wReiHAbdIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp21.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp21.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp21.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp21.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZajLvMZefqO"
   },
   "source": [
    "## 2-2. (32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EiCGNbU7eQCm"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "z_Ywjw2xfCHR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=16, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp22_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "7FBFKA9pfDgm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp22_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05V-KQUSfEoE",
    "outputId": "70ffee6f-7aca-4462-fcda-9ae7a84d8d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21090     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73794     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129154    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221314    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         405762    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401346   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2174978   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2171394   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21352648 (81.45 MB)\n",
      "Trainable params: 2433888 (9.28 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp22_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtt2vlBufF-G",
    "outputId": "3a44abe6-5371-474a-e679-c9a1e581bc6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19296\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221184\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp22_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "p7JVgT5zfG8x"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp22_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ywJfZm9PfIlc"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "yc4NMzPJfJf6"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "3uc9kMrGfKXi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp22_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo9O94YY--zH"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSIOk0uqfMog",
    "outputId": "7ebc32ba-af98-4b74-d965-158397531961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9746\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 75s 40ms/step - loss: 0.0821 - accuracy: 0.9746 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9808\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 65s 39ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9501\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 67s 40ms/step - loss: 0.1541 - accuracy: 0.9501 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8925\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.3302 - accuracy: 0.8925 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.8550\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.4444 - accuracy: 0.8550 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.8183\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3025944232940674, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.5516 - accuracy: 0.8183 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.7853\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3026270866394043, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.6570 - accuracy: 0.7853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7652 - accuracy: 0.7493\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3024771213531494, acc: 0.10140000283718109\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.7652 - accuracy: 0.7493 - val_loss: 2.3025 - val_accuracy: 0.1014\n",
      "Epoch 9/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.8659 - accuracy: 0.7196\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.302384853363037, acc: 0.10010000318288803\n",
      "\n",
      "1667/1667 [==============================] - 69s 41ms/step - loss: 0.8661 - accuracy: 0.7196 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9474 - accuracy: 0.6916\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3165667057037354, acc: 0.10100000351667404\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.9474 - accuracy: 0.6916 - val_loss: 2.3165 - val_accuracy: 0.1010\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0449 - accuracy: 0.6575\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.3377485275268555, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 1.0449 - accuracy: 0.6575 - val_loss: 2.3377 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1253 - accuracy: 0.6282\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.50758695602417, acc: 0.10490000247955322\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 1.1253 - accuracy: 0.6282 - val_loss: 2.5075 - val_accuracy: 0.1050\n",
      "Epoch 13/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 1.1968 - accuracy: 0.6022\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 5.463865280151367, acc: 0.10740000009536743\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 1.1967 - accuracy: 0.6022 - val_loss: 5.4639 - val_accuracy: 0.1076\n",
      "Epoch 14/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.9980 - accuracy: 0.7060\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.728248357772827, acc: 0.10050000250339508\n",
      "\n",
      "1667/1667 [==============================] - 67s 40ms/step - loss: 0.9980 - accuracy: 0.7060 - val_loss: 2.7284 - val_accuracy: 0.1005\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.7828\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.2612526416778564, acc: 0.21639999747276306\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.6439 - accuracy: 0.7828 - val_loss: 2.2613 - val_accuracy: 0.2163\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.7916\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.97490394115448, acc: 0.5080000162124634\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.6133 - accuracy: 0.7916 - val_loss: 1.9749 - val_accuracy: 0.5081\n",
      "Epoch 17/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.7976\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.5605082511901855, acc: 0.6189000010490417\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.5948 - accuracy: 0.7976 - val_loss: 1.5606 - val_accuracy: 0.6191\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7970\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7317078709602356, acc: 0.7605999708175659\n",
      "\n",
      "1667/1667 [==============================] - 68s 41ms/step - loss: 0.5991 - accuracy: 0.7970 - val_loss: 0.7317 - val_accuracy: 0.7602\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.8060\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7406930923461914, acc: 0.758400022983551\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5733 - accuracy: 0.8060 - val_loss: 0.7407 - val_accuracy: 0.7584\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.8309\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7511334419250488, acc: 0.7645999789237976\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.4990 - accuracy: 0.8309 - val_loss: 0.7511 - val_accuracy: 0.7645\n"
     ]
    }
   ],
   "source": [
    "history_exp22 = exp22_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tq5Lt1mf8vz",
    "outputId": "c120eb20-bc6f-4476-8478-f923414b8cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7511 - accuracy: 0.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7511334419250488, 0.7645999789237976]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp22_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "NYKZmdk1fPCA",
    "outputId": "24c338c0-754c-477d-c17a-d974d1a05ce0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp22.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp22.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp22.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp22.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5MbMZ4hehMi"
   },
   "source": [
    "## 2-3. (32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "8WLRVDyWej1q"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "1fICgSqQqwIW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=32, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=64, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp23_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "rDp5dkpgqx7G"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp23_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrXZDLTRq4LV",
    "outputId": "dca73ae6-8aef-4263-9a75-cbb1e68cbdc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        21090     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        73794     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       129154    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       221314    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         405762    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         737538    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1401346   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2654722   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2396162   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2392578   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21795016 (83.14 MB)\n",
      "Trainable params: 2876256 (10.97 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp23_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BISzZtRq14v",
    "outputId": "219b5c2e-3f4a-48f6-8b05-8221e3e938a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 19296\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 221184\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp23_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "_jH8Ng1iq8s9"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp23_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "6M9Ijmuhq_ql"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "CdXjUGAUrCRa"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ZMc-zQIQrEyM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp23_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dkn_4j2Y_B46"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Xzwh-2nrHaz",
    "outputId": "d0d1c9ee-e321-4dbe-955e-1e355594fe0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9746\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 71s 37ms/step - loss: 0.0800 - accuracy: 0.9746 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9825\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9501\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.1544 - accuracy: 0.9501 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8976\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.3184 - accuracy: 0.8976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8601\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.302607536315918, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.4293 - accuracy: 0.8601 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.8245\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.3026061058044434, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 59s 36ms/step - loss: 0.5328 - accuracy: 0.8245 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.7922\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3026177883148193, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 58s 35ms/step - loss: 0.6341 - accuracy: 0.7922 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7295 - accuracy: 0.7592\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.302478790283203, acc: 0.10599999874830246\n",
      "\n",
      "1667/1667 [==============================] - 59s 35ms/step - loss: 0.7295 - accuracy: 0.7592 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.7296\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.2971768379211426, acc: 0.1006999984383583\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 0.8180 - accuracy: 0.7296 - val_loss: 2.2972 - val_accuracy: 0.1007\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.6999\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.2924931049346924, acc: 0.14030000567436218\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 0.9055 - accuracy: 0.6999 - val_loss: 2.2925 - val_accuracy: 0.1403\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.6745\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.343661069869995, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.9729 - accuracy: 0.6745 - val_loss: 2.3437 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0503 - accuracy: 0.6465\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.6875977516174316, acc: 0.10409999638795853\n",
      "\n",
      "1667/1667 [==============================] - 64s 39ms/step - loss: 1.0503 - accuracy: 0.6465 - val_loss: 2.6872 - val_accuracy: 0.1041\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1065 - accuracy: 0.6273\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 6.123175144195557, acc: 0.10419999808073044\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 1.1065 - accuracy: 0.6273 - val_loss: 6.1202 - val_accuracy: 0.1043\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8868 - accuracy: 0.7300\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.5300099849700928, acc: 0.11540000140666962\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.8868 - accuracy: 0.7300 - val_loss: 2.5299 - val_accuracy: 0.1154\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.7925\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.2089550495147705, acc: 0.2768000066280365\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6121 - accuracy: 0.7925 - val_loss: 2.2090 - val_accuracy: 0.2767\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.7987\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.8765963315963745, acc: 0.5406000018119812\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5827 - accuracy: 0.7987 - val_loss: 1.8766 - val_accuracy: 0.5410\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8051\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.2417364120483398, acc: 0.6449999809265137\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5719 - accuracy: 0.8051 - val_loss: 1.2417 - val_accuracy: 0.6449\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.8045\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7628178596496582, acc: 0.7512999773025513\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.5729 - accuracy: 0.8045 - val_loss: 0.7629 - val_accuracy: 0.7512\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8169\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7196321487426758, acc: 0.7628999948501587\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.5417 - accuracy: 0.8169 - val_loss: 0.7196 - val_accuracy: 0.7629\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.8414\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7166454792022705, acc: 0.7709000110626221\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.4711 - accuracy: 0.8414 - val_loss: 0.7166 - val_accuracy: 0.7709\n"
     ]
    }
   ],
   "source": [
    "history_exp23 = exp23_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndAMXGdSgAmG",
    "outputId": "b4bfcf9d-b12c-40e2-a15b-909d07c76593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.7166 - accuracy: 0.7709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7166454792022705, 0.7709000110626221]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp23_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "dEnYK6elrKvV",
    "outputId": "279e0313-27de-402e-a2d8-b5355114f29d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHWCAYAAAALjsguAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC3U0lEQVR4nOzdd3hT9dvH8Xe66aSMUkZZZe+9tyACIksURJaKjwgqIj8RUQRUcIEMFRUZKlMREAVERJAtCJS99ygbOmjpPM8foZHaAi20PUn7eV1Xrp6cnHEnhOTcub/DYhiGgYiIiIiIiIiYzsnsAERERERERETESkm6iIiIiIiIiJ1Qki4iIiIiIiJiJ5Ski4iIiIiIiNgJJekiIiIiIiIidkJJuoiIiIiIiIidUJIuIiIiIiIiYieUpIuIiIiIiIjYCSXpIiIiIiIiInZCSbrYlT59+lC8ePH72nfkyJFYLJaMDcjOnDhxAovFwsyZM7P83BaLhZEjR9ruz5w5E4vFwokTJ+65b/HixenTp0+GxvMg7xUREckedN1wd7pu+JeuG8SRKEmXNLFYLGm6rVmzxuxQc7yXX34Zi8XCkSNH7rjN8OHDsVgs7Nq1KwsjS79z584xcuRIQkJCzA4lVfv378diseDh4cH169fNDkdExG7ousFx6LohcyX9UPLJJ5+YHYo4EBezAxDH8P333ye7/91337Fy5coU68uXL/9A55k6dSqJiYn3te9bb73FG2+88UDnzw569OjB5MmTmTNnDiNGjEh1m7lz51K5cmWqVKly3+fp2bMn3bp1w93d/b6PcS/nzp1j1KhRFC9enGrVqiV77EHeKxll1qxZBAYGcu3aNRYsWMBzzz1najwiIvZC1w2OQ9cNIvZHSbqkydNPP53s/ubNm1m5cmWK9f8VFRWFp6dnms/j6up6X/EBuLi44OKit3TdunUpVaoUc+fOTfXLdtOmTRw/fpwPPvjggc7j7OyMs7PzAx3jQTzIeyUjGIbBnDlzeOqppzh+/DizZ8+22yT9xo0beHl5mR2GiOQgum5wHLpuELE/au4uGaZZs2ZUqlSJbdu20aRJEzw9PXnzzTcB+Pnnn2nXrh2FChXC3d2d4OBg3n33XRISEpId47/9hW5vIvT1118THByMu7s7tWvXZuvWrcn2Ta1vmcViYeDAgSxevJhKlSrh7u5OxYoV+e2331LEv2bNGmrVqoWHhwfBwcF89dVXae6vtm7dOrp27UrRokVxd3cnKCiIV199lejo6BTPz9vbm7Nnz9KxY0e8vb3Jnz8/Q4YMSfFaXL9+nT59+uDn50fu3Lnp3bt3mptU9+jRgwMHDrB9+/YUj82ZMweLxUL37t2JjY1lxIgR1KxZEz8/P7y8vGjcuDGrV6++5zlS61tmGAbvvfceRYoUwdPTk+bNm7N3794U+169epUhQ4ZQuXJlvL298fX1pU2bNuzcudO2zZo1a6hduzYAffv2tTWNTOpXl1rfshs3bvDaa68RFBSEu7s7ZcuW5ZNPPsEwjGTbped9cScbNmzgxIkTdOvWjW7durF27VrOnDmTYrvExEQmTpxI5cqV8fDwIH/+/DzyyCP8888/ybabNWsWderUwdPTE39/f5o0acLvv/+eLObb+/Yl+W+/vaR/l7/++osXX3yRgIAAihQpAsDJkyd58cUXKVu2LLly5SJv3rx07do11f6B169f59VXX6V48eK4u7tTpEgRevXqxeXLl4mMjMTLy4tXXnklxX5nzpzB2dmZsWPHpvGVFJGcStcNum7ISdcN93Lx4kWeffZZChQogIeHB1WrVuXbb79Nsd28efOoWbMmPj4++Pr6UrlyZSZOnGh7PC4ujlGjRlG6dGk8PDzImzcvjRo1YuXKlRkWq2Q+/XwoGerKlSu0adOGbt268fTTT1OgQAHA+sHs7e3N4MGD8fb25s8//2TEiBGEh4fz8ccf3/O4c+bMISIigv/7v//DYrHw0Ucf0blzZ44dO3bPX0bXr1/PwoULefHFF/Hx8WHSpEl06dKFU6dOkTdvXgB27NjBI488QsGCBRk1ahQJCQmMHj2a/Pnzp+l5//jjj0RFRdG/f3/y5s3Lli1bmDx5MmfOnOHHH39Mtm1CQgKtW7embt26fPLJJ/zxxx+MGzeO4OBg+vfvD1i/tDp06MD69et54YUXKF++PIsWLaJ3795piqdHjx6MGjWKOXPmUKNGjWTn/uGHH2jcuDFFixbl8uXLfPPNN3Tv3p1+/foRERHBtGnTaN26NVu2bEnRVOxeRowYwXvvvUfbtm1p27Yt27dv5+GHHyY2NjbZdseOHWPx4sV07dqVEiVKcOHCBb766iuaNm3Kvn37KFSoEOXLl2f06NGMGDGC559/nsaNGwPQoEGDVM9tGAaPPfYYq1ev5tlnn6VatWqsWLGC//3vf5w9e5ZPP/002fZpeV/czezZswkODqZ27dpUqlQJT09P5s6dy//+979k2z377LPMnDmTNm3a8NxzzxEfH8+6devYvHkztWrVAmDUqFGMHDmSBg0aMHr0aNzc3Pj777/5888/efjhh9P8+t/uxRdfJH/+/IwYMYIbN24AsHXrVjZu3Ei3bt0oUqQIJ06cYMqUKTRr1ox9+/bZqleRkZE0btyY/fv388wzz1CjRg0uX77MkiVLOHPmDNWqVaNTp07Mnz+f8ePHJ6uMzJ07F8Mw6NGjx33FLSI5i64bdN2QU64b7iY6OppmzZpx5MgRBg4cSIkSJfjxxx/p06cP169ft/0ovnLlSrp3785DDz3Ehx9+CFjHx9mwYYNtm5EjRzJ27Fiee+456tSpQ3h4OP/88w/bt2+nVatWDxSnZCFD5D4MGDDA+O/bp2nTpgZgfPnllym2j4qKSrHu//7v/wxPT0/j5s2btnW9e/c2ihUrZrt//PhxAzDy5s1rXL161bb+559/NgDjl19+sa175513UsQEGG5ubsaRI0ds63bu3GkAxuTJk23r2rdvb3h6ehpnz561rTt8+LDh4uKS4pipSe35jR071rBYLMbJkyeTPT/AGD16dLJtq1evbtSsWdN2f/HixQZgfPTRR7Z18fHxRuPGjQ3AmDFjxj1jql27tlGkSBEjISHBtu63334zAOOrr76yHTMmJibZfteuXTMKFChgPPPMM8nWA8Y777xjuz9jxgwDMI4fP24YhmFcvHjRcHNzM9q1a2ckJibatnvzzTcNwOjdu7dt3c2bN5PFZRjWf2t3d/dkr83WrVvv+Hz/+15Jes3ee++9ZNs9/vjjhsViSfYeSOv74k5iY2ONvHnzGsOHD7ete+qpp4yqVasm2+7PP/80AOPll19OcYyk1+jw4cOGk5OT0alTpxSvye2v439f/yTFihVL9tom/bs0atTIiI+PT7Ztau/TTZs2GYDx3Xff2daNGDHCAIyFCxfeMe4VK1YYgLF8+fJkj1epUsVo2rRpiv1EJGfTdcO9n5+uG6yy23VD0nvy448/vuM2EyZMMABj1qxZtnWxsbFG/fr1DW9vbyM8PNwwDMN45ZVXDF9f3xTf77erWrWq0a5du7vGJPZPzd0lQ7m7u9O3b98U63PlymVbjoiI4PLlyzRu3JioqCgOHDhwz+M++eST+Pv72+4n/Tp67Nixe+7bsmVLgoODbferVKmCr6+vbd+EhAT++OMPOnbsSKFChWzblSpVijZt2tzz+JD8+d24cYPLly/ToEEDDMNgx44dKbZ/4YUXkt1v3LhxsueybNkyXFxcbL+Qg7Uv10svvZSmeMDaH/DMmTOsXbvWtm7OnDm4ubnRtWtX2zHd3NwAa7Psq1evEh8fT61atVJt8nY3f/zxB7Gxsbz00kvJmvoNGjQoxbbu7u44OVk/fhISErhy5Qre3t6ULVs23edNsmzZMpydnXn55ZeTrX/ttdcwDIPly5cnW3+v98XdLF++nCtXrtC9e3fbuu7du7Nz585kzfR++uknLBYL77zzTopjJL1GixcvJjExkREjRthek/9ucz/69euXou/f7e/TuLg4rly5QqlSpcidO3ey1/2nn36iatWqdOrU6Y5xt2zZkkKFCjF79mzbY3v27GHXrl337HMqIpJE1w26bsgJ1w1piSUwMDDZdYWrqysvv/wykZGR/PXXXwDkzp2bGzdu3LXpeu7cudm7dy+HDx9+4LjEPErSJUMVLlzY9uF9u71799KpUyf8/Pzw9fUlf/78tgv5sLCwex63aNGiye4nffFeu3Yt3fsm7Z+078WLF4mOjqZUqVIptkttXWpOnTpFnz59yJMnj62/WNOmTYGUzy+pX/Kd4gFr3+GCBQvi7e2dbLuyZcumKR6Abt264ezszJw5cwC4efMmixYtok2bNskuXL799luqVKli67eUP39+li5dmqZ/l9udPHkSgNKlSydbnz9//mTnA+sX+6effkrp0qVxd3cnX7585M+fn127dqX7vLefv1ChQvj4+CRbnzRycFJ8Se71vribWbNmUaJECdzd3Tly5AhHjhwhODgYT0/PZEnr0aNHKVSoEHny5LnjsY4ePYqTkxMVKlS453nTo0SJEinWRUdHM2LECFvfu6TX/fr168le96NHj1KpUqW7Ht/JyYkePXqwePFioqKiAGsXAA8PD9vFnIjIvei6QdcNOeG6IS2xlC5dOsWP9f+N5cUXX6RMmTK0adOGIkWK8Mwzz6ToFz969GiuX79OmTJlqFy5Mv/73//sfuo8SUlJumSo238ZTnL9+nWaNm3Kzp07GT16NL/88gsrV6609aVJy3QYdxoN1PjPwB4ZvW9aJCQk0KpVK5YuXcrQoUNZvHgxK1eutA1U8t/nl1UjmwYEBNCqVSt++ukn4uLi+OWXX4iIiEjWV3jWrFn06dOH4OBgpk2bxm+//cbKlStp0aJFpk5TMmbMGAYPHkyTJk2YNWsWK1asYOXKlVSsWDHLpke53/dFeHg4v/zyC8ePH6d06dK2W4UKFYiKimLOnDkZ9t5Ki/8OHJQktf+LL730Eu+//z5PPPEEP/zwA7///jsrV64kb9689/W69+rVi8jISBYvXmwb7f7RRx/Fz88v3ccSkZxJ1w26bkgLR75uyEgBAQGEhISwZMkSW3/6Nm3aJBt7oEmTJhw9epTp06dTqVIlvvnmG2rUqME333yTZXHKg9PAcZLp1qxZw5UrV1i4cCFNmjSxrT9+/LiJUf0rICAADw8Pjhw5kuKx1Nb91+7duzl06BDffvstvXr1sq1/kFE0ixUrxqpVq4iMjEz2q/jBgwfTdZwePXrw22+/sXz5cubMmYOvry/t27e3Pb5gwQJKlizJwoULkzU1S615dlpiBjh8+DAlS5a0rb906VKKX5kXLFhA8+bNmTZtWrL1169fJ1++fLb76WnuXaxYMf744w8iIiKS/Sqe1CwyKb4HtXDhQm7evMmUKVOSxQrWf5+33nqLDRs20KhRI4KDg1mxYgVXr169YzU9ODiYxMRE9u3bd9cBd/z9/VOM0hsbG0toaGiaY1+wYAG9e/dm3LhxtnU3b95Mcdzg4GD27Nlzz+NVqlSJ6tWrM3v2bIoUKcKpU6eYPHlymuMREUmNrhvST9cNVvZ43ZDWWHbt2kViYmKyanpqsbi5udG+fXvat29PYmIiL774Il999RVvv/22rSVHnjx56Nu3L3379iUyMpImTZowcuRIu50qVlJSJV0yXdIvj7f/0hgbG8sXX3xhVkjJODs707JlSxYvXsy5c+ds648cOZKiP9Kd9ofkz88wjGTTYaRX27ZtiY+PZ8qUKbZ1CQkJ6U6AOnbsiKenJ1988QXLly+nc+fOeHh43DX2v//+m02bNqU75pYtW+Lq6srkyZOTHW/ChAkptnV2dk7xy/OPP/7I2bNnk61Lmts7LVPItG3bloSEBD777LNk6z/99FMsFkua+wney6xZsyhZsiQvvPACjz/+eLLbkCFD8Pb2tjV579KlC4ZhMGrUqBTHSXr+HTt2xMnJidGjR6eoBtz+GgUHByfrJwjw9ddf37GSnprUXvfJkyenOEaXLl3YuXMnixYtumPcSXr27Mnvv//OhAkTyJs3b4a9ziKSc+m6If103WBlj9cNadG2bVvOnz/P/Pnzbevi4+OZPHky3t7etq4QV65cSbafk5MTVapUASAmJibVbby9vSlVqpTtcXEMqqRLpmvQoAH+/v707t2bl19+GYvFwvfff5+lzYPuZeTIkfz+++80bNiQ/v372z60K1WqREhIyF33LVeuHMHBwQwZMoSzZ8/i6+vLTz/99EB9lNq3b0/Dhg154403OHHiBBUqVGDhwoXp7nfl7e1Nx44dbf3L/jst1qOPPsrChQvp1KkT7dq14/jx43z55ZdUqFCByMjIdJ0rad7WsWPH8uijj9K2bVt27NjB8uXLU1ScH330UUaPHk3fvn1p0KABu3fvZvbs2cl+SQdrYpo7d26+/PJLfHx88PLyom7duqn2t27fvj3Nmzdn+PDhnDhxgqpVq/L777/z888/M2jQoGSDvdyvc+fOsXr16hSDzCRxd3endevW/Pjjj0yaNInmzZvTs2dPJk2axOHDh3nkkUdITExk3bp1NG/enIEDB1KqVCmGDx/Ou+++S+PGjencuTPu7u5s3bqVQoUK2eYbf+6553jhhRfo0qULrVq1YufOnaxYsSLFa3s3jz76KN9//z1+fn5UqFCBTZs28ccff6SYOuZ///sfCxYsoGvXrjzzzDPUrFmTq1evsmTJEr788kuqVq1q2/app57i9ddfZ9GiRfTv3/+eUxuJiNyLrhvST9cNVvZ23XC7VatWcfPmzRTrO3bsyPPPP89XX31Fnz592LZtG8WLF2fBggVs2LCBCRMm2Cr9zz33HFevXqVFixYUKVKEkydPMnnyZKpVq2brv16hQgWaNWtGzZo1yZMnD//88w8LFixg4MCBGfp8JJNlwQjykg3daSqVihUrprr9hg0bjHr16hm5cuUyChUqZLz++uu2KZxWr15t2+5OU6mkNm0F/5na405TqQwYMCDFvv+dtsowDGPVqlVG9erVDTc3NyM4ONj45ptvjNdee83w8PC4w6vwr3379hktW7Y0vL29jXz58hn9+vWzTc1x+zQgvXv3Nry8vFLsn1rsV65cMXr27Gn4+voafn5+Rs+ePY0dO3akeSqVJEuXLjUAo2DBgqlO8TVmzBijWLFihru7u1G9enXj119/TfHvYBj3nkrFMAwjISHBGDVqlFGwYEEjV65cRrNmzYw9e/akeL1v3rxpvPbaa7btGjZsaGzatMlo2rRpium7fv75Z6NChQq2aW2SnntqMUZERBivvvqqUahQIcPV1dUoXbq08fHHHyeb2iXpuaT1fXG7cePGGYCxatWqO24zc+ZMAzB+/vlnwzCs09V8/PHHRrly5Qw3Nzcjf/78Rps2bYxt27Yl22/69OlG9erVDXd3d8Pf399o2rSpsXLlStvjCQkJxtChQ418+fIZnp6eRuvWrY0jR47ccQq2rVu3pojt2rVrRt++fY18+fIZ3t7eRuvWrY0DBw6k+ryvXLliDBw40ChcuLDh5uZmFClSxOjdu7dx+fLlFMdt27atARgbN2684+siIjmbrhuS03WDVXa/bjCMf9+Td7p9//33hmEYxoULF2zf0W5ubkblypVT/LstWLDAePjhh42AgADDzc3NKFq0qPF///d/RmhoqG2b9957z6hTp46RO3duI1euXEa5cuWM999/34iNjb1rnGJfLIZhRz9LitiZjh07ahoLkXvo1KkTu3fvTlNfTBGR7EzXDSKSEdQnXeSW6OjoZPcPHz7MsmXLaNasmTkBiTiA0NBQli5dSs+ePc0ORUQkS+m6QUQyiyrpIrcULFiQPn36ULJkSU6ePMmUKVOIiYlhx44dKebwFMnpjh8/zoYNG/jmm2/YunUrR48eJTAw0OywRESyjK4bRCSzaOA4kVseeeQR5s6dy/nz53F3d6d+/fqMGTNGX7Qiqfjrr7/o27cvRYsW5dtvv1WCLiI5jq4bRCSzqJIuIiIiIiIiYifUJ11ERERERETETihJFxEREREREbETOa5PemJiIufOncPHxweLxWJ2OCIiIhiGQUREBIUKFcLJSb+fZwR934uIiD1Jz3d9jkvSz507R1BQkNlhiIiIpHD69GmKFClidhjZgr7vRUTEHqXluz7HJek+Pj6A9cXx9fU1ORoREREIDw8nKCjI9h0lD07f9yIiYk/S812f45L0pCZvvr6++tIWERG7ombZGUff9yIiYo/S8l2vjm8iIiIiIiIidkJJuoiIiIiIiIidUJIuIiIiIiIiYidM7ZO+du1aPv74Y7Zt20ZoaCiLFi2iY8eOd91nzZo1DB48mL179xIUFMRbb71Fnz59siReEck8hmEQHx9PQkKC2aGIZDhnZ2dcXFzU59yO6DNHMov+v4vIgzI1Sb9x4wZVq1blmWeeoXPnzvfc/vjx47Rr144XXniB2bNns2rVKp577jkKFixI69atsyBiEckMsbGxhIaGEhUVZXYoIpnG09OTggUL4ubmZnYoOZ4+cySz6f+7iDwIU5P0Nm3a0KZNmzRv/+WXX1KiRAnGjRsHQPny5Vm/fj2ffvqpknQRB5WYmMjx48dxdnamUKFCuLm5qfog2YphGMTGxnLp0iWOHz9O6dKlcXJSbzOz6DNHMpP+v4tIRnCoKdg2bdpEy5Ytk61r3bo1gwYNuuM+MTExxMTE2O6Hh4dnVngich9iY2NJTEwkKCgIT09Ps8MRyRS5cuXC1dWVkydPEhsbi4eHh9kh5Vj6zJHMpv/vIvKgHOqnvfPnz1OgQIFk6woUKEB4eDjR0dGp7jN27Fj8/Pxst6CgoKwIVUTSSZUGye70Hrcv+veQzKT3l4g8iGz/CTJs2DDCwsJst9OnT5sdkoiIiIiIiEiqHKq5e2BgIBcuXEi27sKFC/j6+pIrV65U93F3d8fd3T0rwhMRERERERF5IA5VSa9fvz6rVq1Ktm7lypXUr1/fpIhERDJW8eLFmTBhQpq3X7NmDRaLhevXr2daTCKSfekzR0TE/piapEdGRhISEkJISAhgnWItJCSEU6dOAdam6r169bJt/8ILL3Ds2DFef/11Dhw4wBdffMEPP/zAq6++akb4IpKDWSyWu95Gjhx5X8fdunUrzz//fJq3b9CgAaGhofj5+d3X+e5HuXLlcHd35/z581l2TpGcLqd95ujHABHJyUxt7v7PP//QvHlz2/3BgwcD0Lt3b2bOnEloaKgtYQcoUaIES5cu5dVXX2XixIkUKVKEb775RtOviUiWCw0NtS3Pnz+fESNGcPDgQds6b29v27JhGCQkJODicu+P3Pz586crDjc3NwIDA9O1z4NYv3490dHRPP7443z77bcMHTo0y86dmri4OFxdXU2NQSQr5NTPHBGRnMjUSnqzZs0wDCPFbebMmQDMnDmTNWvWpNhnx44dxMTEcPToUfr06ZPlcWeUm3EJ7DsXzq+7zjHxj8O8PHcHj0/ZyKcrD3EzLsHs8ERMYxgGUbHxptwMw0hTjIGBgbabn58fFovFdv/AgQP4+PiwfPlyatasibu7O+vXr+fo0aN06NCBAgUK4O3tTe3atfnjjz+SHfe/TU8tFgvffPMNnTp1wtPTk9KlS7NkyRLb4/+tNs2cOZPcuXOzYsUKypcvj7e3N4888kiyC/z4+HhefvllcufOTd68eRk6dCi9e/emY8eO93ze06ZN46mnnqJnz55Mnz49xeNnzpyhe/fu5MmTBy8vL2rVqsXff/9te/yXX36hdu3aeHh4kC9fPjp16pTsuS5evDjZ8XLnzm37Tjhx4gQWi4X58+fTtGlTPDw8mD17NleuXKF79+4ULlwYT09PKleuzNy5c5MdJzExkY8++ohSpUrh7u5O0aJFef/99wFo0aIFAwcOTLb9pUuXcHNzS9HFSrInfeZMsN23t8+cO7l27Rq9evXC398fT09P2rRpw+HDh22Pnzx5kvbt2+Pv74+XlxcVK1Zk2bJltn179OhB/vz5yZUrF6VLl2bGjBn3HYs4iDPb4LuOcH6P2ZGI3JNDDRzniAzD4FJEDEcuRXLs0g2OXork6KUbHL0YybmwaFL7bv7n5DWW7DzHmE6VqR+cN+uDFjFZdFwCFUasMOXc+0a3xtMtYz4a33jjDT755BNKliyJv78/p0+fpm3btrz//vu4u7vz3Xff0b59ew4ePEjRokXveJxRo0bx0Ucf8fHHHzN58mR69OjByZMnyZMnT6rbR0VF8cknn/D999/j5OTE008/zZAhQ5g9ezYAH374IbNnz2bGjBmUL1+eiRMnsnjx4mQtm1ITERHBjz/+yN9//025cuUICwtj3bp1NG7cGLB2YWratCmFCxdmyZIlBAYGsn37dhITEwFYunQpnTp1Yvjw4Xz33XfExsbaLprT+7qOGzeO6tWr4+Hhwc2bN6lZsyZDhw7F19eXpUuX0rNnT4KDg6lTpw5g7T41depUPv30Uxo1akRoaCgHDhwA4LnnnmPgwIGMGzfONtDorFmzKFy4MC1atEh3fOJ49JmTnL185txNnz59OHz4MEuWLMHX15ehQ4fStm1b9u3bh6urKwMGDCA2Npa1a9fi5eXFvn37bK0N3n77bfbt28fy5cvJly8fR44cueNUvpKN7PgOjq2GnXMh8H2zoxG5KyXpGSQmPoGTV6I4ejGSY5etSfjRW4l5REz8Hffzy+VKcH4vSub3Jji/N97uzkz+8wjHL9+g+9TNPFkriGFty5Hb0y0Ln42IZITRo0fTqlUr2/08efJQtWpV2/13332XRYsWsWTJkhSV3Nv16dOH7t27AzBmzBgmTZrEli1beOSRR1LdPi4uji+//JLg4GAABg4cyOjRo22PT548mWHDhtmq2J999lmakuV58+ZRunRpKlasCEC3bt2YNm2aLUmfM2cOly5dYuvWrbaL+VKlStn2f//99+nWrRujRo2yrbv99UirQYMG0blz52TrhgwZYlt+6aWXWLFiBT/88AN16tQhIiKCiRMn8tlnn9G7d28AgoODadSoEQCdO3dm4MCB/PzzzzzxxBOAtTrYp08fLBZLuuMTMUt2+8y5k6TkfMOGDTRo0ACA2bNnExQUxOLFi+natSunTp2iS5cuVK5cGYCSJUva9j916hTVq1enVq1agLU1geQA4bdad0RoPBWxf0rSH8AP/5zmtz3nOXopktNXo0i8Q4s1JwsUzeN5KxH/NyEPzu9FHi+3FBeBHaoX5qPfDjBr8ynm/3OaVQcu8E77ijxapaAuGCVHyOXqzL7R5ow1kcvVOcOOlXQBmCQyMpKRI0eydOlSQkNDiY+PJzo6OtnYG6mpUqWKbdnLywtfX18uXrx4x+09PT1tF8sABQsWtG0fFhbGhQsXbBVmAGdnZ2rWrGmreN/J9OnTefrpp233n376aZo2bcrkyZPx8fEhJCSE6tWr37HaFhISQr9+/e56jrT47+uakJDAmDFj+OGHHzh79iyxsbHExMTg6ekJwP79+4mJieGhhx5K9XgeHh625vtPPPEE27dvZ8+ePcma+Er2ps+c5OzlM+dO9u/fj4uLC3Xr1rWty5s3L2XLlmX//v0AvPzyy/Tv35/ff/+dli1b0qVLF9vz6t+/P126dGH79u08/PDDdOzY0ZbsSzYWcStJj7xw9+1E7ICS9Adw5GIkfx7490vLx92FkgHeBOfzIjjg34S8WF5P3F3S/iXs6+HKex0r07FaYd5YuJsjFyN5ae4OFu04y7sdK1E4d+pzwotkFxaLJcOaf5rJy8sr2f0hQ4awcuVKPvnkE0qVKkWuXLl4/PHHiY2Nvetx/jswmsViuevFbWrbp7Xf653s27ePzZs3s2XLlmSDxSUkJDBv3jz69etHrlx3/2y61+OpxRkXF5diu/++rh9//DETJ05kwoQJVK5cGS8vLwYNGmR7Xe91XrA2ea9WrRpnzpxhxowZtGjRgmLFit1zP8k8Z8+eZejQoSxfvpyoqChKlSrFjBkzUiSiGUGfOcnZw2fOg3ruuedo3bo1S5cu5ffff2fs2LGMGzeOl156iTZt2nDy5EmWLVvGypUreeihhxgwYACffPKJqTFLJkuqoKuSLg7AoeZJtzePVArkvY6VmNuvHlvefIhdIx/m5wENGf9kNQY0L8UjlQpSpoBPuhL029UqnoelLzdiUMvSuDk78eeBi7Qa/xfT1x8n4U5lexGxWxs2bKBPnz506tSJypUrExgYyIkTJ7I0Bj8/PwoUKMDWrVtt6xISEti+fftd95s2bRpNmjRh586dtqkzQ0JCGDx4MNOmTQOs1beQkBCuXr2a6jGqVKly14HY8ufPn2ywqcOHDxMVFXXP57RhwwY6dOjA008/TdWqVSlZsiSHDh2yPV66dGly5cp113NXrlyZWrVqMXXqVObMmcMzzzxzz/NK5rl27RoNGzbE1dWV5cuXs2/fPsaNG4e/v7/ZoTkUR/7MuZvy5csTHx+fbFDKK1eucPDgQSpUqGBbFxQUxAsvvMDChQt57bXXmDp1qu2x/Pnz07t3b2bNmsWECRP4+uuv7zsecQAJcXDjknVZlXRxAI7/s7GJahT1p0bRzL1gcHdxZlDLMjxapSDDFu5m64lrjP51Hz+HnGVs5ypUKOSbqecXkYxTunRpFi5cSPv27bFYLLz99tv33dzzQbz00kuMHTuWUqVKUa5cOSZPnsy1a9fu2J0mLi6O77//ntGjR1OpUqVkjz333HOMHz+evXv30r17d8aMGUPHjh0ZO3YsBQsWZMeOHRQqVIj69evzzjvv8NBDDxEcHEy3bt2Ij49n2bJltsp8ixYt+Oyzz6hfvz4JCQkMHTo0TdOrlS5dmgULFrBx40b8/f0ZP348Fy5csF2se3h4MHToUF5//XXc3Nxo2LAhly5dYu/evTz77LPJnsvAgQPx8vJKNuq8ZL0PP/yQoKCgZCNulyhRwsSIHJOjfubcbvfu3fj4+NjuWywWqlatSocOHejXrx9fffUVPj4+vPHGGxQuXJgOHToA1rEr2rRpQ5kyZbh27RqrV6+mfPnyAIwYMYKaNWtSsWJFYmJi+PXXX22PSTYVeRG4VeCKCYfYKHDzNDUkkbtRJd1BlArwYf7z9Xm/UyV83F3YeSaM9p+t58PfDmi6NhEHMX78ePz9/WnQoAHt27endevW1KhRI8vjGDp0KN27d6dXr17Ur18fb29vWrdujYeHR6rbL1myhCtXrqSauJYvX57y5cszbdo03Nzc+P333wkICKBt27ZUrlyZDz74AGdna2uiZs2a8eOPP7JkyRKqVatGixYt2LJli+1Y48aNIygoiMaNG/PUU08xZMgQW7/yu3nrrbeoUaMGrVu3plmzZgQGBqaY2untt9/mtddeY8SIEZQvX54nn3wyRR/b7t274+LiQvfu3e/4WkjWWLJkCbVq1aJr164EBARQvXr1ZFXQ1MTExBAeHp7sltM56mfO7Zo0aUL16tVtt5o1awIwY8YMatasyaOPPkr9+vUxDINly5bZfthLSEhgwIABlC9fnkceeYQyZcrwxRdfANa53ocNG0aVKlVo0qQJzs7OzJs3L/NeADHff5u4R6rJu9g3i2F2p6EsFh4ejp+fH2FhYfj6OmYV+kL4TUYu2cvyPdYPmGJ5PRnTqTINS+UzOTKR9Lt58ybHjx+nRIkSSoxMkpiYSPny5XniiSd49913zQ7HNCdOnCA4OJitW7dmSiJzt/d6dvhuykhJr8/gwYPp2rUrW7du5ZVXXuHLL7+0jdD/XyNHjkw2c0CS/76m+swxX074zNH7zM7s/xXm9/j3ft/foFh98+KRHCk93/WqpDugAr4eTHm6Jl/3rEmgrwcnr0TR45u/ee2HnVy7cffBYERETp48ydSpUzl06BC7d++mf//+HD9+nKeeesrs0EwRFxfH+fPneeutt6hXr54plUZJLjExkRo1ajBmzBiqV6/O888/T79+/fjyyy/vuM+wYcMICwuz3U6fPp2FEcvd6DNHTBcRmvy+Kuli55SkO7CHKwaycnATetUvhsUCP20/Q8vxf/FzyFnTR1UVEfvl5OTEzJkzqV27Ng0bNmT37t388ccfObZP5oYNGyhYsCBbt269axIoWadgwYLJBgADa9eKu00d5u7ujq+vb7Kb2Ad95ojp/pukR2jwOLFvGjjOwfl4uDK6QyU6VCvMsIW7OHQhklfmhbBw+1ne61iJoDwaFENEkgsKCmLDhg1mh2E3mjVrph827UzDhg05ePBgsnWHDh3StHgOSp85Yjpbn3QLYKiSLnZPlfRsomYxf359qTGvtSqDm7MTfx26xMOfrmXq2mPEJ2T9SK4iIiL369VXX2Xz5s2MGTOGI0eOMGfOHL7++msGDBhgdmgi4oiSKul5S926r0q62Dcl6dmIm4sTLz1UmuWDGlO3RB6i4xJ4f9l+un29mYibcWaHJyIikia1a9dm0aJFzJ07l0qVKvHuu+8yYcIEevToce+dRUT+K6mSXqia9a8q6WLnlKRnQ8H5vZnbrx4fdqmMj4cL/5y8Rp8ZW7kRE292aCIiImny6KOPsnv3bm7evMn+/fvp16+f2SGJiKNKqqQXrHbrvirpYt+UpGdTTk4WnqxdlLn96uHr4cK2k9d49tutRMdqTnURERERySHibkL0NetyoerWv6qki51Tkp7NVSrsx/fP1sXH3YXNx67y/Pf/cDNOibqIiIiI5ABJCbmLB+QvZ12OugLxmrZY7JeS9BygalBuZj5TG083Z9Ydvkz/WduIiVeiLiIiIiLZXPitpu4+geCZB5xcrfdvXDQvJpF7UJKeQ9QslocZfWrj4erE6oOXGDhnB3Ea9V3EdM2aNWPQoEG2+8WLF2fChAl33cdisbB48eIHPndGHUdEHIc+cyTHSeqP7lMQLBbwLnBrvfqli/1Skp6D1C2Zl2961cbNxYmV+y4waF6IpmcTuU/t27fnkUceSfWxdevWYbFY2LVrV7qPu3XrVp5//vkHDS+ZkSNHUq1atRTrQ0NDadOmTYae606io6PJkycP+fLlIyYmJkvOKZKd6DMnbWbOnEnu3Lkz9RziYJJGdvcJvPX3VpKufulix5Sk5zCNSufjq6dr4upsYenuUIb8uJOERMPssEQczrPPPsvKlSs5c+ZMisdmzJhBrVq1qFKlSrqPmz9/fjw9PTMixHsKDAzE3d09S871008/UbFiRcqVK2d6Jc0wDOLjNduFOBZ95ojcp9sr6QDet5L1CCXpYr+UpOdAzcsF8PlTNXBxsrA45Bxv/LSLRCXqYk8MA2JvmHMz0vZ/4dFHHyV//vzMnDkz2frIyEh+/PFHnn32Wa5cuUL37t0pXLgwnp6eVK5cmblz5971uP9tenr48GGaNGmCh4cHFSpUYOXKlSn2GTp0KGXKlMHT05OSJUvy9ttvExcXB1irSqNGjWLnzp1YLBYsFost5v82Pd29ezctWrQgV65c5M2bl+eff57IyEjb43369KFjx4588sknFCxYkLx58zJgwADbue5m2rRpPP300zz99NNMmzYtxeN79+7l0UcfxdfXFx8fHxo3bszRo0dtj0+fPp2KFSvi7u5OwYIFGThwIAAnTpzAYrEQEhJi2/b69etYLBbWrFkDwJo1a7BYLCxfvpyaNWvi7u7O+vXrOXr0KB06dKBAgQJ4e3tTu3Zt/vjjj2RxxcTEMHToUIKCgnB3d6dUqVJMmzYNwzAoVaoUn3zySbLtQ0JCsFgsHDly5J6vidgRfebY7meXz5w7OXXqFB06dMDb2xtfX1+eeOIJLlz4t9nzzp07ad68OT4+Pvj6+lKzZk3++ecfAE6ePEn79u3x9/fHy8uLihUrsmzZsvuORbLIHSvpau4u9svF7ADEHA9XDGRit+q8NHc7P247g5uLE+91rITFYjE7NBGIi4Ixhcw595vnwM3rnpu5uLjQq1cvZs6cyfDhw23/d3788UcSEhLo3r07kZGR1KxZk6FDh+Lr68vSpUvp2bMnwcHB1KlT557nSExMpHPnzhQoUIC///6bsLCwZH1Jk/j4+DBz5kwKFSrE7t276devHz4+Prz++us8+eST7Nmzh99++82WgPr5+aU4xo0bN2jdujX169dn69atXLx4keeee46BAwcmSwpWr15NwYIFWb16NUeOHOHJJ5+kWrVqd53D+ujRo2zatImFCxdiGAavvvoqJ0+epFixYgCcPXuWJk2a0KxZM/788098fX3ZsGGDrdo9ZcoUBg8ezAcffECbNm0ICwtjw4YN93z9/uuNN97gk08+oWTJkvj7+3P69Gnatm3L+++/j7u7O9999x3t27fn4MGDFC1aFIBevXqxadMmJk2aRNWqVTl+/DiXL1/GYrHwzDPPMGPGDIYMGWI7x4wZM2jSpAmlSpVKd3xiIn3mANnnM+duzy8pQf/rr7+Ij49nwIABPPnkk7Yf9Xr06EH16tWZMmUKzs7OhISE4OpqHWhswIABxMbGsnbtWry8vNi3bx/e3t7pjkOymCrp4oCUpOdg7aoUJD6xGoPmhzD771O4OjvxTvsKStRF0uiZZ57h448/5q+//qJZs2aANUnr0qULfn5++Pn5JUvgXnrpJVasWMEPP/yQpgvmP/74gwMHDrBixQoKFbImEGPGjEnRp/Ott96yLRcvXpwhQ4Ywb948Xn/9dXLlyoW3tzcuLi4EBgbe8Vxz5szh5s2bfPfdd3h5WROGzz77jPbt2/Phhx9SoIC18uDv789nn32Gs7Mz5cqVo127dqxatequF8zTp0+nTZs2+Pv7A9C6dWtmzJjByJEjAfj888/x8/Nj3rx5tovhMmXK2PZ/7733eO2113jllVds62rXrn3P1++/Ro8eTatWrWz38+TJQ9WqVW333333XRYtWsSSJUsYOHAghw4d4ocffmDlypW0bNkSgJIlS9q279OnDyNGjGDLli3UqVOHuLg45syZk6K6LpJR9JmTts+cO1m1ahW7d+/m+PHjBAUFAfDdd99RsWJFtm7dSu3atTl16hT/+9//KFfOOlVX6dKlbfufOnWKLl26ULlyZSD554HYsf9W0r0DrH9VSRc7piQ9h+tQrTAx8Ym8vmAXMzeewN3FiTfalFOiLuZy9bRWl8w6dxqVK1eOBg0aMH36dJo1a8aRI0dYt24do0ePBiAhIYExY8bwww8/cPbsWWJjY4mJiUlz/8/9+/cTFBRku1gGqF+/fort5s+fz6RJkzh69CiRkZHEx8fj6+ub5ueRdK6qVavaLpYBGjZsSGJiIgcPHrRdMFesWBFnZ2fbNgULFmT37t13PG5CQgLffvstEydOtK17+umnGTJkCCNGjMDJyYmQkBAaN25sS9Bvd/HiRc6dO8dDDz2UrueTmlq1aiW7HxkZyciRI1m6dCmhoaHEx8cTHR3NqVOnAGvTdWdnZ5o2bZrq8QoVKkS7du2YPn06derU4ZdffiEmJoauXbs+cKySxfSZA2SPz5x7nTMoKMiWoANUqFCB3Llzs3//fmrXrs3gwYN57rnn+P7772nZsiVdu3YlODgYgJdffpn+/fvz+++/07JlS7p06XJf4wBIFrMl6bfe1z6qpIv9U5904YlaQbzfqRIAX609xviVh0yOSHI8i8Xa/NOMWzp/oHr22Wf56aefiIiIYMaMGQQHB9uSuo8//piJEycydOhQVq9eTUhICK1btyY2NjbDXqpNmzbRo0cP2rZty6+//sqOHTsYPnx4hp7jdv9NpC0WC4mJd54lYsWKFZw9e5Ynn3wSFxcXXFxc6NatGydPnmTVqlUA5MqV64773+0xACcn69eYcVu/3jv1V709GQAYMmQIixYtYsyYMaxbt46QkBAqV65se+3udW6A5557jnnz5hEdHc2MGTN48skns2wQLslA+sxJM3v/zHlQI0eOZO/evbRr144///yTChUqsGjRIsD6//3YsWP07NmT3bt3U6tWLSZPnpxpsUgGiImA2AjrclJfdG/1SRf7pyRdAOhRtxgj21cAYPKfR5i86rDJEYk4hieeeAInJyfmzJnDd999xzPPPGNribJhwwY6dOjA008/TdWqVSlZsiSHDqX9R7Dy5ctz+vRpQkNDbes2b96cbJuNGzdSrFgxhg8fTq1atShdujQnT55Mto2bmxsJCQn3PNfOnTu5ceOGbd2GDRtwcnKibNmyaY75v6ZNm0a3bt0ICQlJduvWrZttALkqVaqwbt26VJNrHx8fihcvbkvo/yt//vwAyV6j2weRu5sNGzbQp08fOnXqROXKlQkMDOTEiRO2xytXrkxiYiJ//fXXHY/Rtm1bvLy8mDJlCr/99hvPPPNMms4tcr/0mXP/kp7f6dOnbev27dvH9evXqVChgm1dmTJlePXVV/n999/p3LkzM2bMsD0WFBTECy+8wMKFC3nttdeYOnVqpsQqGSSpWu7mA+4+1uWkSnrkRUi8+/tUxCxK0sWmT8MSvNnW2gdr3MpDfPXX0XvsISLe3t48+eSTDBs2jNDQUPr06WN7rHTp0qxcuZKNGzeyf/9+/u///i/ZKML30rJlS8qUKUPv3r3ZuXMn69atY/jw4cm2KV26NKdOnWLevHkcPXqUSZMm2ao+SYoXL87x48cJCQnh8uXLqc5T3qNHDzw8POjduzd79uxh9erVvPTSS/Ts2dPW7DS9Ll26xC+//ELv3r2pVKlSsluvXr1YvHgxV69eZeDAgYSHh9OtWzf++ecfDh8+zPfff8/BgwcBa2Vr3LhxTJo0icOHD7N9+3Zb9SpXrlzUq1ePDz74gP379/PXX38l6y97N6VLl2bhwoWEhISwc+dOnnrqqWQVuuLFi9O7d2+eeeYZFi9ezPHjx1mzZg0//PCDbRtnZ2f69OnDsGHDKF26dKpNg0Uykj5z7i0hISHFD4P79++nZcuWVK5cmR49erB9+3a2bNlCr169aNq0KbVq1SI6OpqBAweyZs0aTp48yYYNG9i6dSvly5cHYNCgQaxYsYLjx4+zfft2Vq9ebXtM7JRt0LjbxkfwCgAsYCRA1BVTwhK5FyXpkszzTYIZ8rB1wKaxyw8wff1xkyMSsX/PPvss165do3Xr1sn6cr711lvUqFGD1q1b06xZMwIDA+nYsWOaj+vk5MSiRYuIjo6mTp06PPfcc7z//vvJtnnsscd49dVXGThwINWqVWPjxo28/fbbybbp0qULjzzyCM2bNyd//vypTsnk6enJihUruHr1KrVr1+bxxx/noYce4rPPPkvfi3GbpAGhUutP/tBDD5ErVy5mzZpF3rx5+fPPP4mMjKRp06bUrFmTqVOn2pq59u7dmwkTJvDFF19QsWJFHn30UQ4f/re1z/Tp04mPj6dmzZoMGjSI9957L03xjR8/Hn9/fxo0aED79u1p3bo1NWrUSLbNlClTePzxx3nxxRcpV64c/fr1S1b5A+u/f2xsLH379k3vSyRyX/SZc3eRkZFUr1492a19+/ZYLBZ+/vln/P39adKkCS1btqRkyZLMnz8fsP7oduXKFXr16kWZMmV44oknaNOmDaNGjQKsyf+AAQMoX748jzzyCGXKlOGLL7544HglE/130DgAZxfwypf8cRE7YzGMNE7QmU2Eh4fj5+dHWFhYugc5yUnG/36QSX9a5/l9r2Mlnq5XzOSIJLu6efMmx48fp0SJEnh4eJgdjki6rVu3joceeojTp0/ftQJ4t/e6vpsy3p1eU33mSFbQ+8xObJgIK0dA5Segy21dE6Y0ggu7occCKN3qzvuLZKD0fNerki6perVVGf6vqXVqkbcW7+GHrafvsYeISM4SExPDmTNnGDlyJF27dn3gJroiIpLBUqukw7+DyKmSLnZKSbqkymKx8MYj5ejbsDgAQxfuYtGOM+YGJSJiR+bOnUuxYsW4fv06H330kdnhiIjIf9n6pBdMvt47afA4Jelin5Skyx1ZLBZGPFqBp+sVxTDgtR928usuk+aRFRGxM3369CEhIYFt27ZRuHBhs8MREZH/SqqU+/4nSbdV0jUNm9gnJelyVxaLhdGPVeLJWkEkGvDKvBBW7NWvjiIiIiJi58JvFZdUSRcHoyRd7snJycKYzpXpXL0wCYkGA2ZvZ+raYyQm5qgxByWT5bAxLCUH0nvcvujfQzKT3l92wDDS0CddlXSxT0rSJU2cnSx89HgVOlUvTHyiwfvL9vPst1u5Eply7lOR9EiaZisqKsrkSEQyV9J7POk9L+bQZ45kBf1/twPR1yDh1nWq93+SdFXSxc65mB2AOA4XZyfGP1GVmsX8Gf3rPlYfvESbieuY0K0aDYLzmR2eOChnZ2dy587NxYsXAevcuRaLxeSoRDKOYRhERUVx8eJFcufOjbOzs9kh5Wj6zJHMpP/vdiSpip7LH1z/Mw3e7ZV0wwB9BoidUZIu6WKxWHi6XjFqFvNn4JztHL10gx7f/M1LLUrzcotSuDircYakX2Cg9RftpItmkewod+7ctve6mEufOZLZ9P/dDtxpZHf4t5KeEAM3r1sTeRE7oiRd7kv5gr788lIjRi7Zyw//nGHSqsNsPnqFid2rUdAvl9nhiYOxWCwULFiQgIAA4uLizA5HJMO5urqqomZH9JkjmUn/3+3Enfqjg7Wy7uEHN8Os1XQl6WJnlKTLffN0c+Gjx6vSsFQ+hi/aw5YTV2kzcR2fPF6VlhUKmB2eOCBnZ2dd2IhIltFnjkg2ZqukF0r9ce9Aa5IeeR4CymVdXCJpoLbJ8sA6VCvMry81onJhP65HxfHcd/8w6pe9xMQnmB2aiIiIiOREd6ukg0Z4F7umJF0yRPF8XvzUvwHPNioBwIwNJ+gyZSPHL98wOTIRERERyXFslfQ7JOka4V3smJJ0yTBuLk68/WgFpvWuhb+nK3vOhvPopHUs3nHW7NBEREREJCe528BxoEq62DUl6ZLhHipfgOWvNKFuiTzciE1g0PwQhvy4kxsx8WaHJiIiIiI5ga25+x2SdFXSxY4pSZdMEejnwZx+9RjUsjROFliw7QztP1vPvnPhZocmIiIiItlZYmIa+qTfWq9KutghJemSaZydLAxqWYY5/eoR6OvBsUs36PjFBr7bdALDMMwOT0RERESyo6jLYCQAFvAOSH0b71vN3VVJFzukJF0yXb2SeVn2SmMeKhdAbHwiI37eywuzthEWpblpRURERCSDJfVH98oPzq6pb6NKutgxJemSJfJ4ufFN71qMeLQCrs4WVuy9QNtJ69h28qrZoYmIiIhIdpLU1N33Dv3R4d9KemwExGo2IrEvStIly1gsFp5pVIKF/RtSLK8nZ69H88RXm/l89RESE9X8XUREREQywL1Gdgdw9wFXz1vbq8m72Bcl6ZLlKhfx49eXGtGhWiESEg0+XnGQ7lM3c+ZalNmhiYiIiIijC7/HHOkAFstt/dLV5F3si5J0MYWPhysTnqzGR49XwdPNmb+PX6XNhHUs2nFGg8qJiIiIyP1LSyUdbuuXrkq62Bcl6WIai8XCE7WCWP5KY2oUzU1ETDyvzt/JwDk7uB4Va3Z4IiIiIuKI7jX9WhJV0sVOKUkX0xXL68UP/1ef11qVwcXJwtLdobSesJZ1hy+ZHZqIiIiIOBpV0sXBKUkXu+Di7MRLD5Vm4YsNKJnfiwvhMfSctoWRS/ZyMy7B7PBERERExFGoki4OTkm62JUqRXKz9KXG9KpfDICZG0/QfvJ69pwNMzkyEREREbF7CXFw41ZrTFXSxUEpSRe7k8vNmdEdKjGzb23y+7hz+GIknb7YwOerj5CgqdpExE4kJhrciIk3OwwREbld5EXAACcX8Mx3921tlfSLmR6WSHooSRe71axsACsGNeGRioHEJVinauv29SZOX9VUbSJinviERH4OOUubiesY9ctes8MREZHbJfVH9w4Ep3ukOkmV9EhV0sW+KEkXu5bHy40pT9fgk65V8XZ3YeuJa7SZuI4f/zmtqdpEJEvFxicyb8spHhr/F6/MC+HghQhW7rtAVKyq6SIidiMiDXOkJ/G+tU3UFYjXzEJiP1zMDkDkXiwWC4/XLELdEnkY/EMIW09c438LdrFq/0XGdK5MHi83s0MUkWwsOjaBeVtP8fXaY4SG3QTA39OVZxqWoFeD4ni66atURMRupHXQOADPPODkColxcOMi+BXJ3NhE0khXFuIwgvJ4Mu/5+ny19iifrjzEb3vPs+3UNT56vArNywaYHZ6IZDMRN+P4fvNJpq8/zuVIa4UlwMed55uUpHudoni56ytURMTupHX6NQCLxdovPfwMRFxQki52Q1cY4lCcnSy82KwUTUrnZ9D8EI5cjKTvjK30rFeMN9uWJ5ebs9khioiDu3YjlhkbjjNz4wnCb1qbshfxz8ULTYN5vGYRPFz1OSMiYrfSU0kH8LmVpKtfutgRJenikCoV9uPXlxrx4W8HmLHhBN9vPsmGI5f59MlqVA3KbXZ4IuKALobfZOq6Y8z++xRRsQkABOf34sVmpXisWiFcnTWMi4iI3UtPJR3+7ZeuadjEjuiKQxyWh6sz77SvyPfP1qGArzvHLt+gy5SNTFp1mPiERLPDExEHcfpqFG8t3k2jj1Yzdd1xomITqFDQly961OD3V5vSpWYRJehZbOTIkVgslmS3cuXKmR2WiDiC+6mkA0ReyJx4RO6DKuni8BqXzs+KQU0YvngPS3eFMn7lIVbuu8DYzpWpVNjP7PBExE4dvRTJF6uP8nPIWeITrbNF1Czmz8DmpWhWNj8Wi8XkCHO2ihUr8scff9juu7jokkVE0iCpku5bKG3bq5IudkjfeJIt5PZ047Pu1WlVvgAjft7D7rNhdPh8A881KsGglmXUV11EbPaeC+OL1UdZtieUpJkcG5XKx4DmpahXMo+Sczvh4uJCYGAaK2EiIgBx0RB9zbqsSro4MCXpkm1YLBY6Vi9Mg1J5GfXLPpbuCuWrtcdYtieU9ztWpkmZ/GaHKCImMQyD7aeu8fnqo/x54KJtfcvyBRjQPJjqRf1NjE5Sc/jwYQoVKoSHhwf169dn7NixFC1a9I7bx8TEEBMTY7sfHh6eFWGKiD1Jqoa7eIBH7rTto0q62CEl6ZLtBPh48PlTNehc/QJvL97D6avR9Jq+hU7VC/NWu/Lk9XY3O0QRyWSJiQYHL0Sw5fhVthy/yt/Hr3I50prAOVmgXZVCvNgsmPIFfU2OVFJTt25dZs6cSdmyZQkNDWXUqFE0btyYPXv24OPjk+o+Y8eOZdSoUVkcqYjYldv7o6e1VZQq6WKHLIaR1NgvZwgPD8fPz4+wsDB8fXVxlt3diIln3O+HmLnxOIkG5PZ05a12FehSo7CatIpkI/EJiewLDefvY9aEfOuJq4RFxyXbxs3FiY7VCtG/WSlK5PMyKdLU6bvp7q5fv06xYsUYP348zz77bKrbpFZJDwoK0msqkpPsWQgL+kLR+vDMb2nbJzwUxpcDizO8fQmc1EVSMkd6vutVSZdszcvdhRHtK9ChWiHeWLib/aHhDPlxJwu3n2FMp8oUt7MLdRFJm5j4BHafCePvW1XybSeucuPWtGlJPN2cqVnMn7ol8lCnRF6qFPHTHOcOKnfu3JQpU4YjR47ccRt3d3fc3dVSSiRHS+/I7gBe+QELGAkQdQW8AzIlNJH0UJIuOULVoNwsGdiQaeuP8+nKQ2w8eoXWE9bySsvS9GtcUtMridi56NgEdpy6xubjV9ly/Ao7Tl0nJj75VIu+Hi7UKZHn1i0vFQv56v92NhEZGcnRo0fp2bOn2aGIiD1L7xzpAM4u1kT9xkVrkq8kXeyA6Un6559/zscff8z58+epWrUqkydPpk6dOnfcfsKECUyZMoVTp06RL18+Hn/8ccaOHYuHh0cWRi2OyNXZiReaBtOmUiDDF+1h/ZHLfPTbQZaEnGNs58oaOEoknWLjEzl3PZqz16M5cy2KsOg4nCwWnJ2sN9uyxYKTkwVnJ3CyWHBxcrItOzvdeszyn32cICw6jq0nrvH3sSvsPhtGXELy3ll5vdyoWzIPdYpbk/KygT44O6kbS3YwZMgQ2rdvT7FixTh37hzvvPMOzs7OdO/e3ezQRMSe2Srp6UjSwdov/cZF9UsXu2Fqkj5//nwGDx7Ml19+Sd26dZkwYQKtW7fm4MGDBASk/BVrzpw5vPHGG0yfPp0GDRpw6NAh+vTpg8ViYfz48SY8A3FExfJ68f2zdVi04yzv/rqPA+cj6DxlI73rF2dI67J4u5v+25WIXYiJT+Dc9ZucuRbF2WvRnLlmTcbP3Fq+EHGTrBzVpKCfh63pep0SeQjO76WxJbKpM2fO0L17d65cuUL+/Plp1KgRmzdvJn9+zdIhIndxP5V0uDXC+26N8C52w9RsZPz48fTr14++ffsC8OWXX7J06VKmT5/OG2+8kWL7jRs30rBhQ5566ikAihcvTvfu3fn777+zNG5xfBaLhc41itCsbADvLd3Hwu1nmbnxBCv2nufdDpVoWaGA2SGKZLqbcQmcux5tS7rPXIu6VRW3Ll8Ij7nnMdxdnCjin4si/p74e7qSaECCYZCYaJCQaJBoWP8mGNjW2R6/7W9CIinWuTk7Ub1obuqUyEvdEnko4p9LSXkOMW/ePLNDEBFHZEvS09EnHW4b4V1JutgH05L02NhYtm3bxrBhw2zrnJycaNmyJZs2bUp1nwYNGjBr1iy2bNlCnTp1OHbsGMuWLbtrHzXNmyp3k8fLjfFPVKNz9SK8uWg3p65G8dx3/9CuckHeaV+BAF91oxDHFRUb/28F/FaT9LPXom2J+KWIeyfhuVydbyXh1kS88G3LRfxzkdfLTYmziIjYh/tt7u59K0mPUHN3sQ+mJemXL18mISGBAgWSVywLFCjAgQMHUt3nqaee4vLlyzRq1AjDMIiPj+eFF17gzTffvON5NG+qpEWj0vlYMagJE1cdZuq6YyzdHcraw5cY1qY83WoH4aR+rmKHwqLjbiXh1gp4UkKe1Ef8WlTcPY/h6eZMULLk+98EvHDuXORREi4iIo4gJgJiI63LPulsEel9q/KuSrrYCYfqfLtmzRrGjBnDF198Qd26dTly5AivvPIK7777Lm+//Xaq+wwbNozBgwfb7ifNmyryX7ncnHmjTTkeq1qIYQt3sfNMGG8u2s2iHWcY27kypQJ8zA5Rcqi4hEQWbj/D/tAIW5/ws9ejibgZf899fTxcrBXw3Lcn4bkonNuamPt7uioJFxERx5dURXfzAfd0XrP5qJIu9sW0JD1fvnw4Oztz4ULy/wwXLlwgMDD1fiRvv/02PXv25LnnngOgcuXK3Lhxg+eff57hw4fj5JRyqh3NmyrpVaGQLwtfbMi3G0/wye8H2XriGm0nruelFqX4v6bBuLloSifJOoZhMGzhbhZsO5Pq43m83GwJuO1vUiXcPxe+Hq5ZHLGIiIgJ7rc/OqiSLnbHtCTdzc2NmjVrsmrVKjp27AhAYmIiq1atYuDAganuExUVlSIRd3Z2BqwXsiIZxdnJwjONStC6UiBvLdrN6oOXGLfyEEt3h/JhlypUDcptdoiSQ0zfcIIF287gZIE+DUpQIr8XRWzJeC483RyqQZSIiEjmsPVHv48k/fZKumGAWpiJyUy9uhs8eDC9e/emVq1a1KlThwkTJnDjxg3baO+9evWicOHCjB07FoD27dszfvx4qlevbmvu/vbbb9O+fXtbsi6SkQrnzsX0PrVZsvMco36xTtfW6YsNPNuoBINblSWXm953knnWHb7E+0v3AfBm2/I817ikyRGJiIjYqaRKum+h9O+bVElPiIGb1yGXf4aFJXI/TE3Sn3zySS5dusSIESM4f/481apV47fffrMNJnfq1KlklfO33noLi8XCW2+9xdmzZ8mfPz/t27fn/fffN+spSA5gsVjoUK0wjUrlY/Sv+/g55BxT1x1nxd4LfNC5Mg1K5TM7RMmGTly+wcA5O0g0oHONwjzbqITZIYmIiNivB6mku3qAhx/cDLNW05Wki8ksRg5rJx4eHo6fnx9hYWH4+vqaHY44oD8PXOCtRXs4F3YTgCdrBfFmu/L45VLfX8kYETfj6PTFRo5cjKRaUG7mPV8PD1e12sjO9N2U8fSaiuQwP/SGfYvhkQ+gXv/07/9ZHbh8EHr9DCWbZXR0Iun6XtIIWCLp1KJcAX4f3JRe9YsBMP+f07Qa/xe/7dFgI/LgEhMNXp0fwpGLkQT4uPNVz5pK0EVERO7lQSrpoBHexa4oSRe5D97uLozuUIkfX6hPyfxeXIyI4YVZ23hx9jYuRtw0OzxxYONXHuKP/Rdxc3Hi6161KODrYXZIIiIi9s82unvB+9tfI7yLHVGSLvIAahfPw7KXGzOgeTDOThaW7T5Pq/Fr+eGf05pxQNLt113n+Gz1EQA+6FyZappFwP4lJpgdgYiIGIYq6ZKtaO4ekQfk4erM/1qXo23lggz9aRd7zobz+oJdLAk5x5hOlSma19PsEMUB7DkbxpAfdwLQr3EJOtcoYnJEYmMYcOMSXDoIlw/B5cP//s1THHr/YnaEIiI5W/Q168js8G9FPL1USRc7oiRdJINULOTH4hcbMm39ccavPMT6I5dpPWEtrz1chr4NS+DspDk3JXWXI2N4/rt/uBmXSJMy+XmjTXmzQ8qZEuLh2gnrwEHJkvFD1hF/U90nNktDFBGRVCRV0XP5W0dqvx9JFXhV0sUOKEkXyUAuzk78X9NgHq4YyBs/7eLv41d5b+l+ft0VyoddqlA20MfsEMXOxMYn0n/WNs6F3aREPi8md6uuH3Qy281wuHIYLh36Nwm/fBiuHoPEuDvsZAH/YpCvLOQrDfnK3LqVztLQRUQkFbb+6PcxR3oS71vN3VVJFzugJF0kE5TI58XcfvWYt/U0Y5ftJ+T0dR6dvI4Xm5XixebBuLtotG4BwzB4Z8letp64ho+7C1N71cLPU1P5Zajoa3B6K5zeDGf+sSbkSRdzqXH1hLylIH/Zf5PwfGUgT/D9V2dERCRzPWh/9Nv3VSVd7ICSdJFM4uRk4am6RWlRLoC3Fu/hj/0XmLjqMMt2h/JBlyrULOZvdohisll/n2LullNYLDCpe3VKBXibHZJjMwxrNfz033Bqs/XvpQOpb+sdmLIinq8M+BYGJ42pKiLiUCLOWf/e78ju8G8lPTYCYm+Am9eDxyVyn5Ski2SyQD8PpvaqydLdoYxcspfDFyPpMmUjj9cswuuPlCXAR9W5nGjzsSuMWrIXgNdbl6N5uQCTI3JA8TFwLsSajCfdblxKuV2eYChaD4LqQIFK1kp5rtxZHa2IiGSWjKiku/tYW1PFRVmPlzc4Y2ITuQ9K0kWygMVi4dEqhWgYnI/3lu7np+1nWLDtDL/tOc9LLUrRp2FxNYHPQU5fjeLF2duJTzR4rGohXmha0uyQHMONy7dVybfAuR3/juabxNkNCtWwJuRF60FQXfDKZ068IiKSNTIiSbdYrNX0a8ch8oKSdDGVknSRLOTv5ca4J6rSo15RRi3Zy84zYYxdfoC5W07x9qMVaFEuAItFg4ZlZzdi4un33T9cvRFLpcK+fNiliv7N7+TSITi16d8q+ZUjKbfxzPdvlTyoHhSqBi7uWR6qiIiYyDZw3AM0dwdrkn/t+L9Jv4hJlKSLmKBGUX8WvdiQn7af4cPfDnLiShTPfvsPTcvk5+1HK6hvcjaVmGgw5MedHDgfQT5vd77uWYtcbmpBkao/34e1H6Vcn7+ctToeVNeanOcpaa1+iIhIzmWrpD9gkm4b4V2Dx4m5lKSLmMTJyULXWkE8UimQz1YfYfr64/x16BIbJqyld4PivNKyNL4eGuk7O5n85xGW7zmPq7OFL5+uQaHcucwOyT6FnYH1n1qXizW8VSmvB0VqgWcec2MTERH7kpiYMc3db99flXQxmZJ0EZP5eLgyrE15utUuynu/7mPVgYtMW3+cxTvO8r/WZelaK0jzZmcDv+05z6d/HALgvY6VqFVcyeYdbZxsna+8eGPo86vZ0YiIiD2LugxGAmD5txJ+v1RJFzuheWZE7ESJfF5M61ObmX1rE5zfiys3Ynlj4W46fL6erSeumh2ePIAD58MZ/EMIAH0aFOfJ2kXNDcieRV6Cbd9alxu/Zm4sIiJi/5L6o3sHgPMD1h9VSRc7oSRdxM40KxvAb4Oa8Fa78vi4u7DnbDhdv9zEy3N3EBoWbXZ4kk5Xb8TS77t/iIpNoEFwXoa3K292SPZt8xcQH20dob1kM7OjERERexeeNGjcAzZ1B1XSxW4oSRexQ67OTjzXuCSr/9eM7nWCsFhgyc5ztPjkLyavOszNuASzQ5Q0iEtIZMDs7Zy+Gk3RPJ58/lQNXJ31sXtH0ddh6zfW5SZDNCCciIjcW0aN7A6qpIvd0NWiiB3L5+3O2M5V+GVgI2oX9yc6LoFxKw/RcvxfLN8dimEYZocod/H+0v1sOnYFLzdnpvaqhb+Xm9kh2bctUyEmHAIqQJk2ZkcjIiKOIKMGjQPwvnWM6KsQH/vgxxO5T0rSRRxApcJ+/PB/9ZnUvToF/Tw4cy2a/rO389TUvzlwPtzs8CQV87eeYubGEwB8+mQ1ygb6mBuQvYuJtDZ1B2tfdCd9PYmISBpkZCXdMw843ZpZR03exUS6ChJxEBaLhceqFmLVa015uUUp3F2c2HTsCm0nruPtxXu4dkO/+NqLbSev8dbiPQAMblWGhytmwK/72d32b62VizwloWIns6MRERFHkZGVdItF/dLFLihJF3Ewnm4uDH64LH8MbkrbyoEkGvD95pM0H7eG7zedID4h0ewQczTDMBi5ZC9xCQZtKwfyUotSZodk/+JjrNOuATQcBE7OpoYjIiIOxFZJL5Qxx/O5laSrX7qYSEm6iIMKyuPJFz1qMqdfXcoF+nA9Ko63f97Lo5PXs+noFbPDy7FWH7zI7rNh5HJ15t0OlbBo8LN7C5ltvcjyLQxVu5sdjYiIOJKMrKTDv/3SI5Wki3mUpIs4uAbB+fj1pUaM7lARv1yuHDgfQfepm3lx9jbOXIsyO7wcxTAMJv5xGIBe9YuR19vd5IgcQEI8rJ9gXW7wMrhocD0REUmjhDi4ccm6nBF90uG2Srqau4t5lKSLZAMuzk70ql+cNUOa0bNeMZwssGz3eR4a9xefrjxEdKymbMsKaw5dYucZaxW9X5OSZofjGPYsgOsnwTMf1OhldjQiIuJIIi8ABji5gGfejDmmKuliB5Ski2Qj/l5uvNuxEktfbky9knmIiU9k4qrDtBz/F0t3acq2zGQYBhNuVdGfrleUfKqi31tiIqwbb12uPwDcPM2NR0REHEtSU3fvwIybFUSVdLEDStJFsqHyBX2Z268eX/SoQeHcuTh7PZoBc7bT7evN7A/VlG2Z4a9Dl9h5+joerk483yTY7HAcw4Ff4fJBcPeD2s+ZHY2IiDga26BxGTiLiirpYgeUpItkUxaLhbaVC/LH4KYMalkadxcn/j5+lXaT1vHW4t2asi0DGYbBxFW3quh1i5HfR1X0ezIMWPeJdbnu8+Dha248IiLieDJ60DhQJV3sgpJ0kWwul5szg1qWYdVrTWlXuSCJBszafIpmn6zhO03ZliHWHb7MjlPXcXdx4vmm6oueJkdWQehOcPWEuv3NjkZERByRrZKeQYPGwb+V9BsXIVFj+og5lKSL5BBF/D35vEcN5varR7lAH8Ki4xjx817aTVrPxqOXzQ7PYd1eRe9RtxgBPh4mR+QgkqrotZ4Brwwa7EdERHKWpEq6bwYm6V75AQsYiXBD10diDiXpIjlM/eC8/PpSI97tWIncnq4cvBDBU1P/pv+sbZy+qinb0mvDkStsO3kNdxcnXlAVPW1OboRTm8DZDeoPNDsaERFxVJlRSXd2uZWoo37pYhol6SI5kIuzEz3rFWPNkGb0qm+dsm35nvO0HP8X4zVlW5pZR3Q/BED3OkUJ8FUVPU3W3qqiV386Y6sfIiKSs2RGn3RQv3QxnZJ0kRwst6cbozskn7Jt0qrDPDRuDT/8c5o49Ve/q41Hr/DPyWu4uTjRv5lGdE+Ts9vh6CqwOEPDV8yORkREHFn4OevfjKykw20jvCtJF3MoSReRFFO2nQu7yesLdvHQuL/4YauS9dQYhsHEW/Oid68dRAFV0dNm3Tjr38pdwb+4qaGIiIgDi4uGm9ety5lVSVdzdzGJknQRAf6dsm3Va015s2058nm7cepqFK//tIsW49Ywb8spJeu32XTsCltOXMXN2Yn+zUqZHY5juLjfOjc6Fmg82OxoRETEkSU1dXfxAI/cGXvspEq6mruLSZSki0gyHq7OPN8kmLWvN2d42/Lk83bj9NVo3li4m2Yfr2HullPExitZT6qid6sTRKCfquhpsv5T69/y7SF/WXNjERERx3Z7f3SLJWOPnVSZVyVdTKIkXURS5enmQr8mJVn3egvealeefN7unL0ezbCFu2n+yRpm/30yxybrm49d4e/jSVV09UVPk6vHYfcC63KTIebGIiIiji8zRnZP4q2B48RcStJF5K5yuTnzXOOSrHu9OW8/WoH8PtZkffiiPTT7eDWzNp8kJj5njQafVEV/onYRCvrlMjkaB7FhAhgJUKoVFKxqdjQiIuLobJX0TEjSVUkXkylJF5E0yeXmzLONSrDu9eaMeLQCAT7unAu7yVuL99Ds4zV8v+lEjkjW/z52hU3HruDqbFFf9LQKPwchc6zLjV8zNxYREckesqqSbhgZf3yRe1CSLiLp4uHqzDONSrD29eaMbF+BAr7uhIbd5O2f99Ls4zV8t+kEN+Oyb7I+cZW1it61VhCFc6uKniYbJ0NCLBRrCMXqmx2NiIhkB5k1Rzr8m6QnxPw7grxIFlKSLiL3xcPVmT4NS/DX/5oz6rGKBPp6EBp2kxG3kvVvN2a/ZH3riatsPGqtor+ovuhpc+MybJtpXVYVXe7TBx98gMViYdCgQWaHIiL2IjMr6a63jRivfuliAiXpIvJAPFyd6d2gOGv+14x3O1SkoJ8H58Nv8s6SvTT9eDUzNhzPNsl6Ul/0x2sWoYi/p8nROIjNUyAuCgpVh+AWZkcjDmjr1q189dVXVKlSxexQRMSe2JL0TKik335c9UsXEyhJF5EM4eHqTM/6t5L1jpUo5OfBhfAYRv2yjyYfrea7TSccep71bSevsv7IZVycLLyovuhpczMMtky1LjcekvFT5Ei2FxkZSY8ePZg6dSr+/v5mhyMi9iQzB44DjfAuplKSLiIZyt3FmZ71irH6f814v1MlCufOxcWIGEb8vJeHP13L8t2hGA44CMuE26roQXlURU+TLVMhJgzyl4eybc2ORhzQgAEDaNeuHS1btrzntjExMYSHhye7iUg2FRMBsZHWZZ8CmXOOpCRdlXQxgZJ0EckU7i7O9KhbjNVDrM3g83m7cfzyDfrP3s7jX25i28mrZoeYZttOXmPdYWsVfUBzVdHTJPYGbP7Cutx4MDjp60bSZ968eWzfvp2xY8emafuxY8fi5+dnuwUFBWVyhCJimqQqupsPuPtkzjl8VEkX8+iqSUQylZuL061m8M15uUUpcrk6s+3kNbpM2cQL32/j+OUbZod4T0kjuneuUVhV9LTa/h1EXQH/4lCxs9nRiIM5ffo0r7zyCrNnz8bDwyNN+wwbNoywsDDb7fTp05kcpYiYJqk/um8mNXUH8FafdDGPknQRyRLe7i4Mfrgsa/7XjG61g3CywG97z9Nq/F+88/MerkTGmB1iqnacusbaQ5dwdrIwsHlps8NxDPExsGGSdbnRq+DsYm484nC2bdvGxYsXqVGjBi4uLri4uPDXX38xadIkXFxcSEhIORilu7s7vr6+yW4ikk1l5vRrSZKOrUq6mEBJuohkqQK+HnzQpQrLX2lCi3IBxCcafLvpJE0/XsPnq48QHWtfI8EnVdE7VS9M0byqoqfJzrkQcQ58CkHV7mZHIw7ooYceYvfu3YSEhNhutWrVokePHoSEhODs7Gx2iCJipsycfi2J+qSLiVTeEBFTlA30YXqf2mw8epkxy/az52w4H684yHebTvBaq7J0qVkEZydzRwMPOX2dNQeTqujqi54mCfGw/lPrcsOXwcXd3HjEIfn4+FCpUqVk67y8vMibN2+K9SKSA4Vn8vRrtx9blXQxgSrpImKqBsH5WDKgERO7VaNw7lxcCI/h9Z920W7SOtYcvGjqSPCTblXRO1QrRPF8XqbF4VD2LoRrJ8AzL9ToZXY0IiKSHWVlJT02wjoYqkgWUiVdREzn5GShQ7XCtK4YyPebTjL5z8McOB9BnxlbaVgqL8PalKdSYb8sjWnn6ev8eeAiThZ4qYX6oqdJYiKsG29drvciuOmHDck4a9asMTsEEbEXWdEn3d0HXD0hLsp6vrzBmXcukf9QJV1E7IaHqzP9mpRk7evN6de4BG7OTmw4coX2n61n8PwQzl6PzrJYkqroHasVpoSq6GlzcBlc2g/uflCnn9nRiIhIdpUVlXSL5bZ+6WryLllLSbqI2J3cnm4Mb1eBVa81pUO1QhgGLNxxluafrGHs8v2ERcdl6vl3nwlj1a0q+sAW6oueJoYB6z6xLtfpBx5Z2/JBRERyCMO4rZKeiUk63NYvXYPHSdZSki4idisojycTu1VnycCG1CuZh9j4RL766xhNP17NF2uOcDHiZqacN2lE98eqFqJkfu9MOUe2c/RPOLfD2jSw3otmRyMiItlV9DVIuDVta2Y2dwdV0sU0StJFxO5VKZKbuf3qMb1PLUoHeHM9Ko6PfjtI/bF/8uzMrfy2J5TY+MQMOdees2H8sf8CFgsMVF/0tFs3zvq3Zl/wymtuLCIikn0lVbVz5cn8GURUSReTaOA4EXEIFouFFuUK0KR0fhbtOMucLafYceo6qw5cZNWBi/h7utKhWmG61ipCxUL339Q6qS96+yqFKBWgKnqanNgAJzeAsxs0GGh2NCIikp1lRX/0JKqki0mUpIuIQ3FxdqJrrSC61griyMVIFmw7w8LtZ7gYEcPMjSeYufEE5Qv60rVmETpUK0Re77T/yr73XBi/77NW0V9+SH3R02ztR9a/1XuCbyFzYxERkewtIgvmSE+iSrqYRM3dRcRhlQrw5o025dj4Rgtm9K1Nu8oFcXN2Yn9oOKN/3Ue9sav4v+//4Y99F4hLuHdz+KQqervKBSkV4JPZ4WcPp/6GY2vAyRUavWp2NCIikt2pki45gCrpIuLwXJydaF42gOZlA7geFcuSnedYsO0Mu86EsWLvBVbsvUA+b3c6VS/E4zWDKBuYMgHfHxrOir1JVXT1RU+zpCp6te6QO8jcWEREJPvLijnSk6iSLiZRki4i2UpuTzd61S9Or/rFOXA+nAX/nGFxyFkuR8Ywdd1xpq47TpUifjxeswiPVS1Ebk834N8qetvKBSlTQFX0NDm7DY78ARZnaDTY7GhERCQnyMok3fvWOaKvQnwsuLhl/jlFUJIuItlYuUBf3nq0AkPblGPNwUv8+M9p/jxwkV1nwth1Joz3ft1PqwoFaFgqH8v3WL/0X9aI7mn318fWv1W7QZ4S5sYiIiI5Q1Jz96wYA8Uzj7U7V2Kctcm7WoxJFlGSLiLZnquzE60qFKBVhQJciYxhccg5fvznNAfOR7B0dyhLd1u/8NtWDky1KbykInQnHFoOFido/JrZ0YiISE6RlZV0i8XaLz38jJJ0yVJK0kUkR8nr7c6zjUrwbKMS7DkbxoJt1ubwcfGJDGpZxuzwHMfaW1X0So9D3mBzYxERkZwhMfG2JD0LBo4D8LmVpKtfumQhJekikmNVKuxHpcJ+DG9XnriERDzd9JGYJhf2wv5fAAs0GWJ2NCIiklNEXQYjAbCAV0DWnDOpX3qkknTJOroiFZEcz9XZCVdnzUiZZklV9IodIX9ZU0MREZEcJPyc9a93ADhnURrjc2satghNwyZZR1elIiKSdpcOwt7F1uUm/zM1FBERyWGysj96ElXSxQRK0kVEJO3WfgIYUO5RKFDR7GhERCQnSRrZPav6o4Mq6WIKJekiIpI2V47CngXW5aavmxuLiIjkPKqkSw6R7iS9ePHijB49mlOnTmVGPCIiYq/WjQMjEcq0gYJVzY5GRERyGlslPQvmSE+iSrqYIN1J+qBBg1i4cCElS5akVatWzJs3j5iYmPsO4PPPP6d48eJ4eHhQt25dtmzZctftr1+/zoABAyhYsCDu7u6UKVOGZcuW3ff5RUQkDa4eh53zrMtN1RddRERMYGYl/cZFSEzIuvNKjnZfSXpISAhbtmyhfPnyvPTSSxQsWJCBAweyffv2dB1r/vz5DB48mHfeeYft27dTtWpVWrduzcWLF1PdPjY2llatWnHixAkWLFjAwYMHmTp1KoULF07v0xARkfRYP9467U2pllC4ptnRiIhITmRGn3Sv/IDF2pLsxuWsO6/kaPfdJ71GjRpMmjSJc+fO8c477/DNN99Qu3ZtqlWrxvTp0zEM457HGD9+PP369aNv375UqFCBL7/8Ek9PT6ZPn57q9tOnT+fq1assXryYhg0bUrx4cZo2bUrVqmp2KSKSaa6fgpC51uUm6osuIiImsSXpWVhJd3a5laijfumSZe47SY+Li+OHH37gscce47XXXqNWrVp88803dOnShTfffJMePXrcdf/Y2Fi2bdtGy5Yt/w3GyYmWLVuyadOmVPdZsmQJ9evXZ8CAARQoUIBKlSoxZswYEhLu3PQkJiaG8PDwZDcREUmH9RMgMQ5KNIWidc2ORkREcqKEOLhxybqclZV0UL90yXIu6d1h+/btzJgxg7lz5+Lk5ESvXr349NNPKVeunG2bTp06Ubt27bse5/LlyyQkJFCgQIFk6wsUKMCBAwdS3efYsWP8+eef9OjRg2XLlnHkyBFefPFF4uLieOedd1LdZ+zYsYwaNSqdz1JERAAIPwc7vrcuNx1qbiwiIpJzRd5KkJ1cwDNv1p7bOxDYrUq6ZJl0J+m1a9emVatWTJkyhY4dO+Lq6ppimxIlStCtW7cMCfB2iYmJBAQE8PXXX+Ps7EzNmjU5e/YsH3/88R2T9GHDhjF48GDb/fDwcIKCgjI8NhGRbGnDREiIhWINoXhDs6MREZGcKmnQOO9AcMriWaRVSZcslu4k/dixYxQrVuyu23h5eTFjxoy7bpMvXz6cnZ25cCH5m/3ChQsEBqbez6RgwYK4urri7OxsW1e+fHnOnz9PbGwsbm5uKfZxd3fH3d39rrGIiEgqIs7DtpnWZc2LLiIiZjKjP3oSzZUuWSzdP0NdvHiRv//+O8X6v//+m3/++SfNx3Fzc6NmzZqsWrXKti4xMZFVq1ZRv379VPdp2LAhR44cITEx0bbu0KFDFCxYMNUEXUREHsDGyRB/E4LqWvuji4iImCWpku6bxf3R4d8fBiKUpEvWSHeSPmDAAE6fPp1i/dmzZxkwYEC6jjV48GCmTp3Kt99+y/79++nfvz83btygb9++APTq1Ythw4bZtu/fvz9Xr17llVde4dChQyxdupQxY8ak+7wiInIPkZfgn1szbTR5HSwWc+MREZGczYzp15J432ruHqnm7pI10t3cfd++fdSoUSPF+urVq7Nv3750HevJJ5/k0qVLjBgxgvPnz1OtWjV+++0322Byp06dwum2PidBQUGsWLGCV199lSpVqlC4cGFeeeUVhg7VYEYiIhlq02cQFwWFakCph8yORkREcrqkKrYZzd1tlXQl6ZI10p2ku7u7c+HCBUqWLJlsfWhoKC4u6T4cAwcOZODAgak+tmbNmhTr6tevz+bNm9N9HhERSaOoq7BlqnW56VBV0UVExHzh56x/Ta2knwfD0PeiZLp0N3d/+OGHGTZsGGFhYbZ1169f580336RVq1YZGpyIiJhg8xcQdwMCq0CZ1mZHIyIiYm4lPSlJT4iF6GtZf37JcdJd+v7kk09o0qQJxYoVo3r16gCEhIRQoEABvv/++wwPUEREslD0Nfj7K+tyU/VFFxERO2Fmn3RXD/DIDTevW/ule+bJ+hgkR0l3kl64cGF27drF7Nmz2blzJ7ly5aJv375079491TnTRUTEgfz9FcSEQ0AFKNvO7GhEREQgLtqaIIM5lfSk8968bq3oB5Q3JwbJMdLfiRzrPOjPP/98RsciIiJmuhlubeoO0OR/4JTuHlEiIiIZL6mpu8utirYZvAvApQMa4V2yxH0l6WAd5f3UqVPExsYmW//YY489cFAiImKCLV/DzTDIVxYqdDA7GhEREStbf/SC5nXD0lzpkoXSnaQfO3aMTp06sXv3biwWC4ZhAGC59R8mISEhYyMUEZHMFxMJmz63LjcZAk7O5sYjDuv06dNYLBaKFCkCwJYtW5gzZw4VKlRQKzwRuT9m9kdPornSJQuluy3jK6+8QokSJbh48SKenp7s3buXtWvXUqtWrVSnTBMREQfwzzSIvgp5gqFiZ7OjEQf21FNPsXr1agDOnz9Pq1at2LJlC8OHD2f06NEmRyciDsnMkd2TqJIuWSjdSfqmTZsYPXo0+fLlw8nJCScnJxo1asTYsWN5+eWXMyNGERHJTLFRsGGSdbnJEHC+755QIuzZs4c6deoA8MMPP1CpUiU2btzI7NmzmTlzprnBiYhjijBxjvQkqqRLFkp3kp6QkICPjw8A+fLl49w563+aYsWKcfDgwYyNTkREMt+2GRB1GXIXg8pdzY5GHFxcXBzu7u4A/PHHH7axasqVK0doaKiZoYmIo7KnSrqSdMkC6U7SK1WqxM6dOwGoW7cuH330ERs2bGD06NGULFkywwMUEZFMFBcNGyZalxu/Bs6aSlMeTMWKFfnyyy9Zt24dK1eu5JFHHgHg3Llz5M2b1+ToRMQh3T5wnFm8k5q7K0mXzJfuJP2tt94iMTERgNGjR3P8+HEaN27MsmXLmDRpUoYHKCIimWj799aqgF8QVO1udjSSDXz44Yd89dVXNGvWjO7du1O1alUAlixZYmsGLyKSLraB48yspN9q7h4bAbE3zItDcoR0dzxs3bq1bblUqVIcOHCAq1ev4u/vbxvhXUREHEB8DKz/1LrcaBC4uJkajmQPzZo14/Lly4SHh+Pv729b//zzz+Pp6WliZCLisJIq6b6FzIvB3QdcvSDuhjWevMHmxSLZXroq6XFxcbi4uLBnz55k6/PkyaMEXUTE0YTMtg7G41MIqvc0OxrJJqKjo4mJibEl6CdPnmTChAkcPHiQgIAAk6MTEYcTEwGxkdblpMHbzOJ96zNM/dIlk6UrSXd1daVo0aKaC11ExNHFx8K68dblhq+Ai7u58Ui20aFDB7777jsArl+/Tt26dRk3bhwdO3ZkypQpJkcnIg4nqYru7gvu3ubGomnYJIuku0/68OHDefPNN7l69WpmxCMiIllh1zwIOw1eAVCzt9nRSDayfft2GjduDMCCBQsoUKAAJ0+e5LvvvtPYNSKSfvbQHz2JpmGTLJLuPumfffYZR44coVChQhQrVgwvL69kj2/fvj3DghMRkUyQEA/rxlmXG74CrrnMjUeylaioKNtUrb///judO3fGycmJevXqcfLkSZOjExGHE25HSboq6ZJF0p2kd+zYMRPCEBGRLBO6E66dAA8/qNXX7GgkmylVqhSLFy+mU6dOrFixgldffRWAixcv4uvra3J0IuJwbJV0E6dfS6JKumSRdCfp77zzTmbEISIiWSU0xPq3cC1w87rrpiLpNWLECJ566ileffVVWrRoQf369QFrVb169eppOsaUKVOYMmUKJ06cAKxzr48YMYI2bdpkVtgiYq9sc6Srki45R7qTdBERcXDnd1n/FqxibhySLT3++OM0atSI0NBQ2xzpAA899BCdOnVK0zGKFCnCBx98QOnSpTEMg2+//ZYOHTqwY8cOKlasmFmhi4g9UiVdcqB0J+lOTk53nW5NI7+LiNi50J3WvwWr3n07kfsUGBhIYGAgZ86cAaxJd506ddK8f/v27ZPdf//995kyZQqbN29Wki6S09gq6XaQpKuSLlkk3Un6okWLkt2Pi4tjx44dfPvtt4waNSrDAhMRkUyQEAcX9lmXA1VJl4yXmJjIe++9x7hx44iMtM5t7OPjw2uvvcbw4cNxckrfxDIJCQn8+OOP3Lhxw9Z0PjUxMTHExMTY7oeHh9/fExAR+2JXlfRbSXr0VetUpi5u5sYj2Va6k/QOHTqkWPf4449TsWJF5s+fz7PPPpshgYmISCa4fAgSYqzzzfqXMDsayYaGDx/OtGnT+OCDD2jYsCEA69evZ+TIkdy8eZP3338/TcfZvXs39evX5+bNm3h7e7No0SIqVKhwx+3Hjh2rYoFIdmMY9tUn3TMPOLlCYpy1yXvuILMjkmwq3fOk30m9evVYtWpVRh1OREQyQ1JT98DKkM6KpkhafPvtt3zzzTf079+fKlWqUKVKFV588UWmTp3KzJkz03ycsmXLEhISwt9//03//v3p3bs3+/btu+P2w4YNIywszHY7ffp0BjwbETFV9DXrD8tgH0m6xaJ+6ZIlMmTguOjoaCZNmkThwoUz4nAiIpJZQm8NGqem7pJJrl69Srly5VKsL1euHFevXk3zcdzc3ChVqhQANWvWZOvWrUycOJGvvvoq1e3d3d1xd3e/v6BFxD4lNXXPlQdc7OT/t08BCD+jfumSqdKdpPv7+ycbOM4wDCIiIvD09GTWrFkZGpyIiGQwDRonmaxq1ap89tlnTJo0Kdn6zz77jCpV7v/HocTExGR9zkUkB7Cn/uhJkvqlRypJl8yT7iT9008/TZakOzk5kT9/furWrYu/v3+GBiciIhkoMRHO77Yua/o1ySQfffQR7dq1448//rAN9LZp0yZOnz7NsmXL0nSMYcOG0aZNG4oWLUpERARz5sxhzZo1rFixIjNDFxF7Y0/90ZP43GruHqHm7pJ50p2k9+nTJxPCEBGRTHftOMRGgIsH5CtrdjSSTTVt2pRDhw7x+eefc+DAAQA6d+7M888/z3vvvUfjxo3veYyLFy/Sq1cvQkND8fPzo0qVKqxYsYJWrVpldvgiYk9USZccKt1J+owZM/D29qZr167J1v/4449ERUXRu3fvDAtOREQyUFJT94AK4JwhQ5KIpKpQoUIpRnHfuXMn06ZN4+uvv77n/tOmTcus0ETEkSRV0n3tKElXJV2yQLqH9h07diz58uVLsT4gIIAxY8ZkSFAiIpIJzt8aNE5N3UVExBHYY3N3VdIlC6Q7ST916hQlSqScW7dYsWKcOnUqQ4ISEZFMoEHjRETEkdhjc3dV0iULpDtJDwgIYNeuXSnW79y5k7x582ZIUCIiksEM47bp15Ski4iIA7DnSvqNi5CYYG4skm2lu1Ni9+7defnll/Hx8aFJkyYA/PXXX7zyyit069YtwwMUEZEMEBEKUZfB4gwFKpgdjWRDnTt3vuvj169fz5pARCR7SEy4LUm3o0q6V37AAkYi3Lj8b2VdJAOlO0l/9913OXHiBA899BAuLtbdExMT6dWrl/qki4jYq6Sm7vnLgmsuc2ORbMnPz++ej/fq1SuLohERh3fjMhgJgAW8AsyO5l/OLtZE/cZFa790JemSCdKdpLu5uTF//nzee+89QkJCyJUrF5UrV6ZYsWKZEZ+IiGQEW1N3DRonmWPGjBlmhyAi2UlSf3TvAPubkcSngDVJj7gAdlTkl+zjvt/xpUuXpnTp0hkZi4iIZBYNGiciIo7EHvujJ/EOBHZrhHfJNOkeOK5Lly58+OGHKdZ/9NFHKeZOFxERO6Hp10RExJHYRnYvZG4cqdEI75LJ0p2kr127lrZt26ZY36ZNG9auXZshQYmISAaKugphp63LgZXNjUVERCQt7L6SjirpkmnSnaRHRkbi5uaWYr2rqyvh4eEZEpSIiGSgpKbu/iXA4+6De4mIiNgFe5wjPUnSDwcRStIlc6Q7Sa9cuTLz589PsX7evHlUqKBpfURE7I6auouIiKOxJen2WEm/1dw9Us3dJXOke+C4t99+m86dO3P06FFatGgBwKpVq5gzZw4LFizI8ABFROQBadA4ERFxJLt+hCN/WJfzBpsbS2pslXQl6ZI50p2kt2/fnsWLFzNmzBgWLFhArly5qFq1Kn/++Sd58uTJjBhFRORB2KZfU5IuIiJ2LmQu/PwiGIlQ7Wko1tDsiFKyVdLPg2GAxWJuPJLtpLu5O0C7du3YsGEDN27c4NixYzzxxBMMGTKEqlV1ASgiYldiIuHKEeuymruLiIg92/49LO5vTdBr9oHHJttnApyUpCfEQvQ1c2ORbOm+knSwjvLeu3dvChUqxLhx42jRogWbN2/OyNhERORBXdgDGNaBd7wDzI5GREQkdf9MhyUDAQNqPwftPgWn+05VMperB3jkti6rX7pkgnQ1dz9//jwzZ85k2rRphIeH88QTTxATE8PixYs1aJyIiD2yNXVXFV1EROzUlqmwbIh1uW5/eGSsfVbQb+cTCDevW0d4DyhvdjSSzaT556n27dtTtmxZdu3axYQJEzh37hyTJ0/OzNhERORBadA4ERGxZ5u++DdBb/CSYyTooBHeJVOluZK+fPlyXn75Zfr370/p0qUzMyYREcko55OSdFXSRUTEzmyYCCtHWJcbDYaHRjhGgg6aK10yVZor6evXryciIoKaNWtSt25dPvvsMy5fvpyZsYmIyIOIj4GLB6zLqqSLiIg9WfvJvwl606GOlaCDKumSqdKcpNerV4+pU6cSGhrK//3f/zFv3jwKFSpEYmIiK1euJCIiIjPjFBGR9Lq4HxLjrIPb+AWZHY2IiIjVmg/hz3ety82HQ/M3HStBB1XSJVOle8hELy8vnnnmGdavX8/u3bt57bXX+OCDDwgICOCxxx7LjBhFROR+nL81aFzBKo538SMiItmPYcCf78GaMdb7D70DTV83N6b75V/c+vfgMji43NRQJPt5oHkNypYty0cffcSZM2eYO3duRsUkIiIZQYPGiYiIvTAM+OMdWPux9f7D70HjwebG9CBKt4YybSD+JszrASFzzI5IspEMmXzQ2dmZjh07smTJkow4nIiIZATb9GtK0kVExESGASuGWweKA3jkA+tI7o7M2QWenAVVnwIjARb3hw2TzI5KsokMSdJFRMTOJCbAhT3WZY3sLiIiZjEMWD4UNn9uvd/2E6jX39yYMoqzC3T84t8fHFa+bR0MzzDMjUscnpJ0EZHs6MoRiIsCV0/IW8rsaEREJCdKTISlg2HLV9b7j06AOv1MDSnDWSzWpvutRlvvb5gIPw+EhHhz4xKHpiRdRCQ7SmrqXqASODmbG4uIiOQ8iYnw6yvwz3TAAh0+h1p9zY4q8zR8xfocLU4QMgt+6AVx0WZHJQ5KSbqISHYUGmL9q0HjREQkqyUmwM8DYPt31qS105dQ/Wmzo8p81Z+GJ2eDszscXAqzusDNMLOjEgekJF1EJDu6ffo1ERGRrJIQD4tegJ1zwOIMnadC1W5mR5V1yrWFnovA3RdOboAZ7SDigtlRiYNRki4ikt0Yxm0juytJFxGRLJIQBwv7we4fwMkFHp8GlR83O6qsV7wh9F0GXgFwYTdMfxiuHjM7KnEgStJFRLKb66fg5nVwcoWA8mZHIyIiOUF8LCx4BvYutH7/dJ0JFTuZHZV5AivDsyvAvzhcOwHTWsP53WZHJQ7CxewAREQkgyU1dQ8oBy7u5sYiIiLZT3ysNfG8etQ6m8iVo3D2H2sS6uwGT3wHZduYHaX58pSEZ1bArMetFfUZbaH7PGulXeQulKSLiGQ3oTutfzVonIiI3K+EeAg7BVeOJU/Grx61ttgyElPu4+wO3eZA6ZZZH6+98gmEPr/C3O5waiPM6gyPz7D2XRe5AyXpIiLZja0/upJ0kQd2/RQcWGp2FGJ3LGnYxGKdAtPJxXqzJC3fts52P7V1t+/3n31t65xTHteShtiSJCZCxDlr8n3liLXfdNLytROQGHfnfV29IG+w9ZYnGPKWgmINwL9Y2s+fU+TKDT0XWrsDHFwG85+GxyZD9R5mRyZ2Skm6iEh2o5HdRTLO5UPw2xtmRyGSDpZ/k3ZbAu/0nx8KnKxTo0VcgPi7zOXt7G5tsv3fZDxvMHgXSN8PAjmday544nv45RXrPOo/vwhRl63zq4v8h5J0EZHsJPIiRIQCFihQyexoRByfdwGo1MXsKCRVZiWIRho3S7TOF56YAInxt91u3TcSUq674/1Ea1U7McG6X2pNzW+PLzHu7lXw2zm5QO5i/ybftmQ8GHyLWBN6yRjOLtDhM/DKCxsmwsoRcOMStHpXP3hIMkrSRUSyk6Sm7nlLgbu3ubGIZAeBleHx6WZHIZKcYfwn2U9aTkzlh4DE//wokPDvdl75IXdRcHY1+xnlHBYLtBoNnvlg5duwcTJEXYX2k6xJvAhK0kVEspfQEOtfDRonIpJ9WSzWhE5JneNq+DJ45oUlL0HIbGui3nWGtVm85HhqvyIikp2oP7qIiIhjqN4DnpwFLh5waDl83xmir5sdldgBJekiItmJbWR3JekiIiJ2r1xb6LkI3P2sU7TNfNQ6vozkaErSRUSyi5thcO24dVnN3UVERBxDsQbQd5l1oMoLu2FGGwg7Y3ZUYiK7SNI///xzihcvjoeHB3Xr1mXLli1p2m/evHlYLBY6duyYuQGKiDiC87utf/2CwDOPubGIiIhI2gVWgr7Lrd/hV47A9DbWeeslRzI9SZ8/fz6DBw/mnXfeYfv27VStWpXWrVtz8eLdm3mcOHGCIUOG0Lhx4yyKVETEzoXutP5VFV1ERMTx5A22Jup5giHslDVRv3jA7KjEBKYn6ePHj6dfv3707duXChUq8OWXX+Lp6cn06Xee7iQhIYEePXowatQoSpYsmYXRiojYMfVHFxERcWy5g6yJekBFiDxvbfp+LsTsqCSLmZqkx8bGsm3bNlq2bGlb5+TkRMuWLdm0adMd9xs9ejQBAQE8++yz9zxHTEwM4eHhyW4iItmSRnYXERFxfD4FoM+vULgmRF+Fb9vDqc1mRyVZyNQk/fLlyyQkJFCgQIFk6wsUKMD58+dT3Wf9+vVMmzaNqVOnpukcY8eOxc/Pz3YLCgp64LhFROxOXDRcOmhdVnN3ERERx+aZB3r9DMUaQUw4fN8Jjv5pdlSSRUxv7p4eERER9OzZk6lTp5IvX7407TNs2DDCwsJst9OnT2dylCIiJriwD4wE8MwHPgXNjkZEREQelLsP9PgRSrWCuCiY8yQcWGp2VJIFXMw8eb58+XB2dubChQvJ1l+4cIHAwMAU2x89epQTJ07Qvn1727rExEQAXFxcOHjwIMHBwcn2cXd3x93dPROiFxGxI+dvGzTOYjE3FhEREckYbp7QbQ789CzsXwLze0Knr6BKV7Mjk0xkaiXdzc2NmjVrsmrVKtu6xMREVq1aRf369VNsX65cOXbv3k1ISIjt9thjj9G8eXNCQkLUlF1Eci7byO7qjy6Ob+zYsdSuXRsfHx8CAgLo2LEjBw8eNDssERFzuLjB4zOgandrq7mF/eCfGWZHJZnI1Eo6wODBg+nduze1atWiTp06TJgwgRs3btC3b18AevXqReHChRk7diweHh5UqlQp2f65c+cGSLFeRCRH0cjuko389ddfDBgwgNq1axMfH8+bb77Jww8/zL59+/Dy8jI7PBGRrOfsAh2+ADcv2PoN/DoIYm9Ag4FmRyaZwPQk/cknn+TSpUuMGDGC8+fPU61aNX777TfbYHKnTp3Cycmhus6LiGSthDi4sNe6rEHjJBv47bffkt2fOXMmAQEBbNu2jSZNmpgUlYiIyZycoO0n4OYNGybA78MhNhKaDlVXt2zG9CQdYODAgQwcmPqvQGvWrLnrvjNnzsz4gEREHMnlQ5AQA24+4F/C7GhEMlxYWBgAefLkueM2MTExxMTE2O5rylURyZYsFmg1yjqo3J/vwpqxEBMBD7+nRD0bUYlaRMTRhd42P7paHkk2k5iYyKBBg2jYsOFdu7ZpylURyVGaDIFHPrQub/rM2vw9McHUkCTj6GpORMTRJQ0ap/7okg0NGDCAPXv2MG/evLtupylXRSTHqfcCPPYZWJxg20xY9H/WLnDi8OyiubuIiDyA87dV0kWykYEDB/Lrr7+ydu1aihQpctdtNeWqiORINXpaB5Nb2A92/wixUdB1Brjo89CRqZIuIuLIEhNva+6uQeMkezAMg4EDB7Jo0SL+/PNPSpTQWAsiIndUqTM8ORuc3eHgUpjzpHXkd3FYStJFRBzZteMQG2H9Ys5XxuxoRDLEgAEDmDVrFnPmzMHHx4fz589z/vx5oqOjzQ5NRMQ+lX0EevwIrl5wbDV83xluhpkdldwnJekiIo4sqal7gYrg7GpuLCIZZMqUKYSFhdGsWTMKFixou82fP9/s0ERE7FfJptDrZ/Dwg9Ob4dvH4MYVs6OS+6AkXUTEkSUNGqf+6JKNGIaR6q1Pnz5mhyYiYt+CakPvX8EzH4SGwMx21inaxKEoSRcRcWRJ/dE1sruIiIiA9Yf7vsvBpyBc2g8bJpodkaSTknQREUdlGLdV0quZGoqIiIjYkfxloM1H1uWNn0H4OXPjkXRRki4i4qgiQiHqMlicoUAFs6MRERERe1K+PQTVg/ho+PN9s6ORdFCSLiLiqJKauucrA665zI1FRERE7IvFAg+/Z10OmQ3n95gbj6SZknQREUdla+qu+dFFREQkFUG1oUJHwICVI8yORtJISbqIiKNKmn5NI7uLiIjInbR8B5xc4egqOLLK7GgkDZSki4g4KlXSRURE5F7ylIQ6/azLK0dAYoK58cg9KUkXEXFEUVch7LR1ObCyubGIiIiIfWvyP3D3gwt7YOc8s6ORe1CSLiLiiJKauvsXBw8/U0MRERERO+eZB5q8Zl3+8z2IjTI3HrkrJekiIo5ITd1FREQkPer8H/gVhYhzsPlzs6ORu1CSLiLiiJKmXwvUoHEiIiKSBq4e8NCtEd7XT4TIS+bGI3ekJF1ExBHZKunVTA1DREREHEilLtZrh9gI+OsDs6ORO1CSLiLiaGIi4coR67KmXxMREZG0cnKCh9+zLv8zAy4dMjceSZWSdBERR3NhL2CAdyB4B5gdjYiIiDiSEo2hTBswEuCPkWZHI6lQki4i4mg0aJyIiIg8iFajwOIMB5fCyY1mRyP/oSRdRMTRnE9K0tXUXURERO5D/rJQo5d1ecVwSEw0Nx5JRkm6iIijUSVdREREHlSzYeDmDee2w96FZkcjt1GSLiLiSOJj4eIB67KmXxMREZH75VMAGr5iXV41CuJjzI1HbJSki4g4kkv7ITEOPHJD7qJmRyMiIiKOrP4A60C010/BlqlmRyO3KEkXEXEkobf1R7dYzI1FREREHJubF7QYbl1e+xFEXTU3HgGUpIuIOJbQXda/auouIiIiGaFaDwioADfDYN04s6MRlKSLiDgWWyW9mqlhiIiISDbh5Ayt3rUub/karh43Nx5Rki4i4jASE+DCHuuypl8TERGRjFLqISjZDBJiYdVos6PJ8ZSki4g4iitHIS4KXD0hbymzoxEREZHswmK5VU23WKdjO7PN7IhyNCXpIiKOIqmpe4FK1qZpIiIiIhmlYBWo2t26/PtbYBjmxpODKUkXEXEU528b2V1EREQko7V4C1w84NRGOLjM7GhyLCXpIiKOwjZoXFVz4xAREZHsya8w1HvRurxyBCTEmRtPDqUkXUTEERiGpl8TERGRzNfoVfDMB1eOwLaZZkeTIylJFxFxBGGn4eZ1cHKBgPJmRyMiIiLZlYcvNHvDurzmA7gZbm48OZCSdBERR5DU1D2gPLi4mxuLiIiIZG81+1hnkom6DBsmmB1NjqMkXUTEEdiauqs/uoiIiGQyZ1doOcq6vOlzCDtrbjw5jJJ0ERFHoEHjREREJCuVawdF60P8TVj9vtnR5ChK0kVEHMH5W5V0Tb8mIiIiWcFigYffsy6HzIHzu82NJwdRki4iYu8iL0JEKGCBApXMjkZERERyiiK1oGInwIDf3zY7mhxDSbqIiL1L6o+etxS4e5sbi4iIiOQsD70DTq5wbDUc+cPsaHIEJekiIvbu2Grr3yK1zI1DREREcp48JaDO89bl30dAYoK58eQAStJFROyZYcD+X6zLZduYG4uIiIjkTE2GgIcfXNwLW6aaHU22pyRdRMSeXdgD10+CiweUaml2NCIiIpITef5/e3ceH1V1/3/8Ndkm+75D2CFhF1lSRFGQstQFXOpSqri0Vgv+9Efbr/rrV9Fva9Hab+vXpaj9itraKtqKWlEpIBFBUMsiECGssoWskJ1sM/f3xw0DQxIgkOTembyfj8d9zF3OnXzO3AmHT86958TDxKZn0pc9okHkOpiSdBERO9u+xHztOxFCIqyNRURERLqu0T+CAVPBVQdv3w711VZH5LeUpIuI2Nm2D8zXrCutjUNERES6NocDpv8RotKgdCd89B9WR+S3lKSLiNjV0W+hcAs4AvU8uoiIiFgvIgGu/RPggI2vw5a/Wx2RX1KSLiJiV8d70XteZD4LJiIiImK13pfA+F+Y6/+8H47ssTQcf6QkXUTErrY3JekDr7I2DhEREZGTXfoA9BgL9ZXw9zuhsd7qiPyKknQRETuqKoL968z1rCusjUVERMSHHamu58u9R/h4awHVdY1Wh+MfAoPM295DYyF/A3zyK6sj8itBVgcgIiItyPsQMCB9BMR0tzoaERERWzMMg/zyWnYVVXmW3UVV7Cqu4kj1iV7e9JhQHps+hO8OSrEwWj8RmwHTn4NFP4TPn4E+l2q62HaiJF1ExI40qruIiEgzDS43+0przCS8+KSEvLiKmnpXq+d1jwujweUmv7yWH//530wdnMqjVw8mNSa0E6P3QwOvMqdm++p/YfHdcPcaiNIfQM6XknQREbuprYC9n5rreh5dRES6oLpGFzsLvRPxXUVVfFtaTYPLaPGcoAAHvRIj6J8cSb+mpW+SuYSFBHKs3sUzn+zkT6v28HFuAat3lfCLKZn88Ds9CQxwdHIN/cjkX8O+tVCUC4vvgh8uhgA9VX0+lKSLiNjNzn+Bqx4S+kNSptXRiFhi1apVPPXUU6xfv57Dhw+zePFiZsyYYXVYItIBDMPgcHktG/YfZeP+MjbsP0ruoQrqXe4Wy4eHBNI3yTsR75ccSc+EcIIDW08Ow0ICeWBqFtMvSOehd7awcX8Z897P5Z2Nh5h/zVAGpUd3VBX9W3AYfP8VeOky2JMDn/8PXPx/rY7KpylJFxGxG8+o7rrVXbqu6upqhg8fzh133MG1115rdTgi0o5qG1xsPVTulZQXVtQ1KxcbHuzpFe+bFEn/lCj6JUeSFh1KwHn0fGelRvOPuy/ir1/u57cfbefrA2Vc9dxqfnRxb+6b1J/wEKVIbZaUCdOehPfvhU9+DT0vhozRVkfls/QNFBGxk4Za2LnMXM/Sre7SdU2bNo1p06ZZHYaInCfDMDh49JgnId+4/yjfHK5odst6YICDgWlRXNgjjhE9YrmwRxw94sNxODrmNvSAAAe3fKcnkwel8F///IYlWw7z4qo9fLD5ML+eMYQJWckd8nP92ohbYPdKyH0H/nEH/OQzCIu1OiqfpCRdRMRO9n4K9VUQlW6O7C4iZ6Wuro66uhM9cRUVFRZGI9J11dQ3svlguaeHfOP+MkqqmveSJ0Y6ubBHLCN6xHFhj1iGdo+xpAc7JTqU52deyHXbC3n43VwOlR3j9le/4ophacy7chDJ0RpY7qw5HHDV03BoPZTtgw/uh+tfMfdLmyhJFxGxk23/NF+zrtCgKyJtMH/+fB577DGrwxDpUmobXOQVVJKbX0FufjmbDpSxvaASl9u7lzwowMHg9GhGnNRL3j0urMN6yc/FxKwUvjM3gT8s28HCNd+yZPNhVu0o5oGpWfxgTI/zur2+SwmNgesXwsIpkLsY+kyAkbOsjsrnOAzDaHl4RD9VUVFBTEwM5eXlREdrcAgRsRG3C343AGpK4Nb3oM9lVkcknURt0+k5HI4zDhzXUk96RkaGPlORdlJZ28A3+RVsbUrIv8mvYGdRVbOEHCAl2ul12/qQbjGEBgdaEPW52XqonP+3eAubD5YDcGGPWOZfO4zM1CiLI/Mhq5+G5fMgKAzuyoHkLKsjslxb2nr1pIuI2MX+dWaCHhoLPcdZHY2IT3E6nTidTqvDEPELxZV15OaXe3rIc/Mr2Fda02LZuPBghnSLYVB6NEO7xXBhjzjSYkJt1UveVkO6xbD4p+P4y9pveWppHhv2l3HFM59x1/g+/J/L+/vUHxwsc9H/MR/h2/0J/P12+PEn5ijwclaUpIuI2MXxUd0HTIXAYGtjERERv3d8ULcTCXkFWw+VU1TZ/BlygPSYUAalxzCkWzSD02MYnB7t8wl5awIDHNw2rjdThqTy6Pu5LM0t5I85u/lg82Eev2YIl/RPsjpEewsIgBkvwAvjoOgbWPpLuPL3VkflM5Ski4jYgWFo6jWRk1RVVbFr1y7P9t69e9m0aRPx8fH06NHDwshEfFddo4uvD5Szbk8pX+wtZcvBcipqG5uVczigd2IEg9NjGJJuJuSD0qOJjwixIGprpcWE8eIto/hXbgHz3s9l/5Eabnn5S6ZfkM7DVw4iMVJ38LQqKgWueRFevxb+/bL5GN+gq62OyifomXQRETs4vBlevMR8dus/9kBIuNURSSdS29RcTk4OEyZMaLZ/1qxZvPrqq2c8X5+piHdSvm5PKev3HaWu0e1VJjjQwYCUKAY3JeNDukWTlRpNhFN9eaeqqmvkv/+Vx2uff4vbgJiwYP5r+mCmX9DN6tDsbdkjsOZ/zEHl7l4NsV3zD616Jl1ExNcc70Xvd7kSdBHgsssuo4v1I4ict7NJyhMjQ8juk8B3+iQwIiOWASlRhARpNpGzEekMYt5Vg7lmRDceemcLufkV3PfmJjbsO8ovrxikz7E1Ex+Gb1ebU7P948dw2xIIVBp6Ovp0RETsYFtTkp6lW91FROTs1DW62LS/jHV7jrBuTykb9p8+KR/bJ56+SZF++Qx5ZxrWPZb3Zo/jmRU7eeaTXby2dh9b8yv448wLSdG86s0FBsN1L8OL4+HAOvj0CZj4n1ZHZWtK0kVErHZkDxTlgiMQBkyxOhoREbGps0vKnXynTzzfaUrM+yZFKCnvAEGBAcydnMnwjFjuX7SJ9fuOcsUzq3n+ByPI7pNgdXj2E98brnoa/n4HrPod9B5vLtIiJekiIlY73ove62IIj7c2FhERsY3jt6+v3V2qpNymLh+Ywj/nXMzdr69ne0ElP/jfL/h/3xvIHeN66Tqcash1sHslbPwLvHOX+Xx6RKLVUdmSknQREat5RnW/yto4RETEUvWNbjYfLGPdnlLWNj1TXtugpNzueiVG8M5PL+Khd7bw3qZ8fvXBN2w6UMYT1w7VAHynmvYkHPgCSnbAuz+FHywypxMQL7b41jz//PM89dRTFBQUMHz4cJ599lnGjBnTYtk//elP/PnPf2br1q0AjBw5kt/85jetlhcRsbXKQjjwpbmedYW1sYiISKdqcLnZcuhET/m/vz3KsQaXV5njz5SPVVJua+EhQTx94wWMyIjl10u28c+v88krqODFW0bROzHC6vDsIyQCrn8F/jQRdi6FdQtg7E+tjsp2LE/SFy1axNy5c3nhhRfIzs7m6aefZsqUKeTl5ZGcnNysfE5ODjfffDMXXXQRoaGhPPnkk0yePJnc3Fy6ddP0ByLiY/KWAAZ0GwnR6VZHIyIiHajR5WZrfoXZU767lH9/e4Tqeu+kPD4ixNNTPrZPAv2SNdCbr3A4HNw2rjeDu8Xw079uYEdhFVc/u5r/vmE4kwenWh2efaQOgSmPw4c/N6dnc9VBfF9zarbYHhAW1+V71y2fJz07O5vRo0fz3HPPAeB2u8nIyODee+/lwQcfPOP5LpeLuLg4nnvuOW699dYzlte8qSJiK3+5FnavgMvnwSVzrY5GLKK2qf3pMxU7cLkNvsmvYO2eEtbtOcJXe49QWdfoVSY2PJjs3vFmT3nfBAYkRxEQ0LUTFH9QVFHL7L9t4KtvjwIwe0Jf5n43k0BdW5NhwKIfnnjk72QhkRCT0ZS0Z5xI3mOaXiMSfTKJ95l50uvr61m/fj0PPfSQZ19AQACTJk1i7dq1Z/UeNTU1NDQ0EB/f8mBLdXV11NXVebYrKirOL2gRkfZSWw57V5nreh5dRMTnGYbB7uJqPttZzJpdJXyx9wiVtd5JeXRo0ElToiWQlaqk3B8lR4fytx9/h998uI1X1nzL8yt3s/lgOc/cNIK4iBCrw7OewwHXvAhfLIDCb6D8AJTth6pCqK+C4m3m0pKgsBPJe8xJSfzx7dBocAS0sPjO75mlSXpJSQkul4uUlBSv/SkpKWzfvv2s3uOBBx4gPT2dSZMmtXh8/vz5PPbYY+cdq4hIu9vxL3A3QGImJPa3OhoRETkHR6rrWbOrhM92FrN6Zwn55bVex6OcQYzpHc/YvmZiPjAtWr2pXURwYADzrhrMBRmxPPiPLXy2s4Qrn13NCz8cydDuMVaHZz1nJIz/hfe+hlooPwhl+04k7mX7oaxpvfIwNB4zB54r2dHGH+honrgHBJ5I4L2OBXpv/2g5RKWc+Ue0E8ufST8fTzzxBG+++SY5OTmEhoa2WOahhx5i7twTt5BWVFSQkZHRWSGKiLRu+z/N14FXWhuHiIictfpGN+v3HTWT8l0lbDlUzskPj4YEBTCmVzwX90/kor4JDEqLJigwwLqAxXLTL+hGZmoUd/9lPd+W1nDdC5/z6+lDuGG0cpJmgkMhsZ+5tKSxHioOeifunmT+gHnMcLd8LgYYLnNps859QtzSJD0xMZHAwEAKCwu99hcWFpKaevrBFX73u9/xxBNPsHz5coYNG9ZqOafTidPpbJd4RUTaTcMx2LncXM9Ski4iYlfmLexVrNpRwupdJazbU0rNKYO9ZaVGcUn/RC7pn8ToXvGEhQRaFK3YVVZqNO/NuZifvbWJ5duK+I9/bGbjgTIevXoQziB9X85aUAjE9zGXlrgawVVvJuqGuykpN07ablrcrlP2Gaecc0r5sJYfre6wanbqTztFSEgII0eOZMWKFcyYMQMwB45bsWIFc+bMafW83/72tzz++OMsXbqUUaNGdVK0IiLtaE8ONFRDdDdIH2F1NCIicpIj1fWs3lXCZzvM3vLDp9zCnhjpbErKE7m4XyLJ0S3f0SlyspiwYF66ZRR/zNnFfy/bwRtf7ueb/HIW/HAk6bFhVofnHwKDzMXHWV6DuXPnMmvWLEaNGsWYMWN4+umnqa6u5vbbbwfg1ltvpVu3bsyfPx+AJ598kkceeYS//e1v9OrVi4KCAgAiIyOJjIy0rB4iIm2yrWk006wrfGogExERf1TX6GL9vqOs3lnCZztL2Jrf/Bb27N7xnt7yrNQoTYsm5yQgwMGcif0Z2j2W+97cyNcHy7ny2dU8e/MIxvVLtDo8sQnLk/Qbb7yR4uJiHnnkEQoKCrjgggv4+OOPPYPJ7d+/n4CAE8/xLFiwgPr6eq6//nqv95k3bx6PPvpoZ4YuInJuXI2Q96G5rlvdRUQskV92jJy8YlbmFbFmV0mLt7CPH5DEJf0TGd0rntBg3ZIs7efSAUn8c87F3P36enLzK7jl5S/4xZQs7r60j/4AJNbPk97ZNG+qiFhu72fw2pUQFgc/3+UXt2XJ+VHb1P70mcqpGlxuNuw7ysq8YnLyitheUOl1PDHSyfj+iVwyIJFx/RJJjtIt7NLxahtcPPzuVt5efxCAfsmRpMeGkRgRQnxECAmRThIiQkiINLcTI53ER4QQHhKoZN7H+Mw86SIiXdL2JebrgGlK0EVEOlBRZS2f5hWTk1fMqp3FXnOWBzhgRI84JmQmcVlmMoPSojVfuXS60OBAfnv9MC7oEcuj7+eyq6iKXUVVZ3FeAAkRTk/yfnICfzypT4hwEhMWTGhwIM6gAEKCAnAGBWi2AR+g/x2KiHQmw4DtTc+ja+o1EZF25XIbfH2wjJztRazMK2bLoXKv43HhwVyWmcxlmUmM759EXESIRZGKnOBwOJiZ3ZMJmclsL6igtKqe0up6jlTXU1JVx5HqekqrTmzXNbqpbXBzqOwYh8qOtfnnBQY4cDYl7M6gQJzBJ60HBTRtB3rKhJx0LDjoRIJvGGBgeGYnMzBnQzC8tpvKNK3TVOb4cQfmgHqJUU4SI80lIdL8g0N0aFCXvVtASbqISGc6/LU5n2dwOPSdaHU0IiI+72h1Pat2FrNyexGf7ijmaE2D1/Fh3WO4LDOZCZlJDOseS6B6y8Wm0mPDzjjKu2EY1NS7mhL5uhPJe3UdR5qSezPBN4+VH2ugvtFNo/vEE84ut/ke5jgMDa3/MIuFBAWQGBFCYpR5y39ipPOkZD7Ek9QnRoYQFx7iV3fCKEkXEelMx3vR+10OwZpuRUSkrQzDIDe/gpXbi1iZV8SmA2WclH8QFRrE+AFJTMhM5tIBSSRFOa0LVqSdORwOIpxBRDiD6JEQftbnudwG9Y1u6hpd1DW6qWs4ab3R1bTtPrF9fL3B5bW/vtGNA4dnYhoHJyapcTgceNJkB62XO2m/YcDRGvMOgZKqekqbXqvqGqlvdJNfXkv+KVMgtiQwwOG51b9PUgRDu8UytFsMQ7vFEBMefNafk10oSRcR6UyeqdeusjYOEREfUlPfyOqdJXzSlJgXVtR5Hc9KjWJCVjITMpO5sEesnrkVOUVggIOwkEDCQnxjloLaBhfFlXWUVtdTUlnXlMSbCfyp62U1DbjcBsWVdRRX1rG9oJIPtxR43qtHfDhDu5sJ+7BuMQzuFkNMmL0TdyXpIiKdpXQ3FG+DgCAYMNnqaEREbO3AkRo+2V7Eiu1FrNtTSn2j23MsPCSQcf0SmZhlPl+eFqM7k0T8SWhwIBnx4WTEn/lugQaXmyPV9WaSXlVHXkElWw6Vs+VgOfuP1HiWJZsPe87plRDO0O6xDO0WzdBusQzpFk1UqH0SdyXpIiKdZds/zddel5jTr4mIiEejy82G/WWs2F7IJ9uK2HnKCNcZ8WFcnpXCxKxksvvE4wzyjR5BEelYwYEBpESHkhJtTps4ITPZc6yspp6thyrYfKiMrYfK2XywnINHj/FtaQ3fltbwz6/zPWX7JEZ4etyHNvW4RzqtSZeVpIuIdBaN6i4i4qWspp5PdxSzYps56Fv5sRODWAUGOBjVM46JWclcPjCZvkmRXXakZxE5N7HhIVzcP5GL+yd69h2trjd72pt627ccKudQ2TH2lFSzp6Sa9zaZibvDYSbuw7rHMve7A86qV7+9KEkXEekMFYfh4FfmeuYV1sYiImIRwzDYUVjFJ9uL+GR7Iev3HfUa9C02PJgJmclMyErm0v5JPjngk4jYW1xECOMHJDF+QJJnX2lVHVsOlXt627ccKudweS27i6vZXVzNQ9/L6tQYlaSLiHSGvCXma/fREJ1mbSwiIp2ortHF2t2l5vPl24qazeuclRrFxKxkJmYlM6JHnKZIE5FOlxDp5LLMZC476Vb54so6th4qZ2dRJclRoZ0aj5J0EZHO4BnVXbe6i4j/q6prZOX2IpbmFpCTV0xVXaPnmDMogIv6JjBxoPl8ebczzAstImKFpCinOWtEVvKZC7czJekiIh3t2FH49jNzfaCmXhMR/1RSVcfybwpZmlvAml2l1LtOjMaeHOVk0qAULs9K5qK+iT4zDZSIiBWUpIuIdLQd/wJ3IyQNhIS+VkcjItJuDhypYWluAf/KLeTf+454PV/eJzGCyYNTmTI4heHdYwnQbewiImdFSbqISEfb3jT1WpYGjBMR32YYBnmFlSzdavaYf3O4wuv40G4xTBmcwpTBqfRL1mjsIiLnQkm6iEhHajgGu1aY65p6TUR8kNttsPHAUZbmmon5vtIaz7EAB4zpHc+UwalMHpyq58tFRNqBknQR8bZzGaxbACNvg0FXWx2N79v9CTTUQEwGpF1gdTQiImelvtHN2j2lLM0tYNk3hRRX1nmOhQQFML5/IpMHpzJpYArxESEWRioi4n+UpIuIye2CnCdg1W/N7d0rYNx9MPERCNQ/FefMM6r7FaDbPkXE5vLLjvHy6r289e8DVNaeGJE9yhnExIHJTBmcyqUDkohwql0QEeko+hdWRKC6FN75kdnrC9DjItj/Oaz5Hzj8NVy3ECISrI3RF7kaYcdH5rqmXhMRG9tVVMkLn+7h3Y2HaGwa/S0pysl3B5nPl4/tk0BIUIDFUYqIdA1K0kW6ukPr4a1ZUH4AgsLg6mdg2A2w9R/w3hzYkwMvXQY3/gXSL7A4WB+z/3Nz+rWweOgx1upoRESa2bj/KAtydvOvbwo9+8b2SeAnl/ZhfP8kjcguImIBJekiXZVhwPpX4KMHwFUP8X3gxtchZbB5fMh15pRhi2bCkT2wcApc+Qe44AfWxu1Ljt/qnvk9PTIgIrZhGAardpawIGcX6/YcAcyncSYPSuHuS/syokecxRGKiHRt+l+jSFdUXwNLfgZf/83czroSZvwRQmO8y6UMgh+vhMU/gR0fw7v3wKENMOU3EKSBgk7LMGD7EnNdo7qLiA00utx8uLWAF3J2e6ZOCw50MOOCbvzk0r70S460OEIREQEl6SJdz5E9sOhWKNwCjgC4fJ45QFxrg5qFxcJNb5gDyuXMh6/+BAWb4fuvQXRap4buU/I3QsVBCI6APhOsjkZEurDaBhd/X3+Ql1btYf8Rc/q08JBAfjCmB3de0pu0GE2bJiJiJ0rSRbqSvI/gnZ9AXTlEJMH1C6H3+DOfFxAAlz1oTiH2zl1w4At46VIzUe+pZ61btL3pVvf+kyA41NpYRKRLqqht4PV1+1i4+ltKqswp1OLCg7l9XG9uHduT2HDdESUiYkdK0kW6ArcLVj4On/23ud19DNzwGkSnt+19MqfCXSth0Q+h6Bt47UqY+gSM/pGmFzuVZ+q1q6yNQ0S6nKKKWhau+Za/rttHZZ05jVq32DB+fElvbhidQXiI/vsnImJn+ldaxN9Vl8A/7jRHaQfIvhu++6tzf6Y8oS/cuQzevxdy34EPf26OEH/lHyBYt0wCULITSvIgIBgGTLY6GhHpIr4tqebFVXv4x/qD1LvcAAxIieSey/py5bB0ggM1hZqIiC9Qki7izw7+G966FSoOmc9GX/0MDL3+/N/XGWneKt9tJCx7BL5+AwpzzdHh43qe//v7osoCOPiV+ZnvWmHu6z2++WB8IiLtqK7Rxb+/PcrfvtzPR1sO0zTFOSN7xvHTy/oyITNZ06iJiPgYJeki/sgw4Kv/hY8fAncDJPQ35zlPHth+P8PhgIvmQNowePt2czC5ly41k/e+E9vv59hRQy0c/tpMyg/920zMyw80L6fp6kSknRmGwZ6SalbtKGbVjmLW7TnCsQaX5/jErGTuuawvo3vFWxiliIicDyXpIv6mvgY+uB82LzK3B14N05+H0OiO+Xm9x8NPPoVFt0D+Bnj9Opj4MFz8f/3jOXXDgKN7zUT84FfmUrDV/OPHyRwB5rzy3UdB99HQ4zuQ2N+amEXEr5Qfa+DzXSWs2lnMqh0lHCo75nU8KcrJxMxkbhvXi4FpHfRvvYiIdBol6SKdqaHWvPXc1QBRqeat0O2ZyJbuNpPlolxwBMJ3H4Oxczo+WY7pDrd/ZD6fvvEvsOIxcwqyGX8EZ1TH/uz2VltuPmN/cP2JnvKa0ublIpLNZLz7SPM1fYTv1VVEbMnlNth8sIxVO8zEfNOBMlzH72MHQgIDGN07jvH9kxg/IIms1Cgc/vBHURERAZSki7QfwzCTufIDUH7wxFK2/8R6dZH3OcHhEJVmLtFpp6ynm4l8VNrZDfK27QN49x6oq4DIFLj+Feg1rmPq2pLgUJj+nPmc+oe/gG3vQ3Ee3PTX8+tRdjXCsSPmAHg1JeZnXF0CDccAw/zcm73StM5pypzyWlVkJuTFeTSdeEJgCKQNb0rKR0G3URDbwz/uFBCR06qpb6Swoo7o0CCiw4I7bPC1w+XHmm5hL2H1rhLKj3nfrdM3KYLxA5IY3z+J7D7xGqFdRMSP6V94kbN1vBf85AS8fL/3dmPtmd8nONwc9buuHBpq4Mhuczmd8MSTkvdUM4E/Oanf+g9Y87RZtsdY+P6rZjkrjLodUoaYA9aV5MFLE+CaF2DglWYyXF9tJto1JVBdemL9ePJdU+q9XlvW+XWI62Um4t1Hm0vqEAhydn4cImK5TQfK+MGfvvBsh4cEEhMWTHRosPkaZibvJ7abXkODvLfDgokICfT0eNc2uFi3p5TPdpawakcxO4uqvH5uVGgQF/dLZPyAJC7pn0j3uPBOrbeIiFhHSfr5WPMMfP2m1VFIhzPMhPHUXvDWRKaat397lgyIzTixHhZn9sDW10Dl4aalACryT2xXHD6x7qpvSmJLoHDL6X/2d2abt7gHBp9/tc9HxmjzOfW3b4N9a2DRTIjuZibdZ/OHjGYcEB4P4QnmHyzC4yEkwtzvcJzySiv7z/DqjIJuF5rJeWRSu3wMIuL76hrdRDqDqGqab7ym3kVNvYvD5W3/tywwwOHpkT9cXkt9o9tzLMABwzNiPbewD+8eQ5CmTBMR6ZKUpJ+PqkLz2V/pOoLCTkq4m5Luk9ej08++xzUk3JxzPKFv62UMA2qOnJTMH0/g809K7AvMpHzyr2HIte1Tz/YQmQy3vmdO0bbuj+ZdCMcFOiEisSnpTmhab9qOSDhpvek1LA4CAq2ri4hY4vnnn+epp56ioKCA4cOH8+yzzzJmzJhOjWFCZjJbH5tCo8tNZW0jFbUNlB9roOJYo/nq2W56rW30bFecdLzBZeByGxytaeBojXkre1pMqCcpH9cvgdjws3i0SURE/J6S9PMx8nboN8nqKKQzhMWZSXh4fOc+h+xwmElrRIJ5y7WvCQyGqfNh1B3ms/LHe8JDIvQ8t4ic1qJFi5g7dy4vvPAC2dnZPP3000yZMoW8vDySk5M7PZ6gwADiIkKIi2h7Im0YBrUNbq+kPi48hL5JERrwTUREmnEYhmGcuZj/qKioICYmhvLycqKjNU2JiIhYT21Tc9nZ2YwePZrnnnsOALfbTUZGBvfeey8PPvjgGc/XZyoiInbSlnZJDzuJiIiIrdTX17N+/XomTTpxt1pAQACTJk1i7dq1LZ5TV1dHRUWF1yIiIuKLlKSLiIiIrZSUlOByuUhJSfHan5KSQkFBQYvnzJ8/n5iYGM+SkZHRGaGKiIi0OyXpIiIi4vMeeughysvLPcuBAwesDklEROScaOA4ERERsZXExEQCAwMpLCz02l9YWEhqamqL5zidTpzOs5xdQ0RExMbUky4iIiK2EhISwsiRI1mxYoVnn9vtZsWKFYwdO9bCyERERDqeetJFRETEdubOncusWbMYNWoUY8aM4emnn6a6uprbb7/d6tBEREQ6lJJ0ERERsZ0bb7yR4uJiHnnkEQoKCrjgggv4+OOPmw0mJyIi4m+UpIuIiIgtzZkzhzlz5lgdhoiISKfSM+kiIiIiIiIiNqEkXURERERERMQmlKSLiIiIiIiI2ISSdBERERERERGbUJIuIiIiIiIiYhNK0kVERERERERsostNwWYYBgAVFRUWRyIiImI63iYdb6Pk/Km9FxERO2lLW9/lkvTKykoAMjIyLI5ERETEW2VlJTExMVaH4RfU3ouIiB2dTVvvMLrYn+3dbjf5+flERUXhcDjO670qKirIyMjgwIEDREdHt1OE1lBd7Mdf6gH+Uxd/qQf4T138pR6GYVBZWUl6ejoBAXoSrT2ovW/OX+oB/lMXf6kHqC525C/1AP+oS1va+i7Xkx4QEED37t3b9T2jo6N99styKtXFfvylHuA/dfGXeoD/1MUf6qEe9Pal9r51/lIP8J+6+Es9QHWxI3+pB/h+Xc62rdef60VERERERERsQkm6iIiIiIiIiE0oST8PTqeTefPm4XQ6rQ7lvKku9uMv9QD/qYu/1AP8py7+Ug+xN3/5nvlLPcB/6uIv9QDVxY78pR7gX3U5G11u4DgRERERERERu1JPuoiIiIiIiIhNKEkXERERERERsQkl6SIiIiIiIiI2oSRdRERERERExCaUpJ/B888/T69evQgNDSU7O5svv/zytOXffvttsrKyCA0NZejQoXz44YedFGnr5s+fz+jRo4mKiiI5OZkZM2aQl5d32nNeffVVHA6H1xIaGtpJEbfu0UcfbRZXVlbWac+x4zXp1atXs3o4HA5mz57dYnk7XY9Vq1Zx1VVXkZ6ejsPh4N133/U6bhgGjzzyCGlpaYSFhTFp0iR27tx5xvdt6+9aezhdXRoaGnjggQcYOnQoERERpKenc+utt5Kfn3/a9zyX72hH1gPgtttuaxbT1KlTz/i+drsmQIu/Nw6Hg6eeeqrV97Timojv8fX2Xm29va7Hcb7a3qutV1vfkdTWn5mS9NNYtGgRc+fOZd68eWzYsIHhw4czZcoUioqKWiz/+eefc/PNN3PnnXeyceNGZsyYwYwZM9i6dWsnR+7t008/Zfbs2axbt45ly5bR0NDA5MmTqa6uPu150dHRHD582LPs27evkyI+vcGDB3vFtXr16lbL2vWafPXVV151WLZsGQDf//73Wz3HLtejurqa4cOH8/zzz7d4/Le//S3PPPMML7zwAl988QURERFMmTKF2traVt+zrb9r7eV0dampqWHDhg08/PDDbNiwgXfeeYe8vDyuvvrqM75vW76j7eFM1wRg6tSpXjG98cYbp31PO14TwKsOhw8fZuHChTgcDq677rrTvm9nXxPxLf7Q3qutt9f1OM5X23u19WrrO5La+rNgSKvGjBljzJ4927PtcrmM9PR0Y/78+S2Wv+GGG4wrrrjCa192drbxk5/8pEPjbKuioiIDMD799NNWy7zyyitGTExM5wV1lubNm2cMHz78rMv7yjW57777jL59+xput7vF43a9HoCxePFiz7bb7TZSU1ONp556yrOvrKzMcDqdxhtvvNHq+7T1d60jnFqXlnz55ZcGYOzbt6/VMm39jra3luoxa9YsY/r06W16H1+5JtOnTzcmTpx42jJWXxOxP39s79XW2+t6HOeL7b3a+uasblfU1jdn9TVpb+pJb0V9fT3r169n0qRJnn0BAQFMmjSJtWvXtnjO2rVrvcoDTJkypdXyVikvLwcgPj7+tOWqqqro2bMnGRkZTJ8+ndzc3M4I74x27txJeno6ffr0YebMmezfv7/Vsr5wTerr63n99de54447cDgcrZaz6/U42d69eykoKPD6zGNiYsjOzm71Mz+X3zWrlJeX43A4iI2NPW25tnxHO0tOTg7JyclkZmZyzz33UFpa2mpZX7kmhYWFLFmyhDvvvPOMZe14TcQe/LW9V1tvr+sB/tPeq6032bFdUVtvv2tyrpSkt6KkpASXy0VKSorX/pSUFAoKClo8p6CgoE3lreB2u7n//vsZN24cQ4YMabVcZmYmCxcu5L333uP111/H7XZz0UUXcfDgwU6Mtrns7GxeffVVPv74YxYsWMDevXu55JJLqKysbLG8L1yTd999l7KyMm677bZWy9j1epzq+Ofals/8XH7XrFBbW8sDDzzAzTffTHR0dKvl2vod7QxTp07lz3/+MytWrODJJ5/k008/Zdq0abhcrhbL+8o1ee2114iKiuLaa689bTk7XhOxD39s79XW2+t6HOcv7b3aenu2K2rr7XdNzkeQ1QFI55o9ezZbt2494zMaY8eOZezYsZ7tiy66iIEDB/Liiy/yq1/9qqPDbNW0adM868OGDSM7O5uePXvy1ltvndVf2Ozo5ZdfZtq0aaSnp7daxq7Xo6toaGjghhtuwDAMFixYcNqydvyO3nTTTZ71oUOHMmzYMPr27UtOTg6XX365JTG1h4ULFzJz5swzDqpkx2si0pHU1tuT2nt7U1tvT121rVdPeisSExMJDAyksLDQa39hYSGpqaktnpOamtqm8p1tzpw5fPDBB6xcuZLu3bu36dzg4GBGjBjBrl27Oii6cxMbG8uAAQNajcvu12Tfvn0sX76cH/3oR206z67X4/jn2pbP/Fx+1zrT8UZ73759LFu27LR/WW/Jmb6jVujTpw+JiYmtxmT3awLw2WefkZeX1+bfHbDnNRHr+Ft7r7beZJfrcZw/tfdq65uzY7uitt5+16QtlKS3IiQkhJEjR7JixQrPPrfbzYoVK7z+wnmysWPHepUHWLZsWavlO4thGMyZM4fFixfzySef0Lt37za/h8vlYsuWLaSlpXVAhOeuqqqK3bt3txqXXa/Jca+88grJyclcccUVbTrPrtejd+/epKamen3mFRUVfPHFF61+5ufyu9ZZjjfaO3fuZPny5SQkJLT5Pc70HbXCwYMHKS0tbTUmO1+T415++WVGjhzJ8OHD23yuHa+JWMdf2nu19fa6Hqfyp/ZebX1zdmxX1Nbb75q0ibXj1tnbm2++aTidTuPVV181vvnmG+Ouu+4yYmNjjYKCAsMwDOOWW24xHnzwQU/5NWvWGEFBQcbvfvc7Y9u2bca8efOM4OBgY8uWLVZVwTAMw7jnnnuMmJgYIycnxzh8+LBnqamp8ZQ5tS6PPfaYsXTpUmP37t3G+vXrjZtuuskIDQ01cnNzraiCx89+9jMjJyfH2Lt3r7FmzRpj0qRJRmJiolFUVGQYhu9cE8MwR9Ds0aOH8cADDzQ7ZufrUVlZaWzcuNHYuHGjARi///3vjY0bN3pGQX3iiSeM2NhY47333jM2b95sTJ8+3ejdu7dx7Ngxz3tMnDjRePbZZz3bZ/pds6Iu9fX1xtVXX210797d2LRpk9fvTl1dXat1OdN3tLPrUVlZafz85z831q5da+zdu9dYvny5ceGFFxr9+/c3amtrW62HHa/JceXl5UZ4eLixYMGCFt/DDtdEfIs/tPdq6+11PU7mi+292nq19R1Jbf2ZKUk/g2effdbo0aOHERISYowZM8ZYt26d59ill15qzJo1y6v8W2+9ZQwYMMAICQkxBg8ebCxZsqSTI24OaHF55ZVXPGVOrcv999/vqXdKSorxve99z9iwYUPnB3+KG2+80UhLSzNCQkKMbt26GTfeeKOxa9cuz3FfuSaGYRhLly41ACMvL6/ZMTtfj5UrV7b4fToer9vtNh5++GEjJSXFcDqdxuWXX96sjj179jTmzZvnte90v2tW1GXv3r2t/u6sXLmy1bqc6Tva2fWoqakxJk+ebCQlJRnBwcFGz549jR//+MfNGmBfuCbHvfjii0ZYWJhRVlbW4nvY4ZqI7/H19l5tvb2ux8l8sb1XW6+23qq6HNfV23qHYRjGufbCi4iIiIiIiEj70TPpIiIiIiIiIjahJF1ERERERETEJpSki4iIiIiIiNiEknQRERERERERm1CSLiIiIiIiImITStJFREREREREbEJJuoiIiIiIiIhNKEkXERERERERsQkl6SLS6RwOB++++67VYYiIiEgHUVsvcu6UpIt0MbfddhsOh6PZMnXqVKtDExERkXagtl7EtwVZHYCIdL6pU6fyyiuveO1zOp0WRSMiIiLtTW29iO9ST7pIF+R0OklNTfVa4uLiAPP2tAULFjBt2jTCwsLo06cPf//7373O37JlCxMnTiQsLIyEhATuuusuqqqqvMosXLiQwYMH43Q6SUtLY86cOV7HS0pKuOaaawgPD6d///68//77HVtpERGRLkRtvYjvUpIuIs08/PDDXHfddXz99dfMnDmTm266iW3btgFQXV3NlClTiIuL46uvvuLtt99m+fLlXg3zggULmD17NnfddRdbtmzh/fffp1+/fl4/47HHHuOGG25g8+bNfO9732PmzJkcOXKkU+spIiLSVamtF7ExQ0S6lFmzZhmBgYFGRESE1/L4448bhmEYgHH33Xd7nZOdnW3cc889hmEYxksvvWTExcUZVVVVnuNLliwxAgICjIKCAsMwDCM9Pd345S9/2WoMgPGf//mfnu2qqioDMD766KN2q6eIiEhXpbZexLfpmXSRLmjChAksWLDAa198fLxnfezYsV7Hxo4dy6ZNmwDYtm0bw4cPJyIiwnN83LhxuN1u8vLycDgc5Ofnc/nll582hmHDhnnWIyIiiI6Opqio6FyrJCIiIidRWy/iu5Ski3RBERERzW5Jay9hYWFnVS44ONhr2+Fw4Ha7OyIkERGRLkdtvYjv0jPpItLMunXrmm0PHDgQgIEDB/L1119TXV3tOb5mzRoCAgLIzMwkKiqKXr16sWLFik6NWURERM6e2noR+1JPukgXVFdXR0FBgde+oKAgEhMTAXj77bcZNWoUF198MX/961/58ssvefnllwGYOXMm8+bNY9asWTz66KMUFxdz7733csstt5CSkgLAo48+yt13301ycjLTpk2jsrKSNWvWcO+993ZuRUVERLootfUivktJukgX9PHHH5OWlua1LzMzk+3btwPmaKxvvvkmP/3pT0lLS+ONN95g0KBBAISHh7N06VLuu+8+Ro8eTXh4ONdddx2///3vPe81a9Ysamtr+cMf/sDPf/5zEhMTuf766zuvgiIiIl2c2noR3+UwDMOwOggRsQ+Hw8HixYuZMWOG1aGIiIhIB1BbL2JveiZdRERERERExCaUpIuIiIiIiIjYhG53FxEREREREbEJ9aSLiIiIiIiI2ISSdBERERERERGbUJIuIiIiIiIiYhNK0kVERERERERsQkm6iIiIiIiIiE0oSRcRERERERGxCSXpIiIiIiIiIjahJF1ERERERETEJv4/a5ung5MLBaQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp23.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp23.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp23.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp23.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lR_5oviqMrk"
   },
   "source": [
    "## 2-4. (16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "xshgj9pkqMrt"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "xFEe2jFMqMrt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=16, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp24_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ff6yIKoKqMrt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp24_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnmdfI4IqMrt",
    "outputId": "5dfaba72-17c4-43c5-cb56-3d97fab48549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11442     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55362     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101506    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184450    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350466    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1290754   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2174978   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2171394   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20209432 (77.09 MB)\n",
      "Trainable params: 1290672 (4.92 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp24_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F00Ij82-qMrt",
    "outputId": "733b2d50-d566-473c-a57e-2673a6b34b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9648\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18432\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27648\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp24_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "iXZC49h7qMru"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp24_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "HNE35A0EqMru"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "zeLLoQGzqMru"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "e6Dj91ILqMru"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp24_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3AQTPMJ_GOG"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gp_zFeAtqMru",
    "outputId": "6c9405b4-b137-43f6-b646-2914a05ab6a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9631\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 71s 37ms/step - loss: 0.1160 - accuracy: 0.9631 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9705\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.0935 - accuracy: 0.9705 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9336\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.2071 - accuracy: 0.9336 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.8735\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.3889 - accuracy: 0.8735 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.8342\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.302607536315918, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.5147 - accuracy: 0.8342 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.7932\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.302593469619751, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.6434 - accuracy: 0.7932 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7551 - accuracy: 0.7559\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3026106357574463, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.7551 - accuracy: 0.7559 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 0.8793 - accuracy: 0.7156\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.302622079849243, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.8794 - accuracy: 0.7156 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.6696\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.3026015758514404, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.0228 - accuracy: 0.6696 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1431 - accuracy: 0.6282\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.302344560623169, acc: 0.10520000010728836\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.1431 - accuracy: 0.6282 - val_loss: 2.3023 - val_accuracy: 0.1052\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2495 - accuracy: 0.5901\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.301020622253418, acc: 0.10819999873638153\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 1.2495 - accuracy: 0.5901 - val_loss: 2.3010 - val_accuracy: 0.1082\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3650 - accuracy: 0.5503\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.542207717895508, acc: 0.09759999811649323\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 1.3650 - accuracy: 0.5503 - val_loss: 2.5421 - val_accuracy: 0.0976\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.4581 - accuracy: 0.5131\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 2.683946371078491, acc: 0.10050000250339508\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.4581 - accuracy: 0.5131 - val_loss: 2.6841 - val_accuracy: 0.1005\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0588 - accuracy: 0.6631\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.286025285720825, acc: 0.13840000331401825\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 1.0588 - accuracy: 0.6631 - val_loss: 2.2860 - val_accuracy: 0.1384\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7569\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.1952412128448486, acc: 0.27000001072883606\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.7137 - accuracy: 0.7569 - val_loss: 2.1953 - val_accuracy: 0.2697\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.7702\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.9361207485198975, acc: 0.41429999470710754\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.6743 - accuracy: 0.7702 - val_loss: 1.9361 - val_accuracy: 0.4145\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.7739\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.5150330066680908, acc: 0.5335000157356262\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.6648 - accuracy: 0.7739 - val_loss: 1.5150 - val_accuracy: 0.5335\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.7739\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.8055887222290039, acc: 0.7382000088691711\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.6738 - accuracy: 0.7739 - val_loss: 0.8056 - val_accuracy: 0.7384\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.7801\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7653281688690186, acc: 0.7487999796867371\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.6584 - accuracy: 0.7801 - val_loss: 0.7653 - val_accuracy: 0.7487\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.8041\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7815415859222412, acc: 0.7504000067710876\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.5868 - accuracy: 0.8041 - val_loss: 0.7816 - val_accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "history_exp24 = exp24_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNJCmN8QgDiO",
    "outputId": "3271cf74-8f7e-4df8-b312-c82ab08411c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.7815 - accuracy: 0.7504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7815415859222412, 0.7504000067710876]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp24_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "IrLS0MAbqMru",
    "outputId": "22068cd4-89fd-4c4d-ffb1-a668afcb98b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp24.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp24.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp24.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp24.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05hTVBWz_a7Q"
   },
   "source": [
    "## 2-5. (16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "yAMaW8tq_a7a"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "yQEGKcv1_a7a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=32, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp25_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "_Nx7V_RG_a7a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp25_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QISgWsIB_a7b",
    "outputId": "9bf246a7-26c8-4736-99bc-10025af36a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11442     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55362     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101506    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184450    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350466    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1290754   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2248706   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2245122   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20356888 (77.66 MB)\n",
      "Trainable params: 1438128 (5.49 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp25_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E9kf2WU_a7b",
    "outputId": "8fa986a4-a1bb-4f36-d895-a4e64b55303a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9648\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18432\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27648\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp25_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "kuMPWKdD_a7b"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp25_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "2er5vDY4_a7b"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "Pw6efjC2_a7c"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "ENCdYvNn_a7c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp25_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_LWfZn7_a7c"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ubx3l9if_a7c",
    "outputId": "6af5d9b7-585a-4601-e9ba-ba872ba0788d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9639\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 69s 36ms/step - loss: 0.1150 - accuracy: 0.9639 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9705\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.0911 - accuracy: 0.9705 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.9328\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.2069 - accuracy: 0.9328 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8767\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302607536315918, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.3799 - accuracy: 0.8767 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.8331\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3026087284088135, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.5133 - accuracy: 0.8331 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.7956\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.302605152130127, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.6282 - accuracy: 0.7956 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7534 - accuracy: 0.7551\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3025155067443848, acc: 0.09709999710321426\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.7534 - accuracy: 0.7551 - val_loss: 2.3025 - val_accuracy: 0.0971\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.7187\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3026745319366455, acc: 0.09870000183582306\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.8687 - accuracy: 0.7187 - val_loss: 2.3027 - val_accuracy: 0.0987\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.6824\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.303105115890503, acc: 0.09989999979734421\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.9826 - accuracy: 0.6824 - val_loss: 2.3031 - val_accuracy: 0.0999\n",
      "Epoch 10/20\n",
      "1666/1667 [============================>.] - ETA: 0s - loss: 1.0947 - accuracy: 0.6403\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3060483932495117, acc: 0.0934000015258789\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.0945 - accuracy: 0.6403 - val_loss: 2.3060 - val_accuracy: 0.0933\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1980 - accuracy: 0.6027\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.4811861515045166, acc: 0.09989999979734421\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.1980 - accuracy: 0.6027 - val_loss: 2.4811 - val_accuracy: 0.0999\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2940 - accuracy: 0.5700\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.7049005031585693, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 1.2940 - accuracy: 0.5700 - val_loss: 2.7047 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3882 - accuracy: 0.5344\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 2.8138792514801025, acc: 0.07909999787807465\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.3882 - accuracy: 0.5344 - val_loss: 2.8138 - val_accuracy: 0.0791\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9305 - accuracy: 0.6867\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.26102352142334, acc: 0.18289999663829803\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.9305 - accuracy: 0.6867 - val_loss: 2.2610 - val_accuracy: 0.1827\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6727 - accuracy: 0.7702\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.180492877960205, acc: 0.3192000091075897\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6727 - accuracy: 0.7702 - val_loss: 2.1805 - val_accuracy: 0.3189\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.7838\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.9964900016784668, acc: 0.3734999895095825\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6364 - accuracy: 0.7838 - val_loss: 1.9965 - val_accuracy: 0.3735\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.7874\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.3581163883209229, acc: 0.5942000150680542\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.6234 - accuracy: 0.7874 - val_loss: 1.3581 - val_accuracy: 0.5940\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.7897\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.808661937713623, acc: 0.7376000285148621\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6232 - accuracy: 0.7897 - val_loss: 0.8087 - val_accuracy: 0.7377\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.7960\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7819057106971741, acc: 0.7506999969482422\n",
      "\n",
      "1667/1667 [==============================] - 61s 36ms/step - loss: 0.6064 - accuracy: 0.7960 - val_loss: 0.7819 - val_accuracy: 0.7508\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.8179\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7950417399406433, acc: 0.7465000152587891\n",
      "\n",
      "1667/1667 [==============================] - 61s 36ms/step - loss: 0.5476 - accuracy: 0.8179 - val_loss: 0.7951 - val_accuracy: 0.7464\n"
     ]
    }
   ],
   "source": [
    "history_exp25 = exp25_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "LAh8O2E__a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.7950 - accuracy: 0.7465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7950417399406433, 0.7465000152587891]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp25_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "GFAWHfeB_a7c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp25.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp25.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp25.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp25.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mqm8sMZACK3"
   },
   "source": [
    "## 2-6. (16, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "wj2k2FjkACK_"
   },
   "outputs": [],
   "source": [
    "dataset_size = x_train.shape[0]\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "\n",
    "total_iteration= int(epochs * (dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "VvfLtCIcACK_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, InputLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 새로운 레이어를 추가하기 위한 레이어 리스트 초기화\n",
    "new_layers = []\n",
    "\n",
    "# Dense 레이어 카운터\n",
    "dense_layer_count = 0\n",
    "\n",
    "# VGG 모델의 각 레이어 순회\n",
    "for layer in best_vgg16.layers:\n",
    "    if isinstance(layer, InputLayer):\n",
    "        continue\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Conv2D 레이어를 ConvLoRALayer로 대체\n",
    "        conv_lora_layer = ConvLoRALayer00_cdn2(original_conv_layer=layer, rank=16, alpha=32, total_iteration = total_iteration, trainable=True)\n",
    "        new_layers.append(conv_lora_layer)\n",
    "    elif isinstance(layer, Dense):\n",
    "        dense_layer_count += 1\n",
    "        # 첫 번째와 두 번째 Dense 레이어에만 LoraLayer 적용\n",
    "        if dense_layer_count in [1, 2]:\n",
    "            dense_lora_layer = LoraLayer(original_layer=layer, rank=64, alpha=32, total_iteration=total_iteration, trainable=True)\n",
    "            new_layers.append(dense_lora_layer)\n",
    "        else:\n",
    "            new_layers.append(layer)  # 그대로 유지함\n",
    "    else:\n",
    "        # 다른 유형의 레이어는 그대로 유지\n",
    "        new_layers.append(layer)\n",
    "\n",
    "# 새로운 입력 텐서 생성\n",
    "input_tensor = best_vgg16.input\n",
    "\n",
    "# 새로운 모델 구성\n",
    "x = input_tensor\n",
    "for layer in new_layers:\n",
    "    x = layer(x)\n",
    "\n",
    "# 새로운 모델 생성\n",
    "exp26_lora_vgg16 = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "yZSvkVUZACK_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "# 새로 생성된 모델에서 Dense 레이어 중 LoRA가 적용되지 않은 레이어의 trainable을 False로 설정\n",
    "for layer in exp26_lora_vgg16.layers:\n",
    "    if isinstance(layer, Dense) and not isinstance(layer, LoraLayer):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "587UuheQACK_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (ConvLoRALaye  (None, 32, 32, 64)        11442     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_conv2 (ConvLoRALaye  (None, 32, 32, 64)        55362     \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (ConvLoRALaye  (None, 16, 16, 128)       101506    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_conv2 (ConvLoRALaye  (None, 16, 16, 128)       184450    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (ConvLoRALaye  (None, 8, 8, 256)         350466    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv2 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_conv3 (ConvLoRALaye  (None, 8, 8, 256)         663810    \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (ConvLoRALaye  (None, 4, 4, 512)         1290754   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv2 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_conv3 (ConvLoRALaye  (None, 4, 4, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv2 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_conv3 (ConvLoRALaye  (None, 2, 2, 512)         2507266   \n",
      " r00_cdn2)                                                       \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (LoraLayer)         (None, 4096)              2396162   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (LoraLayer)         (None, 512)               2392578   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20651800 (78.78 MB)\n",
      "Trainable params: 1733040 (6.61 MB)\n",
      "Non-trainable params: 18918760 (72.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp26_lora_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "ugu_3sPBACK_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_3\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block1_conv1\n",
      "  Trainable parameters: 9648\n",
      "  Non-trainable parameters: 1794\n",
      "Layer: block1_conv2\n",
      "  Trainable parameters: 18432\n",
      "  Non-trainable parameters: 36930\n",
      "Layer: block1_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block2_conv1\n",
      "  Trainable parameters: 27648\n",
      "  Non-trainable parameters: 73858\n",
      "Layer: block2_conv2\n",
      "  Trainable parameters: 36864\n",
      "  Non-trainable parameters: 147586\n",
      "Layer: block2_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block3_conv1\n",
      "  Trainable parameters: 55296\n",
      "  Non-trainable parameters: 295170\n",
      "Layer: block3_conv2\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_conv3\n",
      "  Trainable parameters: 73728\n",
      "  Non-trainable parameters: 590082\n",
      "Layer: block3_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block4_conv1\n",
      "  Trainable parameters: 110592\n",
      "  Non-trainable parameters: 1180162\n",
      "Layer: block4_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block4_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: block5_conv1\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv2\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_conv3\n",
      "  Trainable parameters: 147456\n",
      "  Non-trainable parameters: 2359810\n",
      "Layer: block5_pool\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: flatten_2\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_6\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2101250\n",
      "Layer: dropout_4\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_7\n",
      "  Trainable parameters: 294912\n",
      "  Non-trainable parameters: 2097666\n",
      "Layer: dropout_5\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 0.0\n",
      "Layer: dense_8\n",
      "  Trainable parameters: 0.0\n",
      "  Non-trainable parameters: 5130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#모델의 각 레이어를 순회하며 파라미터 수를 계산\n",
    "for layer in exp26_lora_vgg16.layers:\n",
    "    trainable_count = np.sum([tf.size(w).numpy() for w in layer.trainable_weights])\n",
    "    non_trainable_count = np.sum([tf.size(w).numpy() for w in layer.non_trainable_weights])\n",
    "\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"  Trainable parameters: {trainable_count}\")\n",
    "    print(f\"  Non-trainable parameters: {non_trainable_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "QIRBl6_HACLA"
   },
   "outputs": [],
   "source": [
    "lora_layers = []  # lora 레이어들을 저장할 리스트\n",
    "\n",
    "for layer in exp26_lora_vgg16.layers:\n",
    "    if isinstance(layer, LoraLayer) or isinstance(layer, ConvLoRALayer00_cdn2):\n",
    "        lora_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "rQLsY-jCACLA"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class PrintCurrentStepCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, lora_layers):\n",
    "        super().__init__()\n",
    "        self.lora_layers = lora_layers\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print()\n",
    "        for i, lora_layer in enumerate(self.lora_layers):\n",
    "            current_step = lora_layer.current_step.value()\n",
    "            decay_factor = lora_layer.decay_factor.value()\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: {current_step} Step\")\n",
    "            print(f\"End of epoch {epoch + 1}, LoraLayer {i}: Decay factor: {decay_factor}\")\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "i5VDOlyHACLA"
   },
   "outputs": [],
   "source": [
    "# 콜백 생성 시 lora_layers 딕셔너리의 값만 사용\n",
    "print_step_callback = PrintCurrentStepCallback(lora_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "mYnT-xGlACLA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 컴파일\n",
    "exp26_lora_vgg16.compile(optimizer=Adam(learning_rate=0.00005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU49T8ueACLA"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "Vw3LrTXoACLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9636\n",
      "End of epoch 1, LoraLayer 0: 1667 Step\n",
      "End of epoch 1, LoraLayer 0: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 1: 1667 Step\n",
      "End of epoch 1, LoraLayer 1: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 2: 1667 Step\n",
      "End of epoch 1, LoraLayer 2: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 3: 1667 Step\n",
      "End of epoch 1, LoraLayer 3: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 4: 1667 Step\n",
      "End of epoch 1, LoraLayer 4: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 5: 1667 Step\n",
      "End of epoch 1, LoraLayer 5: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 6: 1667 Step\n",
      "End of epoch 1, LoraLayer 6: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 7: 1667 Step\n",
      "End of epoch 1, LoraLayer 7: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 8: 1667 Step\n",
      "End of epoch 1, LoraLayer 8: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 9: 1667 Step\n",
      "End of epoch 1, LoraLayer 9: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 10: 1667 Step\n",
      "End of epoch 1, LoraLayer 10: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 11: 1667 Step\n",
      "End of epoch 1, LoraLayer 11: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 12: 1667 Step\n",
      "End of epoch 1, LoraLayer 12: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 13: 1667 Step\n",
      "End of epoch 1, LoraLayer 13: Decay factor: 1.0\n",
      "End of epoch 1, LoraLayer 14: 1667 Step\n",
      "End of epoch 1, LoraLayer 14: Decay factor: 1.0\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 68s 35ms/step - loss: 0.1145 - accuracy: 0.9636 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9699\n",
      "End of epoch 2, LoraLayer 0: 3334 Step\n",
      "End of epoch 2, LoraLayer 0: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 1: 3334 Step\n",
      "End of epoch 2, LoraLayer 1: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 2: 3334 Step\n",
      "End of epoch 2, LoraLayer 2: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 3: 3334 Step\n",
      "End of epoch 2, LoraLayer 3: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 4: 3334 Step\n",
      "End of epoch 2, LoraLayer 4: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 5: 3334 Step\n",
      "End of epoch 2, LoraLayer 5: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 6: 3334 Step\n",
      "End of epoch 2, LoraLayer 6: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 7: 3334 Step\n",
      "End of epoch 2, LoraLayer 7: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 8: 3334 Step\n",
      "End of epoch 2, LoraLayer 8: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 9: 3334 Step\n",
      "End of epoch 2, LoraLayer 9: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 10: 3334 Step\n",
      "End of epoch 2, LoraLayer 10: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 11: 3334 Step\n",
      "End of epoch 2, LoraLayer 11: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 12: 3334 Step\n",
      "End of epoch 2, LoraLayer 12: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 13: 3334 Step\n",
      "End of epoch 2, LoraLayer 13: Decay factor: 0.9999625086784363\n",
      "End of epoch 2, LoraLayer 14: 3334 Step\n",
      "End of epoch 2, LoraLayer 14: Decay factor: 0.9999625086784363\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 36ms/step - loss: 0.0929 - accuracy: 0.9699 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9346\n",
      "End of epoch 3, LoraLayer 0: 5001 Step\n",
      "End of epoch 3, LoraLayer 0: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 1: 5001 Step\n",
      "End of epoch 3, LoraLayer 1: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 2: 5001 Step\n",
      "End of epoch 3, LoraLayer 2: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 3: 5001 Step\n",
      "End of epoch 3, LoraLayer 3: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 4: 5001 Step\n",
      "End of epoch 3, LoraLayer 4: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 5: 5001 Step\n",
      "End of epoch 3, LoraLayer 5: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 6: 5001 Step\n",
      "End of epoch 3, LoraLayer 6: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 7: 5001 Step\n",
      "End of epoch 3, LoraLayer 7: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 8: 5001 Step\n",
      "End of epoch 3, LoraLayer 8: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 9: 5001 Step\n",
      "End of epoch 3, LoraLayer 9: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 10: 5001 Step\n",
      "End of epoch 3, LoraLayer 10: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 11: 5001 Step\n",
      "End of epoch 3, LoraLayer 11: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 12: 5001 Step\n",
      "End of epoch 3, LoraLayer 12: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 13: 5001 Step\n",
      "End of epoch 3, LoraLayer 13: Decay factor: 0.9374484419822693\n",
      "End of epoch 3, LoraLayer 14: 5001 Step\n",
      "End of epoch 3, LoraLayer 14: Decay factor: 0.9374484419822693\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.2023 - accuracy: 0.9346 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.8761\n",
      "End of epoch 4, LoraLayer 0: 6668 Step\n",
      "End of epoch 4, LoraLayer 0: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 1: 6668 Step\n",
      "End of epoch 4, LoraLayer 1: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 2: 6668 Step\n",
      "End of epoch 4, LoraLayer 2: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 3: 6668 Step\n",
      "End of epoch 4, LoraLayer 3: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 4: 6668 Step\n",
      "End of epoch 4, LoraLayer 4: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 5: 6668 Step\n",
      "End of epoch 4, LoraLayer 5: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 6: 6668 Step\n",
      "End of epoch 4, LoraLayer 6: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 7: 6668 Step\n",
      "End of epoch 4, LoraLayer 7: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 8: 6668 Step\n",
      "End of epoch 4, LoraLayer 8: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 9: 6668 Step\n",
      "End of epoch 4, LoraLayer 9: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 10: 6668 Step\n",
      "End of epoch 4, LoraLayer 10: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 11: 6668 Step\n",
      "End of epoch 4, LoraLayer 11: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 12: 6668 Step\n",
      "End of epoch 4, LoraLayer 12: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 13: 6668 Step\n",
      "End of epoch 4, LoraLayer 13: Decay factor: 0.8749343752861023\n",
      "End of epoch 4, LoraLayer 14: 6668 Step\n",
      "End of epoch 4, LoraLayer 14: Decay factor: 0.8749343752861023\n",
      "\n",
      "Testing loss: 2.302607297897339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 0.3778 - accuracy: 0.8761 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.4999 - accuracy: 0.8374\n",
      "End of epoch 5, LoraLayer 0: 8335 Step\n",
      "End of epoch 5, LoraLayer 0: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 1: 8335 Step\n",
      "End of epoch 5, LoraLayer 1: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 2: 8335 Step\n",
      "End of epoch 5, LoraLayer 2: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 3: 8335 Step\n",
      "End of epoch 5, LoraLayer 3: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 4: 8335 Step\n",
      "End of epoch 5, LoraLayer 4: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 5: 8335 Step\n",
      "End of epoch 5, LoraLayer 5: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 6: 8335 Step\n",
      "End of epoch 5, LoraLayer 6: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 7: 8335 Step\n",
      "End of epoch 5, LoraLayer 7: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 8: 8335 Step\n",
      "End of epoch 5, LoraLayer 8: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 9: 8335 Step\n",
      "End of epoch 5, LoraLayer 9: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 10: 8335 Step\n",
      "End of epoch 5, LoraLayer 10: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 11: 8335 Step\n",
      "End of epoch 5, LoraLayer 11: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 12: 8335 Step\n",
      "End of epoch 5, LoraLayer 12: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 13: 8335 Step\n",
      "End of epoch 5, LoraLayer 13: Decay factor: 0.8124203085899353\n",
      "End of epoch 5, LoraLayer 14: 8335 Step\n",
      "End of epoch 5, LoraLayer 14: Decay factor: 0.8124203085899353\n",
      "\n",
      "Testing loss: 2.3026068210601807, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.4999 - accuracy: 0.8374 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.7970\n",
      "End of epoch 6, LoraLayer 0: 10002 Step\n",
      "End of epoch 6, LoraLayer 0: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 1: 10002 Step\n",
      "End of epoch 6, LoraLayer 1: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 2: 10002 Step\n",
      "End of epoch 6, LoraLayer 2: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 3: 10002 Step\n",
      "End of epoch 6, LoraLayer 3: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 4: 10002 Step\n",
      "End of epoch 6, LoraLayer 4: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 5: 10002 Step\n",
      "End of epoch 6, LoraLayer 5: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 6: 10002 Step\n",
      "End of epoch 6, LoraLayer 6: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 7: 10002 Step\n",
      "End of epoch 6, LoraLayer 7: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 8: 10002 Step\n",
      "End of epoch 6, LoraLayer 8: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 9: 10002 Step\n",
      "End of epoch 6, LoraLayer 9: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 10: 10002 Step\n",
      "End of epoch 6, LoraLayer 10: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 11: 10002 Step\n",
      "End of epoch 6, LoraLayer 11: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 12: 10002 Step\n",
      "End of epoch 6, LoraLayer 12: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 13: 10002 Step\n",
      "End of epoch 6, LoraLayer 13: Decay factor: 0.7499062418937683\n",
      "End of epoch 6, LoraLayer 14: 10002 Step\n",
      "End of epoch 6, LoraLayer 14: Decay factor: 0.7499062418937683\n",
      "\n",
      "Testing loss: 2.302588939666748, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6214 - accuracy: 0.7970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.7347 - accuracy: 0.7596\n",
      "End of epoch 7, LoraLayer 0: 11669 Step\n",
      "End of epoch 7, LoraLayer 0: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 1: 11669 Step\n",
      "End of epoch 7, LoraLayer 1: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 2: 11669 Step\n",
      "End of epoch 7, LoraLayer 2: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 3: 11669 Step\n",
      "End of epoch 7, LoraLayer 3: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 4: 11669 Step\n",
      "End of epoch 7, LoraLayer 4: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 5: 11669 Step\n",
      "End of epoch 7, LoraLayer 5: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 6: 11669 Step\n",
      "End of epoch 7, LoraLayer 6: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 7: 11669 Step\n",
      "End of epoch 7, LoraLayer 7: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 8: 11669 Step\n",
      "End of epoch 7, LoraLayer 8: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 9: 11669 Step\n",
      "End of epoch 7, LoraLayer 9: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 10: 11669 Step\n",
      "End of epoch 7, LoraLayer 10: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 11: 11669 Step\n",
      "End of epoch 7, LoraLayer 11: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 12: 11669 Step\n",
      "End of epoch 7, LoraLayer 12: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 13: 11669 Step\n",
      "End of epoch 7, LoraLayer 13: Decay factor: 0.6873922348022461\n",
      "End of epoch 7, LoraLayer 14: 11669 Step\n",
      "End of epoch 7, LoraLayer 14: Decay factor: 0.6873922348022461\n",
      "\n",
      "Testing loss: 2.3026340007781982, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.7347 - accuracy: 0.7596 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.8469 - accuracy: 0.7230\n",
      "End of epoch 8, LoraLayer 0: 13336 Step\n",
      "End of epoch 8, LoraLayer 0: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 1: 13336 Step\n",
      "End of epoch 8, LoraLayer 1: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 2: 13336 Step\n",
      "End of epoch 8, LoraLayer 2: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 3: 13336 Step\n",
      "End of epoch 8, LoraLayer 3: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 4: 13336 Step\n",
      "End of epoch 8, LoraLayer 4: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 5: 13336 Step\n",
      "End of epoch 8, LoraLayer 5: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 6: 13336 Step\n",
      "End of epoch 8, LoraLayer 6: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 7: 13336 Step\n",
      "End of epoch 8, LoraLayer 7: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 8: 13336 Step\n",
      "End of epoch 8, LoraLayer 8: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 9: 13336 Step\n",
      "End of epoch 8, LoraLayer 9: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 10: 13336 Step\n",
      "End of epoch 8, LoraLayer 10: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 11: 13336 Step\n",
      "End of epoch 8, LoraLayer 11: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 12: 13336 Step\n",
      "End of epoch 8, LoraLayer 12: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 13: 13336 Step\n",
      "End of epoch 8, LoraLayer 13: Decay factor: 0.6248781681060791\n",
      "End of epoch 8, LoraLayer 14: 13336 Step\n",
      "End of epoch 8, LoraLayer 14: Decay factor: 0.6248781681060791\n",
      "\n",
      "Testing loss: 2.3018691539764404, acc: 0.10790000110864639\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.8469 - accuracy: 0.7230 - val_loss: 2.3019 - val_accuracy: 0.1079\n",
      "Epoch 9/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9578 - accuracy: 0.6850\n",
      "End of epoch 9, LoraLayer 0: 15003 Step\n",
      "End of epoch 9, LoraLayer 0: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 1: 15003 Step\n",
      "End of epoch 9, LoraLayer 1: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 2: 15003 Step\n",
      "End of epoch 9, LoraLayer 2: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 3: 15003 Step\n",
      "End of epoch 9, LoraLayer 3: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 4: 15003 Step\n",
      "End of epoch 9, LoraLayer 4: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 5: 15003 Step\n",
      "End of epoch 9, LoraLayer 5: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 6: 15003 Step\n",
      "End of epoch 9, LoraLayer 6: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 7: 15003 Step\n",
      "End of epoch 9, LoraLayer 7: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 8: 15003 Step\n",
      "End of epoch 9, LoraLayer 8: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 9: 15003 Step\n",
      "End of epoch 9, LoraLayer 9: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 10: 15003 Step\n",
      "End of epoch 9, LoraLayer 10: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 11: 15003 Step\n",
      "End of epoch 9, LoraLayer 11: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 12: 15003 Step\n",
      "End of epoch 9, LoraLayer 12: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 13: 15003 Step\n",
      "End of epoch 9, LoraLayer 13: Decay factor: 0.5623641014099121\n",
      "End of epoch 9, LoraLayer 14: 15003 Step\n",
      "End of epoch 9, LoraLayer 14: Decay factor: 0.5623641014099121\n",
      "\n",
      "Testing loss: 2.325556516647339, acc: 0.10000000149011612\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.9578 - accuracy: 0.6850 - val_loss: 2.3256 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.0618 - accuracy: 0.6499\n",
      "End of epoch 10, LoraLayer 0: 16670 Step\n",
      "End of epoch 10, LoraLayer 0: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 1: 16670 Step\n",
      "End of epoch 10, LoraLayer 1: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 2: 16670 Step\n",
      "End of epoch 10, LoraLayer 2: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 3: 16670 Step\n",
      "End of epoch 10, LoraLayer 3: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 4: 16670 Step\n",
      "End of epoch 10, LoraLayer 4: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 5: 16670 Step\n",
      "End of epoch 10, LoraLayer 5: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 6: 16670 Step\n",
      "End of epoch 10, LoraLayer 6: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 7: 16670 Step\n",
      "End of epoch 10, LoraLayer 7: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 8: 16670 Step\n",
      "End of epoch 10, LoraLayer 8: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 9: 16670 Step\n",
      "End of epoch 10, LoraLayer 9: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 10: 16670 Step\n",
      "End of epoch 10, LoraLayer 10: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 11: 16670 Step\n",
      "End of epoch 10, LoraLayer 11: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 12: 16670 Step\n",
      "End of epoch 10, LoraLayer 12: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 13: 16670 Step\n",
      "End of epoch 10, LoraLayer 13: Decay factor: 0.4998500347137451\n",
      "End of epoch 10, LoraLayer 14: 16670 Step\n",
      "End of epoch 10, LoraLayer 14: Decay factor: 0.4998500347137451\n",
      "\n",
      "Testing loss: 2.3017406463623047, acc: 0.093299999833107\n",
      "\n",
      "1667/1667 [==============================] - 61s 37ms/step - loss: 1.0618 - accuracy: 0.6499 - val_loss: 2.3018 - val_accuracy: 0.0932\n",
      "Epoch 11/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.1615 - accuracy: 0.6149\n",
      "End of epoch 11, LoraLayer 0: 18337 Step\n",
      "End of epoch 11, LoraLayer 0: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 1: 18337 Step\n",
      "End of epoch 11, LoraLayer 1: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 2: 18337 Step\n",
      "End of epoch 11, LoraLayer 2: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 3: 18337 Step\n",
      "End of epoch 11, LoraLayer 3: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 4: 18337 Step\n",
      "End of epoch 11, LoraLayer 4: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 5: 18337 Step\n",
      "End of epoch 11, LoraLayer 5: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 6: 18337 Step\n",
      "End of epoch 11, LoraLayer 6: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 7: 18337 Step\n",
      "End of epoch 11, LoraLayer 7: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 8: 18337 Step\n",
      "End of epoch 11, LoraLayer 8: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 9: 18337 Step\n",
      "End of epoch 11, LoraLayer 9: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 10: 18337 Step\n",
      "End of epoch 11, LoraLayer 10: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 11: 18337 Step\n",
      "End of epoch 11, LoraLayer 11: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 12: 18337 Step\n",
      "End of epoch 11, LoraLayer 12: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 13: 18337 Step\n",
      "End of epoch 11, LoraLayer 13: Decay factor: 0.4373359680175781\n",
      "End of epoch 11, LoraLayer 14: 18337 Step\n",
      "End of epoch 11, LoraLayer 14: Decay factor: 0.4373359680175781\n",
      "\n",
      "Testing loss: 2.3503377437591553, acc: 0.11400000005960464\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.1615 - accuracy: 0.6149 - val_loss: 2.3504 - val_accuracy: 0.1140\n",
      "Epoch 12/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.2714 - accuracy: 0.5764\n",
      "End of epoch 12, LoraLayer 0: 20004 Step\n",
      "End of epoch 12, LoraLayer 0: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 1: 20004 Step\n",
      "End of epoch 12, LoraLayer 1: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 2: 20004 Step\n",
      "End of epoch 12, LoraLayer 2: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 3: 20004 Step\n",
      "End of epoch 12, LoraLayer 3: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 4: 20004 Step\n",
      "End of epoch 12, LoraLayer 4: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 5: 20004 Step\n",
      "End of epoch 12, LoraLayer 5: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 6: 20004 Step\n",
      "End of epoch 12, LoraLayer 6: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 7: 20004 Step\n",
      "End of epoch 12, LoraLayer 7: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 8: 20004 Step\n",
      "End of epoch 12, LoraLayer 8: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 9: 20004 Step\n",
      "End of epoch 12, LoraLayer 9: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 10: 20004 Step\n",
      "End of epoch 12, LoraLayer 10: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 11: 20004 Step\n",
      "End of epoch 12, LoraLayer 11: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 12: 20004 Step\n",
      "End of epoch 12, LoraLayer 12: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 13: 20004 Step\n",
      "End of epoch 12, LoraLayer 13: Decay factor: 0.37482190132141113\n",
      "End of epoch 12, LoraLayer 14: 20004 Step\n",
      "End of epoch 12, LoraLayer 14: Decay factor: 0.37482190132141113\n",
      "\n",
      "Testing loss: 2.326859474182129, acc: 0.11069999635219574\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 1.2714 - accuracy: 0.5764 - val_loss: 2.3269 - val_accuracy: 0.1107\n",
      "Epoch 13/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 1.3463 - accuracy: 0.5445\n",
      "End of epoch 13, LoraLayer 0: 21671 Step\n",
      "End of epoch 13, LoraLayer 0: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 1: 21671 Step\n",
      "End of epoch 13, LoraLayer 1: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 2: 21671 Step\n",
      "End of epoch 13, LoraLayer 2: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 3: 21671 Step\n",
      "End of epoch 13, LoraLayer 3: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 4: 21671 Step\n",
      "End of epoch 13, LoraLayer 4: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 5: 21671 Step\n",
      "End of epoch 13, LoraLayer 5: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 6: 21671 Step\n",
      "End of epoch 13, LoraLayer 6: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 7: 21671 Step\n",
      "End of epoch 13, LoraLayer 7: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 8: 21671 Step\n",
      "End of epoch 13, LoraLayer 8: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 9: 21671 Step\n",
      "End of epoch 13, LoraLayer 9: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 10: 21671 Step\n",
      "End of epoch 13, LoraLayer 10: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 11: 21671 Step\n",
      "End of epoch 13, LoraLayer 11: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 12: 21671 Step\n",
      "End of epoch 13, LoraLayer 12: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 13: 21671 Step\n",
      "End of epoch 13, LoraLayer 13: Decay factor: 0.31230783462524414\n",
      "End of epoch 13, LoraLayer 14: 21671 Step\n",
      "End of epoch 13, LoraLayer 14: Decay factor: 0.31230783462524414\n",
      "\n",
      "Testing loss: 2.8932886123657227, acc: 0.10459999740123749\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 1.3463 - accuracy: 0.5445 - val_loss: 2.8933 - val_accuracy: 0.1046\n",
      "Epoch 14/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.6859\n",
      "End of epoch 14, LoraLayer 0: 23338 Step\n",
      "End of epoch 14, LoraLayer 0: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 1: 23338 Step\n",
      "End of epoch 14, LoraLayer 1: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 2: 23338 Step\n",
      "End of epoch 14, LoraLayer 2: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 3: 23338 Step\n",
      "End of epoch 14, LoraLayer 3: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 4: 23338 Step\n",
      "End of epoch 14, LoraLayer 4: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 5: 23338 Step\n",
      "End of epoch 14, LoraLayer 5: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 6: 23338 Step\n",
      "End of epoch 14, LoraLayer 6: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 7: 23338 Step\n",
      "End of epoch 14, LoraLayer 7: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 8: 23338 Step\n",
      "End of epoch 14, LoraLayer 8: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 9: 23338 Step\n",
      "End of epoch 14, LoraLayer 9: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 10: 23338 Step\n",
      "End of epoch 14, LoraLayer 10: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 11: 23338 Step\n",
      "End of epoch 14, LoraLayer 11: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 12: 23338 Step\n",
      "End of epoch 14, LoraLayer 12: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 13: 23338 Step\n",
      "End of epoch 14, LoraLayer 13: Decay factor: 0.24979376792907715\n",
      "End of epoch 14, LoraLayer 14: 23338 Step\n",
      "End of epoch 14, LoraLayer 14: Decay factor: 0.24979376792907715\n",
      "\n",
      "Testing loss: 2.3665547370910645, acc: 0.1598999947309494\n",
      "\n",
      "1667/1667 [==============================] - 64s 38ms/step - loss: 0.9746 - accuracy: 0.6859 - val_loss: 2.3666 - val_accuracy: 0.1599\n",
      "Epoch 15/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.7713\n",
      "End of epoch 15, LoraLayer 0: 25005 Step\n",
      "End of epoch 15, LoraLayer 0: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 1: 25005 Step\n",
      "End of epoch 15, LoraLayer 1: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 2: 25005 Step\n",
      "End of epoch 15, LoraLayer 2: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 3: 25005 Step\n",
      "End of epoch 15, LoraLayer 3: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 4: 25005 Step\n",
      "End of epoch 15, LoraLayer 4: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 5: 25005 Step\n",
      "End of epoch 15, LoraLayer 5: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 6: 25005 Step\n",
      "End of epoch 15, LoraLayer 6: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 7: 25005 Step\n",
      "End of epoch 15, LoraLayer 7: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 8: 25005 Step\n",
      "End of epoch 15, LoraLayer 8: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 9: 25005 Step\n",
      "End of epoch 15, LoraLayer 9: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 10: 25005 Step\n",
      "End of epoch 15, LoraLayer 10: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 11: 25005 Step\n",
      "End of epoch 15, LoraLayer 11: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 12: 25005 Step\n",
      "End of epoch 15, LoraLayer 12: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 13: 25005 Step\n",
      "End of epoch 15, LoraLayer 13: Decay factor: 0.18727970123291016\n",
      "End of epoch 15, LoraLayer 14: 25005 Step\n",
      "End of epoch 15, LoraLayer 14: Decay factor: 0.18727970123291016\n",
      "\n",
      "Testing loss: 2.1746456623077393, acc: 0.26759999990463257\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6721 - accuracy: 0.7713 - val_loss: 2.1747 - val_accuracy: 0.2674\n",
      "Epoch 16/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.7823\n",
      "End of epoch 16, LoraLayer 0: 26672 Step\n",
      "End of epoch 16, LoraLayer 0: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 1: 26672 Step\n",
      "End of epoch 16, LoraLayer 1: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 2: 26672 Step\n",
      "End of epoch 16, LoraLayer 2: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 3: 26672 Step\n",
      "End of epoch 16, LoraLayer 3: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 4: 26672 Step\n",
      "End of epoch 16, LoraLayer 4: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 5: 26672 Step\n",
      "End of epoch 16, LoraLayer 5: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 6: 26672 Step\n",
      "End of epoch 16, LoraLayer 6: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 7: 26672 Step\n",
      "End of epoch 16, LoraLayer 7: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 8: 26672 Step\n",
      "End of epoch 16, LoraLayer 8: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 9: 26672 Step\n",
      "End of epoch 16, LoraLayer 9: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 10: 26672 Step\n",
      "End of epoch 16, LoraLayer 10: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 11: 26672 Step\n",
      "End of epoch 16, LoraLayer 11: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 12: 26672 Step\n",
      "End of epoch 16, LoraLayer 12: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 13: 26672 Step\n",
      "End of epoch 16, LoraLayer 13: Decay factor: 0.12476563453674316\n",
      "End of epoch 16, LoraLayer 14: 26672 Step\n",
      "End of epoch 16, LoraLayer 14: Decay factor: 0.12476563453674316\n",
      "\n",
      "Testing loss: 1.8663846254348755, acc: 0.41600000858306885\n",
      "\n",
      "1667/1667 [==============================] - 63s 38ms/step - loss: 0.6373 - accuracy: 0.7823 - val_loss: 1.8663 - val_accuracy: 0.4163\n",
      "Epoch 17/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.7884\n",
      "End of epoch 17, LoraLayer 0: 28339 Step\n",
      "End of epoch 17, LoraLayer 0: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 1: 28339 Step\n",
      "End of epoch 17, LoraLayer 1: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 2: 28339 Step\n",
      "End of epoch 17, LoraLayer 2: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 3: 28339 Step\n",
      "End of epoch 17, LoraLayer 3: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 4: 28339 Step\n",
      "End of epoch 17, LoraLayer 4: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 5: 28339 Step\n",
      "End of epoch 17, LoraLayer 5: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 6: 28339 Step\n",
      "End of epoch 17, LoraLayer 6: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 7: 28339 Step\n",
      "End of epoch 17, LoraLayer 7: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 8: 28339 Step\n",
      "End of epoch 17, LoraLayer 8: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 9: 28339 Step\n",
      "End of epoch 17, LoraLayer 9: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 10: 28339 Step\n",
      "End of epoch 17, LoraLayer 10: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 11: 28339 Step\n",
      "End of epoch 17, LoraLayer 11: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 12: 28339 Step\n",
      "End of epoch 17, LoraLayer 12: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 13: 28339 Step\n",
      "End of epoch 17, LoraLayer 13: Decay factor: 0.06225156784057617\n",
      "End of epoch 17, LoraLayer 14: 28339 Step\n",
      "End of epoch 17, LoraLayer 14: Decay factor: 0.06225156784057617\n",
      "\n",
      "Testing loss: 1.2925714254379272, acc: 0.644599974155426\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6209 - accuracy: 0.7884 - val_loss: 1.2925 - val_accuracy: 0.6445\n",
      "Epoch 18/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.7874\n",
      "End of epoch 18, LoraLayer 0: 30006 Step\n",
      "End of epoch 18, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 1: 30006 Step\n",
      "End of epoch 18, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 2: 30006 Step\n",
      "End of epoch 18, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 3: 30006 Step\n",
      "End of epoch 18, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 4: 30006 Step\n",
      "End of epoch 18, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 5: 30006 Step\n",
      "End of epoch 18, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 6: 30006 Step\n",
      "End of epoch 18, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 7: 30006 Step\n",
      "End of epoch 18, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 8: 30006 Step\n",
      "End of epoch 18, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 9: 30006 Step\n",
      "End of epoch 18, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 10: 30006 Step\n",
      "End of epoch 18, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 11: 30006 Step\n",
      "End of epoch 18, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 12: 30006 Step\n",
      "End of epoch 18, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 13: 30006 Step\n",
      "End of epoch 18, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 18, LoraLayer 14: 30006 Step\n",
      "End of epoch 18, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.8201044797897339, acc: 0.7379999756813049\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6269 - accuracy: 0.7874 - val_loss: 0.8201 - val_accuracy: 0.7381\n",
      "Epoch 19/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.7940\n",
      "End of epoch 19, LoraLayer 0: 31673 Step\n",
      "End of epoch 19, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 1: 31673 Step\n",
      "End of epoch 19, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 2: 31673 Step\n",
      "End of epoch 19, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 3: 31673 Step\n",
      "End of epoch 19, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 4: 31673 Step\n",
      "End of epoch 19, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 5: 31673 Step\n",
      "End of epoch 19, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 6: 31673 Step\n",
      "End of epoch 19, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 7: 31673 Step\n",
      "End of epoch 19, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 8: 31673 Step\n",
      "End of epoch 19, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 9: 31673 Step\n",
      "End of epoch 19, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 10: 31673 Step\n",
      "End of epoch 19, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 11: 31673 Step\n",
      "End of epoch 19, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 12: 31673 Step\n",
      "End of epoch 19, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 13: 31673 Step\n",
      "End of epoch 19, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 19, LoraLayer 14: 31673 Step\n",
      "End of epoch 19, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7646818161010742, acc: 0.7461000084877014\n",
      "\n",
      "1667/1667 [==============================] - 62s 37ms/step - loss: 0.6099 - accuracy: 0.7940 - val_loss: 0.7647 - val_accuracy: 0.7460\n",
      "Epoch 20/20\n",
      "1667/1667 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.8163\n",
      "End of epoch 20, LoraLayer 0: 33340 Step\n",
      "End of epoch 20, LoraLayer 0: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 1: 33340 Step\n",
      "End of epoch 20, LoraLayer 1: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 2: 33340 Step\n",
      "End of epoch 20, LoraLayer 2: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 3: 33340 Step\n",
      "End of epoch 20, LoraLayer 3: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 4: 33340 Step\n",
      "End of epoch 20, LoraLayer 4: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 5: 33340 Step\n",
      "End of epoch 20, LoraLayer 5: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 6: 33340 Step\n",
      "End of epoch 20, LoraLayer 6: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 7: 33340 Step\n",
      "End of epoch 20, LoraLayer 7: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 8: 33340 Step\n",
      "End of epoch 20, LoraLayer 8: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 9: 33340 Step\n",
      "End of epoch 20, LoraLayer 9: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 10: 33340 Step\n",
      "End of epoch 20, LoraLayer 10: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 11: 33340 Step\n",
      "End of epoch 20, LoraLayer 11: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 12: 33340 Step\n",
      "End of epoch 20, LoraLayer 12: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 13: 33340 Step\n",
      "End of epoch 20, LoraLayer 13: Decay factor: 0.0\n",
      "End of epoch 20, LoraLayer 14: 33340 Step\n",
      "End of epoch 20, LoraLayer 14: Decay factor: 0.0\n",
      "\n",
      "Testing loss: 0.7591454386711121, acc: 0.760699987411499\n",
      "\n",
      "1667/1667 [==============================] - 60s 36ms/step - loss: 0.5441 - accuracy: 0.8163 - val_loss: 0.7591 - val_accuracy: 0.7610\n"
     ]
    }
   ],
   "source": [
    "history_exp26 = exp26_lora_vgg16.fit(x_train, y_train, batch_size=30, epochs=20, validation_data=(x_test, y_test), callbacks=[print_step_callback, TestCallback((x_test, y_test))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "p2oLoaoZACLB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7591 - accuracy: 0.7607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7591454386711121, 0.760699987411499]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "exp26_lora_vgg16.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "7lmu1SLyACLB"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHWCAYAAAALjsguAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAADI/ElEQVR4nOzdd1hTZxvH8W/Ye7kY4gLcuPfeOGpddddZbbXu0ddaW6u21S5bV1vbutqqddXVuvdA68a9UBREnAjIhuS8f0RSEVRQ4AS4P9eVi5OTM36JMTl3znOeR6MoioIQQgghhBBCCCFUZ6J2ACGEEEIIIYQQQuhJkS6EEEIIIYQQQhgJKdKFEEIIIYQQQggjIUW6EEIIIYQQQghhJKRIF0IIIYQQQgghjIQU6UIIIYQQQgghhJGQIl0IIYQQQgghhDASUqQLIYQQQgghhBBGQop0IYQQQgghhBDCSEiRLoxK//79KVGixCutO2XKFDQaTdYGMjI3btxAo9GwZMmSHN+3RqNhypQphvtLlixBo9Fw48aNl65bokQJ+vfvn6V5Xue9IoQQIm+Q44YXk+OG/8hxg8hNpEgXGaLRaDJ027t3r9pR872RI0ei0WgIDAx87jKTJk1Co9Fw5syZHEyWebdv32bKlCkEBASoHSVdFy9eRKPRYGVlRUREhNpxhBDCaMhxQ+4hxw3ZK+WHkm+//VbtKCIXMVM7gMgd/vjjj1T3f//9d3bs2JFmfrly5V5rP7/++is6ne6V1v3444/58MMPX2v/eUHv3r2ZO3cuy5cvZ/Lkyeku8+eff+Lr60ulSpVeeT99+vShR48eWFpavvI2Xub27dtMnTqVEiVKUKVKlVSPvc57JassXboUV1dXHj16xJo1axg0aJCqeYQQwljIcUPuIccNQhgfKdJFhrz99tup7v/777/s2LEjzfxnxcbGYmNjk+H9mJubv1I+ADMzM8zM5C1du3ZtvL29+fPPP9P9sj18+DBBQUF8+eWXr7UfU1NTTE1NX2sbr+N13itZQVEUli9fTq9evQgKCmLZsmVGW6THxMRga2urdgwhRD4ixw25hxw3CGF8pLm7yDJNmjShYsWKnDhxgkaNGmFjY8NHH30EwIYNG2jXrh3u7u5YWlri5eXFZ599hlarTbWNZ68XerqJ0C+//IKXlxeWlpbUrFmTY8eOpVo3vWvLNBoNw4cPZ/369VSsWBFLS0sqVKjA1q1b0+Tfu3cvNWrUwMrKCi8vL37++ecMX6924MABunbtSrFixbC0tMTT05MxY8YQFxeX5vnZ2dkRGhpKx44dsbOzo1ChQowfPz7NaxEREUH//v1xdHTEycmJfv36ZbhJde/evbl06RInT55M89jy5cvRaDT07NmTxMREJk+eTPXq1XF0dMTW1paGDRuyZ8+el+4jvWvLFEXh888/p2jRotjY2NC0aVPOnz+fZt3w8HDGjx+Pr68vdnZ2ODg40KZNG06fPm1YZu/evdSsWROAAQMGGJpGplxXl961ZTExMYwbNw5PT08sLS0pU6YM3377LYqipFouM++L5/H39+fGjRv06NGDHj16sH//fm7dupVmOZ1Ox+zZs/H19cXKyopChQrRunVrjh8/nmq5pUuXUqtWLWxsbHB2dqZRo0Zs3749Veanr+1L8ex1eyn/Lvv27eP999+ncOHCFC1aFICbN2/y/vvvU6ZMGaytrSlQoABdu3ZN9/rAiIgIxowZQ4kSJbC0tKRo0aL07duXBw8eEB0dja2tLaNGjUqz3q1btzA1NWXGjBkZfCWFEPmVHDfIcUN+Om54mXv37vHOO+9QpEgRrKysqFy5Mr/99lua5VasWEH16tWxt7fHwcEBX19fZs+ebXg8KSmJqVOn4uPjg5WVFQUKFKBBgwbs2LEjy7KK7Cc/H4os9fDhQ9q0aUOPHj14++23KVKkCKD/YLazs2Ps2LHY2dmxe/duJk+eTFRUFN98881Lt7t8+XIeP37Me++9h0aj4euvv6Zz585cv379pb+MHjx4kLVr1/L+++9jb2/PnDlz6NKlC8HBwRQoUACAU6dO0bp1a9zc3Jg6dSparZZp06ZRqFChDD3v1atXExsby9ChQylQoABHjx5l7ty53Lp1i9WrV6daVqvV4ufnR+3atfn222/ZuXMnM2fOxMvLi6FDhwL6L60OHTpw8OBBhgwZQrly5Vi3bh39+vXLUJ7evXszdepUli9fTrVq1VLte9WqVTRs2JBixYrx4MEDFixYQM+ePRk8eDCPHz9m4cKF+Pn5cfTo0TRNxV5m8uTJfP7557Rt25a2bdty8uRJWrVqRWJiYqrlrl+/zvr16+natSslS5bk7t27/PzzzzRu3JgLFy7g7u5OuXLlmDZtGpMnT+bdd9+lYcOGANSrVy/dfSuKwptvvsmePXt45513qFKlCtu2beODDz4gNDSU77//PtXyGXlfvMiyZcvw8vKiZs2aVKxYERsbG/78808++OCDVMu98847LFmyhDZt2jBo0CCSk5M5cOAA//77LzVq1ABg6tSpTJkyhXr16jFt2jQsLCw4cuQIu3fvplWrVhl+/Z/2/vvvU6hQISZPnkxMTAwAx44d49ChQ/To0YOiRYty48YNfvrpJ5o0acKFCxcMZ6+io6Np2LAhFy9eZODAgVSrVo0HDx6wceNGbt26RZUqVejUqRMrV67ku+++S3Vm5M8//0RRFHr37v1KuYUQ+YscN8hxQ345bniRuLg4mjRpQmBgIMOHD6dkyZKsXr2a/v37ExERYfhRfMeOHfTs2ZPmzZvz1VdfAfr+cfz9/Q3LTJkyhRkzZjBo0CBq1apFVFQUx48f5+TJk7Rs2fK1coocpAjxCoYNG6Y8+/Zp3LixAijz589Ps3xsbGyaee+9955iY2OjxMfHG+b169dPKV68uOF+UFCQAigFChRQwsPDDfM3bNigAMrff/9tmPfpp5+myQQoFhYWSmBgoGHe6dOnFUCZO3euYV779u0VGxsbJTQ01DDv6tWripmZWZptpie95zdjxgxFo9EoN2/eTPX8AGXatGmplq1atapSvXp1w/3169crgPL1118b5iUnJysNGzZUAGXx4sUvzVSzZk2laNGiilarNczbunWrAig///yzYZsJCQmp1nv06JFSpEgRZeDAganmA8qnn35quL948WIFUIKCghRFUZR79+4pFhYWSrt27RSdTmdY7qOPPlIApV+/foZ58fHxqXIpiv7f2tLSMtVrc+zYsec+32ffKymv2eeff55qubfeekvRaDSp3gMZfV88T2JiolKgQAFl0qRJhnm9evVSKleunGq53bt3K4AycuTINNtIeY2uXr2qmJiYKJ06dUrzmjz9Oj77+qcoXrx4qtc25d+lQYMGSnJycqpl03ufHj58WAGU33//3TBv8uTJCqCsXbv2ubm3bdumAMqWLVtSPV6pUiWlcePGadYTQuRvctzw8ucnxw16ee24IeU9+c033zx3mVmzZimAsnTpUsO8xMREpW7duoqdnZ0SFRWlKIqijBo1SnFwcEjz/f60ypUrK+3atXthJmH8pLm7yFKWlpYMGDAgzXxra2vD9OPHj3nw4AENGzYkNjaWS5cuvXS73bt3x9nZ2XA/5dfR69evv3TdFi1a4OXlZbhfqVIlHBwcDOtqtVp27txJx44dcXd3Nyzn7e1NmzZtXrp9SP38YmJiePDgAfXq1UNRFE6dOpVm+SFDhqS637Bhw1TPZfPmzZiZmRl+IQf9tVwjRozIUB7QXw9469Yt9u/fb5i3fPlyLCws6Nq1q2GbFhYWgL5Zdnh4OMnJydSoUSPdJm8vsnPnThITExkxYkSqpn6jR49Os6ylpSUmJvqPH61Wy8OHD7Gzs6NMmTKZ3m+KzZs3Y2pqysiRI1PNHzduHIqisGXLllTzX/a+eJEtW7bw8OFDevbsaZjXs2dPTp8+naqZ3l9//YVGo+HTTz9Ns42U12j9+vXodDomT55seE2eXeZVDB48OM21f0+/T5OSknj48CHe3t44OTmlet3/+usvKleuTKdOnZ6bu0WLFri7u7Ns2TLDY+fOnePMmTMvveZUCCFSyHGDHDfkh+OGjGRxdXVNdVxhbm7OyJEjiY6OZt++fQA4OTkRExPzwqbrTk5OnD9/nqtXr752LqEeKdJFlvLw8DB8eD/t/PnzdOrUCUdHRxwcHChUqJDhQD4yMvKl2y1WrFiq+ylfvI8ePcr0uinrp6x779494uLi8Pb2TrNcevPSExwcTP/+/XFxcTFcL9a4cWMg7fNLuS75eXlAf+2wm5sbdnZ2qZYrU6ZMhvIA9OjRA1NTU5YvXw5AfHw869ato02bNqkOXH777TcqVapkuG6pUKFCbNq0KUP/Lk+7efMmAD4+PqnmFypUKNX+QP/F/v333+Pj44OlpSUFCxakUKFCnDlzJtP7fXr/7u7u2Nvbp5qf0nNwSr4UL3tfvMjSpUspWbIklpaWBAYGEhgYiJeXFzY2NqmK1mvXruHu7o6Li8tzt3Xt2jVMTEwoX778S/ebGSVLlkwzLy4ujsmTJxuuvUt53SMiIlK97teuXaNixYov3L6JiQm9e/dm/fr1xMbGAvpLAKysrAwHc0II8TJy3CDHDfnhuCEjWXx8fNL8WP9slvfff5/SpUvTpk0bihYtysCBA9NcFz9t2jQiIiIoXbo0vr6+fPDBB0Y/dJ5IS4p0kaWe/mU4RUREBI0bN+b06dNMmzaNv//+mx07dhiupcnIcBjP6w1UeaZjj6xeNyO0Wi0tW7Zk06ZNTJgwgfXr17Njxw5DRyXPPr+c6tm0cOHCtGzZkr/++oukpCT+/vtvHj9+nOpa4aVLl9K/f3+8vLxYuHAhW7duZceOHTRr1ixbhymZPn06Y8eOpVGjRixdupRt27axY8cOKlSokGPDo7zq+yIqKoq///6boKAgfHx8DLfy5csTGxvL8uXLs+y9lRHPdhyUIr3/iyNGjOCLL76gW7durFq1iu3bt7Njxw4KFCjwSq973759iY6OZv369Ybe7t944w0cHR0zvS0hRP4kxw1y3JARufm4ISsVLlyYgIAANm7caLievk2bNqn6HmjUqBHXrl1j0aJFVKxYkQULFlCtWjUWLFiQYznF65OO40S227t3Lw8fPmTt2rU0atTIMD8oKEjFVP8pXLgwVlZWBAYGpnksvXnPOnv2LFeuXOG3336jb9++hvmv04tm8eLF2bVrF9HR0al+Fb98+XKmttO7d2+2bt3Kli1bWL58OQ4ODrRv397w+Jo1ayhVqhRr165N1dQsvebZGckMcPXqVUqVKmWYf//+/TS/Mq9Zs4amTZuycOHCVPMjIiIoWLCg4X5mmnsXL16cnTt38vjx41S/iqc0i0zJ97rWrl1LfHw8P/30U6qsoP/3+fjjj/H396dBgwZ4eXmxbds2wsPDn3s23cvLC51Ox4ULF17Y4Y6zs3OaXnoTExMJCwvLcPY1a9bQr18/Zs6caZgXHx+fZrteXl6cO3fupdurWLEiVatWZdmyZRQtWpTg4GDmzp2b4TxCCJEeOW7IPDlu0DPG44aMZjlz5gw6nS7V2fT0slhYWNC+fXvat2+PTqfj/fff5+eff+aTTz4xtORwcXFhwIABDBgwgOjoaBo1asSUKVOMdqhYkZacSRfZLuWXx6d/aUxMTOTHH39UK1IqpqamtGjRgvXr13P79m3D/MDAwDTXIz1vfUj9/BRFSTUcRma1bduW5ORkfvrpJ8M8rVab6QKoY8eO2NjY8OOPP7JlyxY6d+6MlZXVC7MfOXKEw4cPZzpzixYtMDc3Z+7cuam2N2vWrDTLmpqapvnlefXq1YSGhqaalzK2d0aGkGnbti1arZZ58+almv/999+j0WgyfJ3gyyxdupRSpUoxZMgQ3nrrrVS38ePHY2dnZ2jy3qVLFxRFYerUqWm2k/L8O3bsiImJCdOmTUtzNuDp18jLyyvVdYIAv/zyy3PPpKcnvdd97ty5abbRpUsXTp8+zbp1656bO0WfPn3Yvn07s2bNokCBAln2Ogsh8i85bsg8OW7QM8bjhoxo27Ytd+7cYeXKlYZ5ycnJzJ07Fzs7O8OlEA8fPky1nomJCZUqVQIgISEh3WXs7Ozw9vY2PC5yBzmTLrJdvXr1cHZ2pl+/fowcORKNRsMff/yRo82DXmbKlCls376d+vXrM3ToUMOHdsWKFQkICHjhumXLlsXLy4vx48cTGhqKg4MDf/3112tdo9S+fXvq16/Phx9+yI0bNyhfvjxr167N9HVXdnZ2dOzY0XB92bPDYr3xxhusXbuWTp060a5dO4KCgpg/fz7ly5cnOjo6U/tKGbd1xowZvPHGG7Rt25ZTp06xZcuWNGec33jjDaZNm8aAAQOoV68eZ8+eZdmyZal+SQd9Yerk5MT8+fOxt7fH1taW2rVrp3u9dfv27WnatCmTJk3ixo0bVK5cme3bt7NhwwZGjx6dqrOXV3X79m327NmTppOZFJaWlvj5+bF69WrmzJlD06ZN6dOnD3PmzOHq1au0bt0anU7HgQMHaNq0KcOHD8fb25tJkybx2Wef0bBhQzp37oylpSXHjh3D3d3dMN74oEGDGDJkCF26dKFly5acPn2abdu2pXltX+SNN97gjz/+wNHRkfLly3P48GF27tyZZuiYDz74gDVr1tC1a1cGDhxI9erVCQ8PZ+PGjcyfP5/KlSsblu3Vqxf/+9//WLduHUOHDn3p0EZCCPEyctyQeXLcoGdsxw1P27VrF/Hx8Wnmd+zYkXfffZeff/6Z/v37c+LECUqUKMGaNWvw9/dn1qxZhjP9gwYNIjw8nGbNmlG0aFFu3rzJ3LlzqVKliuH69fLly9OkSROqV6+Oi4sLx48fZ82aNQwfPjxLn4/IZjnQg7zIg543lEqFChXSXd7f31+pU6eOYm1trbi7uyv/+9//DEM47dmzx7Dc84ZSSW/YCp4Z2uN5Q6kMGzYszbrPDlulKIqya9cupWrVqoqFhYXi5eWlLFiwQBk3bpxiZWX1nFfhPxcuXFBatGih2NnZKQULFlQGDx5sGJrj6WFA+vXrp9ja2qZZP73sDx8+VPr06aM4ODgojo6OSp8+fZRTp05leCiVFJs2bVIAxc3NLd0hvqZPn64UL15csbS0VKpWrar8888/af4dFOXlQ6koiqJotVpl6tSpipubm2Jtba00adJEOXfuXJrXOz4+Xhk3bpxhufr16yuHDx9WGjdunGb4rg0bNijly5c3DGuT8tzTy/j48WNlzJgxiru7u2Jubq74+Pgo33zzTaqhXVKeS0bfF0+bOXOmAii7du167jJLlixRAGXDhg2KouiHq/nmm2+UsmXLKhYWFkqhQoWUNm3aKCdOnEi13qJFi5SqVasqlpaWirOzs9K4cWNlx44dhse1Wq0yYcIEpWDBgoqNjY3i5+enBAYGPncItmPHjqXJ9ujRI2XAgAFKwYIFFTs7O8XPz0+5dOlSus/74cOHyvDhwxUPDw/FwsJCKVq0qNKvXz/lwYMHabbbtm1bBVAOHTr03NdFCJG/yXFDanLcoJfXjxsU5b/35PNuf/zxh6IoinL37l3Dd7SFhYXi6+ub5t9tzZo1SqtWrZTChQsrFhYWSrFixZT33ntPCQsLMyzz+eefK7Vq1VKcnJwUa2trpWzZssoXX3yhJCYmvjCnMC4aRTGinyWFMDIdO3aUYSyEeIlOnTpx9uzZDF2LKYQQeZkcNwghsoJcky7EE3FxcanuX716lc2bN9OkSRN1AgmRC4SFhbFp0yb69OmjdhQhhMhRctwghMguciZdiCfc3Nzo378/pUqV4ubNm/z0008kJCRw6tSpNGN4CpHfBQUF4e/vz4IFCzh27BjXrl3D1dVV7VhCCJFj5LhBCJFdpOM4IZ5o3bo1f/75J3fu3MHS0pK6desyffp0+aIVIh379u1jwIABFCtWjN9++00KdCFEviPHDUKI7CJn0oUQQgghhBBCCCMh16QLIYQQQgghhBBGQop0IYQQQgghhBDCSOS7a9J1Oh23b9/G3t4ejUajdhwhhBACRVF4/Pgx7u7umJjI7+dZQb7vhRBCGJNMfderN0S7OkJCQhRAbnKTm9zkJjeju4WEhKj9NZnlfvzxR8XX11ext7dX7O3tlTp16iibN29+4TqrVq1SypQpo1haWioVK1ZUNm3alOn9yve93OQmN7nJzRhvGfmuV/VM+v79+/nmm284ceIEYWFhrFu3jo4dO75wnb179zJ27FjOnz+Pp6cnH3/8Mf3798/wPu3t7QEICQnBwcHhNdILIYQQWSMqKgpPT0/Dd1ReUrRoUb788kt8fHxQFIXffvuNDh06cOrUKSpUqJBm+UOHDtGzZ09mzJjBG2+8wfLly+nYsSMnT56kYsWKGd6vfN8LIYQwJpn5rle1d/ctW7bg7+9P9erV6dy580uL9KCgICpWrMiQIUMYNGgQu3btYvTo0WzatAk/P78M7TMqKgpHR0ciIyPlS1sIIYRRyG/fTS4uLnzzzTe88847aR7r3r07MTEx/PPPP4Z5derUoUqVKsyfPz/D+8hvr6kQQgjjlpnvJVXPpLdp04Y2bdpkePn58+dTsmRJZs6cCUC5cuU4ePAg33//fYaLdCGEEEKoQ6vVsnr1amJiYqhbt266yxw+fJixY8emmufn58f69etfuO2EhAQSEhIM96Oiol47rxBCCKGGXNU7zeHDh2nRokWqeX5+fhw+fPi56yQkJBAVFZXqJoQQQoicc/bsWezs7LC0tGTIkCGsW7eO8uXLp7vsnTt3KFKkSKp5RYoU4c6dOy/cx4wZM3B0dDTcPD09syy/EEIIkZNyVZH+vC/uqKgo4uLi0l1HvrSFEEIIdZUpU4aAgACOHDnC0KFD6devHxcuXMjSfUycOJHIyEjDLSQkJEu3L4QQQuSUPD8E28SJE1M1m0u5YF8IYVwURSE5ORmtVqt2FCGynKmpKWZmZvl2KDALCwu8vb0BqF69OseOHWP27Nn8/PPPaZZ1dXXl7t27qebdvXsXV1fXF+7D0tISS0vLDGeSzxyRXfL7/3chxOvLVUX68764HRwcsLa2TnedzH5pCyFyXmJiImFhYcTGxqodRYhsY2Njg5ubGxYWFmpHUZ1Op0t1/fjT6tata+gYNsWOHTueew37q5DPHJHd5P+7EOJ15KoivW7dumzevDnVvKz+4hZC5CydTkdQUBCmpqa4u7tjYWEhZx9EnqIoComJidy/f5+goCB8fHwwMclVV5u9lokTJ9KmTRuKFSvG48ePWb58OXv37mXbtm0A9O3bFw8PD2bMmAHAqFGjaNy4MTNnzqRdu3asWLGC48eP88svv2RJHvnMEdkpv/9/F0JkDVWL9OjoaAIDAw33g4KCCAgIwMXFhWLFijFx4kRCQ0P5/fffARgyZAjz5s3jf//7HwMHDmT37t2sWrWKTZs2qfUUhBCvKTExEZ1Oh6enJzY2NmrHESJbWFtbY25uzs2bN0lMTMTKykrtSDnm3r179O3bl7CwMBwdHalUqRLbtm2jZcuWAAQHB6cqYurVq8fy5cv5+OOP+eijj/Dx8WH9+vWZGiP9ReQzR2S3/Pz/XQiRNVQt0o8fP07Tpk0N91OuHe/Xrx9LliwhLCyM4OBgw+MlS5Zk06ZNjBkzhtmzZ1O0aFEWLFggw68JkQfImQaR1+XX9/jChQtf+PjevXvTzOvatStdu3bNpkR6+fXfQ+QMeX8JIV6HqkV6kyZNUBTluY8vWbIk3XVOnTqVjamEEEIIIYQQQgh1yM98QgghhBBCCCGEkZAiXQghjEiJEiWYNWtWhpffu3cvGo2GiIiIbMskhMi75DNHCCGMjxTpQgjxCjQazQtvU6ZMeaXtHjt2jHfffTfDy9erV8/QIVdOKVu2LJaWlty5cyfH9ilEfpffPnPkxwAhRH6Wq4ZgE0IIYxEWFmaYXrlyJZMnT+by5cuGeXZ2doZpRVHQarWYmb38I7dQoUKZymFhYYGrq2um1nkdBw8eJC4ujrfeeovffvuNCRMm5Ni+05OUlIS5ubmqGYTICfn1M0cIIfIjOZOuAkVRiIxN4lxoJNvO32HhwSCm/X2B9/44Tucf/Zm76ypJWp3aMYVQjaIoxCYmq3J7UWeWT3N1dTXcHB0d0Wg0hvuXLl3C3t6eLVu2UL16dSwtLTl48CDXrl2jQ4cOFClSBDs7O2rWrMnOnTtTbffZpqcajYYFCxbQqVMnbGxs8PHxYePGjYbHnz3btGTJEpycnNi2bRvlypXDzs6O1q1bpzrAT05OZuTIkTg5OVGgQAEmTJhAv3796Nix40uf98KFC+nVqxd9+vRh0aJFaR6/desWPXv2xMXFBVtbW2rUqMGRI0cMj//999/UrFkTKysrChYsSKdOnVI91/Xr16fanpOTk6ET0Rs3bqDRaFi5ciWNGzfGysqKZcuW8fDhQ3r27ImHhwc2Njb4+vry559/ptqOTqfj66+/xtvbG0tLS4oVK8YXX3wBQLNmzRg+fHiq5e/fv4+FhQW7du166Wsicj/5zJlluG9snznP8+jRI/r27YuzszM2Nja0adOGq1evGh6/efMm7du3x9nZGVtbWypUqMDmzZsN6/bu3ZtChQphbW2Nj48PixcvfuUsIpe4HQB/dIK7F9ROIsRLyZn0bKAoCg9jEgl9FMetR3GERsTq/xruxxGdkPzc9U8GR7Dz4l2+614Fr0J2z11OiLwqLklL+cnbVNn3hWl+2FhkzUfjhx9+yLfffkupUqVwdnYmJCSEtm3b8sUXX2Bpacnvv/9O+/btuXz5MsWKFXvudqZOncrXX3/NN998w9y5c+nduzc3b97ExcUl3eVjY2P59ttv+eOPPzAxMeHtt99m/PjxLFu2DICvvvqKZcuWsXjxYsqVK8fs2bNZv359qiEx0/P48WNWr17NkSNHKFu2LJGRkRw4cICGDRsCEB0dTePGjfHw8GDjxo24urpy8uRJdDr9j46bNm2iU6dOTJo0id9//53ExETDQXNmX9eZM2dStWpVrKysiI+Pp3r16kyYMAEHBwc2bdpEnz598PLyolatWgBMnDiRX3/9le+//54GDRoQFhbGpUuXABg0aBDDhw9n5syZWFpaArB06VI8PDxo1qxZpvOJ3Ec+c1Izls+cF+nfvz9Xr15l48aNODg4MGHCBNq2bcuFCxcwNzdn2LBhJCYmsn//fmxtbblw4YKhtcEnn3zChQsX2LJlCwULFiQwMJC4uLhXziJyiX1fw7XdsP8b6Co/ygjjJkX6a7h69zEXwqIMhbe+EI8lNCKO+KSXnwkvaGeBh5M1RZ1t8HC2xsPJGkVR+G7HFU7fiqTdnANMaluOt+sUR6PR5MAzEkJkpWnTptGyZUvDfRcXFypXrmy4/9lnn7Fu3To2btyY5kzu0/r370/Pnj0BmD59OnPmzOHo0aO0bt063eWTkpKYP38+Xl5eAAwfPpxp06YZHp87dy4TJ040nMWeN29ehorlFStW4OPjQ4UKFQDo0aMHCxcuNBTpy5cv5/79+xw7dsxwMO/t7W1Y/4svvqBHjx5MnTrVMO/p1yOjRo8eTefOnVPNGz9+vGF6xIgRbNu2jVWrVlGrVi0eP37M7NmzmTdvHv369QPAy8uLBg0aANC5c2eGDx/Ohg0b6NatG6A/O9i/f3/57BW5Sl77zHmelOLc39+fevXqAbBs2TI8PT1Zv349Xbt2JTg4mC5duuDr6wtAqVKlDOsHBwdTtWpVatSoAehbE4g8LjkRgvbppwN36u+bWaibSYgXkCL9Nfx2+AZL/w1O9zGNBgrbW+oLcCdrPJytKfqkEE+ZZ21hmu66fhVd+d+aMxy4+oBPNpxnx8V7fPNWJYo4WGXn0xHCaFibm3Jhmp9q+84qKQeAKaKjo5kyZQqbNm0iLCyM5ORk4uLiCA5O/3MkRaVKlQzTtra2ODg4cO/evecub2NjYzhYBnBzczMsHxkZyd27dw1nmAFMTU2pXr264Yz38yxatIi3337bcP/tt9+mcePGzJ07F3t7ewICAqhatepzz7YFBAQwePDgF+4jI559XbVaLdOnT2fVqlWEhoaSmJhIQkICNjY2AFy8eJGEhASaN2+e7vasrKwMzfe7devGyZMnOXfuXKomviJvk8+c1IzlM+d5Ll68iJmZGbVr1zbMK1CgAGXKlOHixYsAjBw5kqFDh7J9+3ZatGhBly5dDM9r6NChdOnShZMnT9KqVSs6duxoKPZFHhV8GBKj9dMJUXDzIHhJSylhvKRIfw3l3RypVdKFok5PCnDn/wpwNycrLM1e7YvXzdGa3wbU4vfDN5ix5RL7r9zHb9Z+pnfypa2vWxY/CyGMj0ajybLmn2qytbVNdX/8+PHs2LGDb7/9Fm9vb6ytrXnrrbdITEx84Xae7RhNo9G88OA2veUzet3r81y4cIF///2Xo0ePpuosTqvVsmLFCgYPHoy1tfULt/Gyx9PLmZSUlGa5Z1/Xb775htmzZzNr1ix8fX2xtbVl9OjRhtf1ZfsFfZP3KlWqcOvWLRYvXkyzZs0oXrz4S9cTeYN85qRmDJ85r2vQoEH4+fmxadMmtm/fzowZM5g5cyYjRoygTZs23Lx5k82bN7Njxw6aN2/OsGHD+Pbbb1XNLLLR1e2p71/aLEW6MGrScdxr6FW7GKveq8t33aswtlUZutcsRn3vgpQoaPvKBXoKExMN/euXZNPIBlT0cCAiNon3l51k7MoAouLTHrQKIYyfv78//fv3p1OnTvj6+uLq6sqNGzdyNIOjoyNFihTh2LFjhnlarZaTJ0++cL2FCxfSqFEjTp8+TUBAgOE2duxYFi5cCOjPvgUEBBAeHp7uNipVqvTCjtgKFSqUqrOpq1evEhsb+9Ln5O/vT4cOHXj77bepXLkypUqV4sqVK4bHfXx8sLa2fuG+fX19qVGjBr/++ivLly9n4MCBL92vEMYuN3/mvEi5cuVITk5O1Snlw4cPuXz5MuXLlzfM8/T0ZMiQIaxdu5Zx48bx66+/Gh4rVKgQ/fr1Y+nSpcyaNYtffvnllfOIXCDwSYeJlbrr/17eAir/kCTEi+T+n43zOO/C9qwdWp+5u6/yw55A1p4K5UhQON92rUxdrwJqxxNCZIKPjw9r166lffv2aDQaPvnkk1du7vk6RowYwYwZM/D29qZs2bLMnTuXR48ePff666SkJP744w+mTZtGxYoVUz02aNAgvvvuO86fP0/Pnj2ZPn06HTt2ZMaMGbi5uXHq1Cnc3d2pW7cun376Kc2bN8fLy4sePXqQnJzM5s2bDWfmmzVrxrx586hbty5arZYJEyZkaHg1Hx8f1qxZw6FDh3B2dua7777j7t27hoN1KysrJkyYwP/+9z8sLCyoX78+9+/f5/z587zzzjupnsvw4cOxtbVN1eu8ELlVbv3MedrZs2ext7c33NdoNFSuXJkOHTowePBgfv75Z+zt7fnwww/x8PCgQ4cOgL7vijZt2lC6dGkePXrEnj17KFeuHACTJ0+mevXqVKhQgYSEBP755x/DYyIPigiB+5dAYwItpsLFvyHqFtw5A26Z7xdFiJwgZ9JzAQszE8a1KsPqIfUoXsCG0Ig4ei34ly82XSA+Sat2PCFEBn333Xc4OztTr1492rdvj5+fH9WqVcvxHBMmTKBnz5707duXunXrYmdnh5+fH1ZW6fd7sXHjRh4+fJhu4VquXDnKlSvHwoULsbCwYPv27RQuXJi2bdvi6+vLl19+iampvmVRkyZNWL16NRs3bqRKlSo0a9aMo0ePGrY1c+ZMPD09adiwIb169WL8+PGG68pf5OOPP6ZatWr4+fnRpEkTXF1d0wzt9MknnzBu3DgmT55MuXLl6N69e5prbHv27ImZmRk9e/Z87mshRG6SWz9zntaoUSOqVq1quFWvXh2AxYsXU716dd544w3q1q2Loihs3rzZ8MOeVqtl2LBhlCtXjtatW1O6dGl+/PFHQD/W+8SJE6lUqRKNGjXC1NSUFStWZN8LINQVuEP/t2hNcHD7r5n7pVfvvFCI7KZR1L5oKIdFRUXh6OhIZGQkDg4OasfJtJiEZD7fdJE/j+o7fSnras/33atQzi33PRchAOLj4wkKCqJkyZJSGKlEp9NRrlw5unXrxmeffaZ2HNXcuHEDLy8vjh07li2FzIve67n9u8kYPe81lc8c9eWHzxx5nxmRP3vB5U3Q9GNo/AGcWgobhoFrJRhyQO10Ih/JzHe9nEnPZWwtzZjR2ZeF/WpQ0M6CS3ce02GePz/vu4ZWl69+bxFCvKKbN2/y66+/cuXKFc6ePcvQoUMJCgqiV69eakdTRVJSEnfu3OHjjz+mTp06qpxpFCIvk88coZqnh17zeTI8YenW+qbvd87om8ILYYSkSM+lmpcrwrbRjWhZvgiJWh0ztlyi56//EhL+8k6WhBD5m4mJCUuWLKFmzZrUr1+fs2fPsnPnznx7Taa/vz9ubm4cO3aM+fPnqx1HiDxHPnOEalKGXrMtrD9zDmBbEDyfDN93eYt62YR4Aek4LhcrYGfJL32qs/r4Lab+fZ6jQeG0mX2AKW9WoEs1jwx1yCKEyH88PT3x9/dXO4bRaNKkierDRQmRl8lnjlBNytBr3i3A5Klzk2Xa6Av4y5uh9rvqZBPiBeRMei6n0WjoVtOTLaMaUaO4M9EJyYxffZqhS08SHvPicVCFEEIIIYTIs1KGXvNpkXp+mXb6vzcOQnxkzmYSIgOkSM8jihWwYeV7dflf6zKYm2rYev4Orb7fz55L916+shBCCCGEEHnJ00OvlWqa+rGC3lCwNOiS4OoOdfIJ8QJSpOchpiYa3m/izbr36+NT2I4H0QkMWHKMqX+fl6acQgghhBAi/3h66DUbl7SPl2mj/yvXpQsjJEV6HlTRw5G/RzRgUIOSACz2v8GsnVdVTiWEEEIIIUQOufqkqbt3y/QfT2nyfnUHaJNyJpMQGSRFeh5lZW7Kx2+U58vOvgDM3nWVNSduqZxKCCGEEEKIbJackHbotWcVrQG2hSAhUn9tuhBGRIr0PK5HrWK838QLgA//OoN/4AOVEwkhhBBCCJGN0ht67VkmplDaTz8tTd6FkZEiPR8Y36oM7Su7k6xTGLL0BFfvPlY7khDiiSZNmjB69GjD/RIlSjBr1qwXrqPRaFi/fv1r7zurtiOEyD3kM0fkCymdwT079NqzUpq8X94M0n+TMCJSpOcDJiYavnmrEjVLOPM4Ppn+i49x73G82rGEyNXat29P69at033swIEDaDQazpw5k+ntHjt2jHffzdoxW6dMmUKVKlXSzA8LC6NNmzZZuq/niYuLw8XFhYIFC5KQkJAj+xQiL5HPnIxZsmQJTk5O2boPkQs8b+i1Z5VqAmbWEBkCd85meywhMkqK9HzCytyUX/rUoGRBW0Ij4hj023FiE5PVjiVErvXOO++wY8cObt1K29fD4sWLqVGjBpUqPaeJ3QsUKlQIGxubrIj4Uq6urlhaWubIvv766y8qVKhA2bJlVT+TpigKycny+SdyF/nMESKDXjT02rMsbMDryTLS5F0YESnS8xFnWwsW96+Ji60FZ25FMvLPALQ6adojjJCiQGKMOrcMNnd74403KFSoEEuWLEk1Pzo6mtWrV/POO+/w8OFDevbsiYeHBzY2Nvj6+vLnn3++cLvPNj29evUqjRo1wsrKivLly7NjR9rxXCdMmEDp0qWxsbGhVKlSfPLJJyQl6XuqXbJkCVOnTuX06dNoNBo0Go0h87NNT8+ePUuzZs2wtramQIECvPvuu0RHRxse79+/Px07duTbb7/Fzc2NAgUKMGzYMMO+XmThwoW8/fbbvP322yxcuDDN4+fPn+eNN97AwcEBe3t7GjZsyLVr1wyPL1q0iAoVKmBpaYmbmxvDhw8H4MaNG2g0GgICAgzLRkREoNFo2Lt3LwB79+5Fo9GwZcsWqlevjqWlJQcPHuTatWt06NCBIkWKYGdnR82aNdm5c2eqXAkJCUyYMAFPT08sLS3x9vZm4cKFKIqCt7c33377barlAwIC0Gg0BAYGvvQ1EUZEPnMM9/PKZ87zBAcH06FDB+zs7HBwcKBbt27cvXvX8Pjp06dp2rQp9vb2ODg4UL16dY4fPw7AzZs3ad++Pc7Oztja2lKhQgU2b978yllENnnZ0GvPKtNW//fypuzLJEQmmakdQOSsEgVt+bVvdXr+eoSdF+/y2T8XmPJmBbVjCZFaUixMd1dn3x/dBgvbly5mZmZG3759WbJkCZMmTUKj0QCwevVqtFotPXv2JDo6murVqzNhwgQcHBzYtGkTffr0wcvLi1q1ar10Hzqdjs6dO1OkSBGOHDlCZGRkqmtJU9jb27NkyRLc3d05e/YsgwcPxt7env/97390796dc+fOsXXrVkMB6ujomGYbMTEx+Pn5UbduXY4dO8a9e/cYNGgQw4cPT1UU7NmzBzc3N/bs2UNgYCDdu3enSpUqDB48+LnP49q1axw+fJi1a9eiKApjxozh5s2bFC9eHIDQ0FAaNWpEkyZN2L17Nw4ODvj7+xvOdv/000+MHTuWL7/8kjZt2hAZGYm/v/9LX79nffjhh3z77beUKlUKZ2dnQkJCaNu2LV988QWWlpb8/vvvtG/fnsuXL1OsWDEA+vbty+HDh5kzZw6VK1cmKCiIBw8eoNFoGDhwIIsXL2b8+PGGfSxevJhGjRrh7e2d6XxCRfKZA+Sdz5wXPb+UAn3fvn0kJyczbNgwunfvbvhRr3fv3lStWpWffvoJU1NTAgICMDc3B2DYsGEkJiayf/9+bG1tuXDhAnZ2dpnOIbJZytBrz+vV/VmlWwMaCDsNkbfAsWi2RRMio6RIz4eqF3fh+25VGLb8JEsO3aCYiw0Dn4ypLoTIuIEDB/LNN9+wb98+mjRpAuiLtC5duuDo6Iijo2OqAm7EiBFs27aNVatWZeiAeefOnVy6dIlt27bh7q4vIKZPn57mms6PP/7YMF2iRAnGjx/PihUr+N///oe1tTV2dnaYmZnh6ur63H0tX76c+Ph4fv/9d2xt9QXDvHnzaN++PV999RVFihQBwNnZmXnz5mFqakrZsmVp164du3bteuEB86JFi2jTpg3Ozs4A+Pn5sXjxYqZMmQLADz/8gKOjIytWrDAcDJcuXdqw/ueff864ceMYNWqUYV7NmjVf+vo9a9q0abRs+d9Bm4uLC5UrVzbc/+yzz1i3bh0bN25k+PDhXLlyhVWrVrFjxw5atNBf11iqVCnD8v3792fy5MkcPXqUWrVqkZSUxPLly9OcXRciq8hnTsY+c55n165dnD17lqCgIDw9PQH4/fffqVChAseOHaNmzZoEBwfzwQcfULZsWQB8fHwM6wcHB9OlSxd8ffXD2z79eSCMxNNDrz1vfPRn2RUCz1oQckTf5L1W5t9bQmQ1KdLzqXaV3Lj1qCwztlzis00X8HC2xq/C879MhchR5jb6s0tq7TuDypYtS7169Vi0aBFNmjQhMDCQAwcOMG3aNAC0Wi3Tp09n1apVhIaGkpiYSEJCQoav/7x48SKenp6Gg2WAunXrpllu5cqVzJkzh2vXrhEdHU1ycjIODg4Zfh4p+6pcubLhYBmgfv366HQ6Ll++bDhgrlChAqampoZl3NzcOHv2+Z3taLVafvvtN2bPnm2Y9/bbbzN+/HgmT56MiYkJAQEBNGzY0FCgP+3evXvcvn2b5s2bZ+r5pKdGjRqp7kdHRzNlyhQ2bdpEWFgYycnJxMXFERwcDOibrpuamtK4ceN0t+fu7k67du1YtGgRtWrV4u+//yYhIYGuXbu+dlaRw+QzB8gbnzkv26enp6ehQAcoX748Tk5OXLx4kZo1azJ27FgGDRrEH3/8QYsWLejatSteXvqhbEeOHMnQoUPZvn07LVq0oEuXLq/UD4DIRhkZei09Zdo+KdI3S5EujIJck56PvduoFL1rF0NRYNSKU5wOiVA7khB6Go2++acatydNSDPqnXfe4a+//uLx48csXrwYLy8vQ1H3zTffMHv2bCZMmMCePXsICAjAz8+PxMTELHupDh8+TO/evWnbti3//PMPp06dYtKkSVm6j6c9W0hrNBp0Ot1zl9+2bRuhoaF0794dMzMzzMzM6NGjBzdv3mTXrl0AWFtbP3f9Fz0GYPJkaB3lqet6n3e96tPFAMD48eNZt24d06dP58CBAwQEBODr62t47V62b4BBgwaxYsUK4uLiWLx4Md27d8+xTrhEFpLPnAwz9s+c1zVlyhTOnz9Pu3bt2L17N+XLl2fdunWA/v/79evX6dOnD2fPnqVGjRrMnTs327KIV5DRodeeVfbJUGxBByA+MutzCZFJUqTnYxqNhqlvVqBJmULEJ+l457djhITHqh1LiFylW7dumJiYsHz5cn7//XcGDhxouFbU39+fDh068Pbbb1O5cmVKlSrFlStXMrztcuXKERISQlhYmGHev//+m2qZQ4cOUbx4cSZNmkSNGjXw8fHh5s2bqZaxsLBAq9W+dF+nT58mJibGMM/f3x8TExPKlCmT4czPWrhwIT169CAgICDVrUePHoYO5CpVqsSBAwfSLa7t7e0pUaKEoaB/VqFChQBSvUZPdyL3Iv7+/vTv359OnTrh6+uLq6srN27cMDzu6+uLTqdj3759z91G27ZtsbW15aeffmLr1q0MHDgwQ/sW4lXJZ86rS3l+ISEhhnkXLlwgIiKC8uXLG+aVLl2aMWPGsH37djp37szixYsNj3l6ejJkyBDWrl3LuHHj+PXXX7Mlq3hFGR167VkFfaCAN+iSIDD97xshcpIU6fmcmakJ83pVo5ybAw+iExmw5BiRsa/ea6oQ+Y2dnR3du3dn4sSJhIWF0b9/f8NjPj4+7Nixg0OHDnHx4kXee++9VL0Iv0yLFi0oXbo0/fr14/Tp0xw4cIBJkyalWsbHx4fg4GBWrFjBtWvXmDNnjuGsT4oSJUoQFBREQEAADx48SHec8t69e2NlZUW/fv04d+4ce/bsYcSIEfTp08fQ7DSz7t+/z99//02/fv2oWLFiqlvfvn1Zv3494eHhDB8+nKioKHr06MHx48e5evUqf/zxB5cvXwb0Z7ZmzpzJnDlzuHr1KidPnjScvbK2tqZOnTp8+eWXXLx4kX379qW6XvZFfHx8WLt2LQEBAZw+fZpevXqlOkNXokQJ+vXrx8CBA1m/fj1BQUHs3buXVatWGZYxNTWlf//+TJw4ER8fn3SbBguRleQz5+W0Wm2aHwYvXrxIixYt8PX1pXfv3pw8eZKjR4/St29fGjduTI0aNYiLi2P48OHs3buXmzdv4u/vz7FjxyhXrhwAo0ePZtu2bQQFBXHy5En27NljeEwYgcwMvZYeQy/v0mO/UJ8U6QI7SzMW96+Jq4MVgfeieW/pcRKTs68pmRB5zTvvvMOjR4/w8/NLdS3nxx9/TLVq1fDz86NJkya4urrSsWPHDG/XxMSEdevWERcXR61atRg0aBBffPFFqmXefPNNxowZw/Dhw6lSpQqHDh3ik08+SbVMly5daN26NU2bNqVQoULpDslkY2PDtm3bCA8Pp2bNmrz11ls0b96cefPmZe7FeEpKh1DpXU/evHlzrK2tWbp0KQUKFGD37t1ER0fTuHFjqlevzq+//mpo5tqvXz9mzZrFjz/+SIUKFXjjjTe4evWqYVuLFi0iOTmZ6tWrM3r0aD7//PMM5fvuu+9wdnamXr16tG/fHj8/P6pVq5ZqmZ9++om33nqL999/n7JlyzJ48OBUZ/5A/++fmJjIgAEDMvsSCfFK5DPnxaKjo6latWqqW/v27dFoNGzYsAFnZ2caNWpEixYtKFWqFCtXrgT0P7o9fPiQvn37Urp0abp160abNm2YOnUqoC/+hw0bRrly5WjdujWlS5fmxx9/fO28Iotkdui1Z6U0eb+6HbRywkqoS6MoGRygM4+IiorC0dGRyMjITHdyktddDIui6/zDRCck07mqBzO7VTY0oRMiu8THxxMUFETJkiWxsrJSO44QmXbgwAGaN29OSEjIC88Avui9Lt9NWe95r6l85oicIO8zFfzZSz/WebOPodEHmV9fp4VvS0PsA+i7EUql32moEK8qM9/1ciZdGJRzc+CH3tUwNdGw9lQos3ZefflKQgiRTyUkJHDr1i2mTJlC165dX7uJrhBCiFeUnADX9+qnMzr02rNMTJ+MmY40eReqkyJdpNK4dCE+61ARgNm7rrLmxC2VEwkhhHH6888/KV68OBEREXz99ddqxxFCiPwr+DAkxWR+6LVnlX1yXfqlzZC/GhsLIyNFukijV+1iDG2iHxP0w7/OcCjwgcqJhBDC+PTv3x+tVsuJEyfw8PBQO44QQuRfrzr02rNKNQEzK4gMhrvnsySaEK9CinSRrg9aleGNSm4k6xTeW3qCq3cfqx1JCCGEEEKItF516LVnWdj+1zO8NHkXKpIiXaTLxETDt10rU6O4M4/jk+m/+Bj3HserHUvkYfmsD0uRD8l73LjIv4fITvL+ykGvO/TaswxN3je9/raEeEVSpIvnsjI35Ze+NShRwIbQiDgG/Xac2MRktWOJPCZlmK3Y2FiVkwiRvVLe4ynveaEO+cwROUH+v+cgw9BrtV5t6LVnlW4NaCAsACJDX397QrwCM7UDCOPmYmvB4gG16PyjP2duRTLyzwB+7lMdUxMZmk1kDVNTU5ycnLh37x6gHztXhv4TeYmiKMTGxnLv3j2cnJwwNTVVO1K+Jp85IjvJ/3cVpFyP/rpN3VPYFdaPtX7rKFzZAjUHZc12hcgEKdLFS5UsaMuvfWvQa8ERdl68y2f/XODT9uXloEZkGVdXVwDDQbMQeZGTk5PhvS7UJZ85IrvJ//cckpwA1/fpp1916LX0lG2rL9IvbZYiXahCinSRITVKuPBdt8oMX36KJYducD86ga+6VMLOUt5C4vVpNBrc3NwoXLgwSUlJascRIsuZm5vLGTUjIp85IjvJ//cclFVDrz2rTFvYOQWC9kN8FFg5ZN22hcgAqbBEhr1RyZ3IuCQ+3XCeTWfCuBgWxU+9q1PG1V7taCKPMDU1lQMbIUSOkc8cIXK5rBp67VkFS4OLF4Rfg2u7oEKnrNu2EBkgHceJTOlduzgr36uDm6MV1+/H0OGHg6w9eUvtWEIIIYQQIr/JqqHXnqXRPNXLuwzFJnKeFOki06oXd+GfEQ1o6FOQ+CQdY1edZuLas8QnadWOJoQQQggh8oOsHnrtWWWeFOlXt4FWLosROUuKdPFKCthZsmRALUa38EGjgT+PBtPlp0MEP5QhbYQQQgghRDbL6qHXnuVZG2wKQHyk/tp3IXKQFOnilZmaaBjdojS/DaiFs405529H0W7uAXZcuKt2NCGEEEIIkZdl9dBrzzIxfTJmOnB5S/bsQ4jnkCJdvLZGpQuxaWRDqhVz4nF8MoN/P86MLRdJ1urUjiaEEEIIIfKa7Bp67Vll2uj/XtoEipJ9+xHiGVKkiyzh7mTNinfrMrB+SQB+3nedXguOcC8qXuVkQgghhBAiT8muodee5dUMzKwg4ibcu5B9+xHiGVKkiyxjYWbC5Pbl+bF3NewszTgaFE7bOQc5dO2B2tGEEEKoZMaMGdSsWRN7e3sKFy5Mx44duXz58gvXWbJkCRqNJtXNysoqhxILIYxedg299iwLWyjVRD99WXp5FzlHinSR5dr6urFxeH3KutrzIDqBtxcc4Yc9geh00kxICCHym3379jFs2DD+/fdfduzYQVJSEq1atSImJuaF6zk4OBAWFma43bx5M4cSCyGMXnYNvZYeQ5N3KdJFzjFTO4DIm0oVsmPd+/X5eP05/jp5i2+2XebEzUd8160yTjYWascTQgiRQ7Zu3Zrq/pIlSyhcuDAnTpygUaNGz11Po9Hg6uqa3fGEELlNRPB/Q695Ncv+/ZVuA4yG2ychKgwc3LJ/nyLfkzPpIttYW5jybddKfNXFFwszE3Zfuke7OQc5cytC7WhCCCFUEhkZCYCLy4uHTIqOjqZ48eJ4enrSoUMHzp8//8LlExISiIqKSnUTQuRBV58aes3aOfv3Z18EitbQT1+RXt5FzpAiXWQrjUZD95rFWPd+PYoXsCE0Io63fjrMH//eRJFeMoUQIl/R6XSMHj2a+vXrU7FixecuV6ZMGRYtWsSGDRtYunQpOp2OevXqcevWreeuM2PGDBwdHQ03T0/P7HgKQgi15WRT9xTS5F3kMI2SzyqlqKgoHB0diYyMxMHBQe04+UpkXBIfrD7N9ifjqHeo4s70Tr7YWspVF0KI/C2/fDcNHTqULVu2cPDgQYoWLZrh9ZKSkihXrhw9e/bks88+S3eZhIQEEhISDPejoqLw9PTM86+pEPlKcgJ8VVLfs/u7+8C9Ss7s994l+LE2mFrA/66DpX3O7FfkKZn5rpcz6SLHOFqb83Of6kxqWw5TEw0bAm7T4Qd/Au89VjuaEEKIbDZ8+HD++ecf9uzZk6kCHcDc3JyqVasSGBj43GUsLS1xcHBIdRNC5DE5NfTaswqVAZdSoE2Ea7tzbr8i35IiXeQojUbD4EalWPFuHYo4WBJ4L5o35/nzz5nbakcTQgiRDRRFYfjw4axbt47du3dTsmTJTG9Dq9Vy9uxZ3NykwyYh8rWcGnrtWRoNlGmrn5Ym7yIHSJEuVFGzhAubRjakvncBYhO1DF9+ihlbLqKVYdqEECJPGTZsGEuXLmX58uXY29tz584d7ty5Q1xcnGGZvn37MnHiRMP9adOmsX37dq5fv87Jkyd5++23uXnzJoMGDVLjKQghjIUa16OnSCnSr24DbXLO71/kK1KkC9UUtLPktwG1eK9xKQB+3ned/ouP8igmUeVkQgghsspPP/1EZGQkTZo0wc3NzXBbuXKlYZng4GDCwsIM9x89esTgwYMpV64cbdu2JSoqikOHDlG+fHk1noIQwhjk9NBrz/KsDdYuEPcIQv7N+f2LfEU6jhNG4Z8zt/lg9RnikrR4uljz89s1KO8u/z5CiPxBvpuynrymQuQxxxbCprHgWQfe2aZOhnVD4PSfUGcYtJ6uTgaRa0nHcSLXeaOSO+uG6YdpCwmPo/NP/mwICFU7lhBCCCGEMAZqNnVPkdLk/fImyF/nOUUOkyJdGI2yrg5sHNaAxqULEZ+kY9SKAD7/5wLJWp3a0YQQQgghhFqSE+D6Pv20d0v1cng1A1NLeHRD3/ReiGwiRbowKo425izqX5NhTb0AWHAwiL6LjvIwOuElawohhBBCiDxJraHXnmVpB6Ua66cvbVIvh8jzpEgXRsfURMMHfmX5qXc1bCxMOXTtIW/O8+dcaKTa0YQQQgghRE5Ta+i19BiavMtQbCL7SJEujFYbXzfWD6tPyYK2hEbE0eWnQ6w9eUvtWEIIQURsIj/uDWT5kWC1owghRN5nuB5dxabuKcq00f8NPQGP76ibReRZUqQLo1a6iD3rh9WnWdnCJCTrGLvqNFP/Pk+SXKcuhFBB4L1oJq07S50Zu/h662Xm7Loqn0dCCJGdUg291lTtNGDvCh7V9dOXt6ibReRZUqQLo+dobc6CvjUY2cwbgMX+N3h7wREeyHXqQogcoCgKB67ep//io7T4bh/LjgQTn6SjnJsD4/3KqB1PCCHytpSm7kVrgbWzullSSJN3kc3M1A4gREaYmGgY26oMFTwcGbfqNEeCwmk/9yDz365OZU8nteMJIfKg+CQt60+Fssg/iCt3owHQaKB52SK806AkdUq5oNFoVE4phBB5nDEMvfassu1g92f6HucTovUdygmRhVQ/k/7DDz9QokQJrKysqF27NkePHn3h8rNmzaJMmTJYW1vj6enJmDFjiI+Pz6G0Qm1+FVxZP6wepQrZEhYZT9efD7P6eIjasYQQeci9qHhmbr9MvS938+Has1y5G42NhSn965Vg97gmLOhXg7peBaRAF0KI7GYsQ689q1BZcC4B2gS4tlvtNCIPUvVM+sqVKxk7dizz58+ndu3azJo1Cz8/Py5fvkzhwoXTLL98+XI+/PBDFi1aRL169bhy5Qr9+/dHo9Hw3XffqfAMhBq8C+uvUx+78jQ7L97lgzVnOBsaycftymNhpvrvTkKIXOpcaCSLDgbx95nbJGkVADycrOlfrwTdanriaG2uckIhhMhnjGXotWdpNFCmHfz7A5xeAeXa6+cJkUVUrWi+++47Bg8ezIABAyhfvjzz58/HxsaGRYsWpbv8oUOHqF+/Pr169aJEiRK0atWKnj17vvTsu8h7HKzM+aVPdca0KA3A74dv0nvBv9x7LK0qhBAZp9UpbDt/h24/H+aNuQdZeyqUJK1C9eLO/Ni7Gvs+aMLgRqWkQBdCCDUY09Brz6rUVd+Z3eVNcHie2mlEHqPamfTExEROnDjBxIkTDfNMTExo0aIFhw8fTnedevXqsXTpUo4ePUqtWrW4fv06mzdvpk+fPs/dT0JCAgkJ/3UwFhUVlXVPQqjKxETDqBY+VPRwYPSKAI7deGS4Tr1qMSPpWEQIYZQexyex+vgtlhy6QXB4LABmJhra+roxsEFJqkhfF0II8XLaJLh5CK5shavbIT4SXEqBixcUKAUFvPXTLqVe7bptYxp67VnuVaHVF7BtImz/RP88y7ZVO5XII1Qr0h88eIBWq6VIkSKp5hcpUoRLly6lu06vXr148OABDRo0QFEUkpOTGTJkCB999NFz9zNjxgymTp2apdmFcWlerggbhtfn3T9OEHgvmu4//8vk9uXpXbuYXDMqhEglJDyWJYdusOpYCI8TkgH9CBK9ahejb93iuDlaq5xQCCGMXGy4vni+vAUCd0FCZOrHY+5DyJG069m5QoEnBXsBryeF/JP75ul89hrb0GvpqTMUHlyBE4vhr0EwcCu4GVGzfJFr5are3ffu3cv06dP58ccfqV27NoGBgYwaNYrPPvuMTz75JN11Jk6cyNixYw33o6Ki8PT0zKnIIoeUKmTH+mH1GbcqgG3n7/Lx+nMcvvaQ6Z19pZmqEPmQoig8jEkkJDyWkEdxhITHEhASwa6Ld9HpLzenVCFbBtYvSedqHthY5KqvQyGEyDmKAg+uwpUtcHkrhPwLiu6/x20KQmk/KN0aHItC+HX97eE1CL+m/xsXDtF39Leb/mn34VBUf+bdULh7Qdhp/WPGNPTaszQaaPuN/vkG7YM/e8LgXfqx1IV4DaodlRQsWBBTU1Pu3r2bav7du3dxdU3/jf3JJ5/Qp08fBg0aBICvry8xMTG8++67TJo0CZN0rlWxtLTE0tIy65+AMDp2lmb81Ls6Cw8G8dXWS2w6G8bpWxHM61VNmq4KkQfFJiYTEh5HcHjsk2L8yd/wOEIexRKbqE13vYY+BRnYoCSNfQphYiKtbYQQRkabDJHB+uL24TV4GKgvdiNvgV0RfRFbwPu/puTOJcDMIoszJOk7bbu8VV+ch19P/Xjh8vqivEwb8KgOJqb/PeZRLe324h7Bw+tPivbApwr46/oz8VG39Leg/WnXNaah19Jjag7dfoMFLeHhVX2hPmBz+q0DhMgg1Yp0CwsLqlevzq5du+jYsSMAOp2OXbt2MXz48HTXiY2NTVOIm5rqPxQURcnWvCJ3MDHRMLhRKWqWdGHEnycJCY/jrZ8OMaF1Wd5pUFIOyIXIQilnq0MfxREaEUd0fDJmphrMTU0wN9VgZmKCuZkJ5iYazJ7MMzc1+W8ZE/20makGC1MTzExNMDPRT5uYaEjS6giLiDcU38FPnRUPCY/lYUziC/NpNFDE3opiLjYUdbGmuIstrSu6UsbVPodeISGEeA6dDh7ffqoIv/5f8froBuiS0l/vwRW4cSD1PI0JOBVLXbinFPKORVMX0C8SG65vvn5li745e/xTzdhNzKFkQ31hXro1OBfP3PO1doai1fW3pykKxD5MfdbdUMhf1//4UPGtzO1LDdbO0GslLGgOt0/CuiHw1mLj6+xO5Bqqtu8bO3Ys/fr1o0aNGtSqVYtZs2YRExPDgAEDAOjbty8eHh7MmDEDgPbt2/Pdd99RtWpVQ3P3Tz75hPbt2xuKdSEAqng68c+Ihny09iybzobxxeaLHLr2gG+7VqaAnbSsECIjkrU67j5OeFKExxqK8VtP/t6OiCM+SffyDb0CEw0o6I/fXsTR2hxPF2s8nW2eFOM2eDpbU8zFBg9nayzN5LtBCKESRdFfn/302fCU4jP8OiTHPX9dU8unrt/21k87FoXHd1OfjX54TT9E2aMb+ltKR2uG7Vj8tw3Dtp5sz66IfjuXt+g7fgv+F5SnWiDZFAAfPyjTGryagWU2/MCp0YBtQf2tWO3UjymK/pZbCt0CXtB9KfzeES6sh72lodkktVOJXErVIr179+7cv3+fyZMnc+fOHapUqcLWrVsNnckFBwenOnP+8ccfo9Fo+PjjjwkNDaVQoUK0b9+eL774Qq2nIIyYo7U583pVpd7RAkz7+wJ7Lt+n7ZwDzOpelbpeBdSOJ4Tq4pO0hEbEGYrvZ//eiYpHq3txlazRQGF7SzycrHG0NidZp5CsVUjS6kjSKSRrdSRpdSRrFRKf/E3W6UhM1hmWTdSmLfRTdmthZkJR5/+K8JSC3NNFf5M+J0S2C9wJS7uonULkKM2TMa+f/NWYZGAeaeclJ0Di4+fvxsQMnIr/VzQbOlPzBgePjBWnigKP76Qt3B8GwqMg0CbqO1+7n06nzGZWkPzM0LWFyz+5vrwNFK2R8bPw2UGjyX1jj5doAO1nwYZhsP9rKOgDlbqpnUrkQholn7UTj4qKwtHRkcjISBwcHNSOI3LIpTtRDFt2kmv3YzDRwMjmPoxo5oOpNH8X+UR8kpazoZGcCn7EqeAITodEcDsy/qXrmZtqcHO0xsPJGg/n//4WffLX1dHqtc9WK4qCVqeQrHuqkNfqQAMFbS3zxWUq8t2U9bLsNZUiXbwWDTh6/leEP90c3amY/nrm7KLTQmTIf2fvnz6bHxGs7/zNxFxfWJZpoy/OnUtkX578ZMdk8J+tb8nQ75+0rQREvpSZ7yUp0kW+EZuYzOQN51lz4hYAdUq5MLtHVYo4WKmcTIispSgKNx7GEhCiL8hPBUdwMSyK5HTOittamKYqvt2d9NNFna3xcLKhkL2l/JiVA+S7Ketl2WuanADxUVkXTGSdrD7LqiiAkv5fRfeceTx/OVNzfYFuboTHGckJ+o7obAuBlXzmZDmdDlb1gUv/6Hu/H7w789fxizxHivQXkAMhse7ULSatO0dsohYXWwtmdqtM0zKF1Y4lxCuLik/idEjEk4L8EQEhETyKTdvpUCF7S6p6OlG1mDNVizlR1tUeR2tzNLmtOWEeJN9NWU9eUyGEqhJjYFFruHMGCpWDd7bLDyL5XGa+l2RgWJHvdKpalMpFnRi+/BQXwqIYsPgY7zYqxfhWZbAwyyWdk4h8S6tTuHL3MaeCIwxnygPvR6fpYM3C1ISKHg6GgrxqMWfcHa2kIBdCCCFygoUt9FwBvzaD+xdhzUD9fVMpv8TLyZl0kW/FJ2mZsfkivx2+CUBlTyfm9ayKp4uNysmESC0hWcuCA0EcvPqAM7ciiEln/O9iLjZULeZElSdnysu52UvP5rmIfDdlPXlNhRBGIfQkLG6r782/9hBo85XaiYRK5Ey6EBlgZW7K1A4VqetVkP+tOc3pkAjazjnAV10q0dbXTe14Qhh8u+0yvx4IMty3tTClsqeT/gy5pzNVijlRUIYWFEIIIYyPRzXo/DOs6gtH5us7D6w1WO1UwshJkS7yvdYVXano4cDIP09xMjiC95edpHftYnzyRnmszOVMpFDX1buPWex/A4AP/MrQvFxhfArbS2duQgghRG5RvgM0nwy7psGWCfre/b2aqZ1KGDG5AFcIoKizDSvfq8vQJl4ALDsSTMcf/Am8F61yMpGfKYrClL/Pk6xTaFm+CMOaelPW1UEKdCGEECK3aTAWKvcERQur+sP9y2onEkZMinQhnjA3NWFC67L8PrAWBe0suHTnMe3nHmT18RDyWdcNwkhsOXcH/8CHWJiZ8Em78mrHEU+Lug3HF8OpZWonEUIIkRtoNNB+NnjWgYRIWN4NYh6qnUoYKSnShXhGo9KF2DyyIfW9CxCXpOWDNWcYszKAx/Fph7QSIrvEJibz+T8XABjS2ItiBaRDQ1XpdHDrBOz+AuY3hO/KwT+j4eD3aicTQgiRW5hZQo9l4FQcHt2AlW/rx6wX4hlSpAuRjsIOVvw+sDbjW5XGRAPrA27Tbs5BTgU/UjuayCd+3HON25HxeDhZM7Sxl9px8qf4KLiwAda/DzNLw4JmsP9r/Zi3aMCjBlTqDtpktZMKIYTILWwLQq9VYOkAwYfg79GkGUdV5HvScZwQz2FqomF4Mx/qlCrAqBUBBIfH0nX+Yca0LM2Qxl5yXbDINjcexPDL/usAfPJGeawtpAPDHPPwGlzdDle2wg1/0D3VgsbCHrybQenW4N0S7Aqpl1MIIUTuVbgsdF0My7rB6eVQ0AcajlU7lTAiUqQL8RI1SriweVRDPlp3lk1nwvhm22UOXn3A992r4OpopXY8kQdN++cCiVodDX0K4lehiNpx8jZtEgT/qy/Kr2yDh1dTP+5SCkq3gdKtoFg9MLNQJ6cQQoi8xbuFfsz0zeNh11T90Gzl31Q7lTASUqQLkQGO1ubM61mVxj6F+HTjeQ5ff0ib2fv5qkslWlVwVTueyEN2XbzL7kv3MDfVMOXNCmg00mIjy8U8hMAd+qI8cJe+A58UJmZQvJ7+bLmPHxT0Vi+nEEKIvK3WYHhwFY7+DGvfBSdPcK+qdiphBKRIFyKDNBoN3Wp6Ur2EM6NWnOJcaBTv/nGCPnWKM6ldORlTXby2+CQtU//WdxY3sEFJvArZqZwoD9BpIeKm/iDozhm4ugNCjgJPXf9nU0BfkJdupR+31spRtbhCCCHyGb/pEH4NAnfCnz1h8G5wcFc7lVCZFOlCZJJXITv+GlqPb7dd5tcDQfzx702OBD1kbs9qlHG1VzueyMV+3X+d4PBYijhYMqKZj9pxcpeEx/pC/MFVeHBFf3sYqL9pE9Mu7+r7pDBvDR7VwER+ZBNCCKECUzN4axEsbAX3L8GK3jBop3wv5XNSpAvxCizNTJnUrjwNfQoxdtVprtyNpv28g3zcrhx96hSXJsoi0249iuWHvYEAfNS2HHaW8vGchqLoxyd/cCV1Mf7gKjy+/fz1zKyggI++Y56SDcGnFTgWzbncQgghxItYOUKvlTC/Edw+CefWQqWuaqcSKpKjQCFeQ6PShdg6uiEfrD7Nnsv3mbzhPPuv3OfrtyrjYisdTImMm775IvFJOmqVdOHNytLMDW0SXN4C9y+nLsaTYp6/jm1hKFhaX4wXLP3ftKMnmMiIo0IIIYyYcwmoPwJ2fw57voAKHcHUXO1UQiVSpAvxmgraWbKof00W+9/gyy2X2HnxHq1n7ef77lWo711Q7XgiFzh49QGbz97B1ETDVOksTm9VP7i8Ke18EzN9j+tPF+MFfPQdvFk753xOIYQQIqvUHgpHfoZHQXDqD6gxUO1EQiVSpAuRBTQaDQMblKROqQKM+PMk1+7H8PbCI7zXyItxrUpjbipn8UT6EpN1fLrxHAB96hSnnJuDyomMwPV9+gLdxAx8u0Gh0v+dGXcuIWcWhBBC5E2WdtBwPGydAPu+hso9wdxa7VRCBVI5CJGFyrs78M+IhvSsVQxFgfn7rvHWT4e4+fAFTXRFvvbboRtcux9DAVsLxrQsrXYc9el0sPNT/XSNgdDpJ2gwBsq20585lwJdCCFEXlZjgP4yrcdhcPRXtdMIlUiRLkQWs7YwZUZnX+a/XQ1Ha3NO34qk7ewDrD15S+1owsjci4pn1s4rAExoUxZHaylAubAObp8CCzto9D+10wghhBA5y8wSmnyonz74HcRHqZtHqEKKdCGySeuKbmwZ1ZBaJV2ISdQydtVpRq84xeP4JLWjCSMxY8slYhK1VPF04q1q0ts4yYmw6zP9dL2RYFdI3TxCCCGEGir10F/iFfcIDv+gdhqhAinShchG7k7W/Dm4DuNalsbURMP6gNu0nXOAk8GP1I4mVHY0KJx1p0LRaGBahwqYmEhncZxYou8sx7Yw1B2mdhohhBBCHaZm0HSSfvrwPIh5oG4ekeOkSBcim5maaBjR3IdV79WlqLM1IeFxdJt/mF/2X0OnU9SOJ1SQrNUxeYO+s7geNYtRqaiTuoGMQcJj2PeVfrrJBH3nOUIIIUR+Ve5NcKsMidFw8Hu104gcJkW6EDmkenFnNo9qSPvK7iTrFKZvvsTg34/zKCZR7Wgihy0/GsylO49xtDbnA78yascxDofmQuwDcPGCav3UTiOEEEKoy8QEmk3WTx/9FSKlb6P8RIp0IXKQg5U5c3pUYXonXyzMTNh16R7t5hzgxE1p/p5fPIxO4NttlwEY71cGF1sLlRMZgcd34dA8/XTzydKDuxBCCAHg3RyK1wdtgn5INpFvSJEuRA7TaDT0ql2M9e/Xp2RBW25HxtP958P8vE+av+cH32y7TFR8MuXdHOhVq5jacYzDvq8gKQY8akD5DmqnEUIIIYyDRgPNPtFPn1oKD6+pm0fkGCnShVBJeXcH/h7RwND8fcaWSwyS5u952umQCFYeDwH0ncWZSmdx8CBQ32EcQMup+gMSIYQQQugVrws+rUDRwp4v1E4jcogU6UKoyM7SLFXz992G5u/hakcTWUynU5i88TyKAp2reVCjhIvakYzD7mn6Aw8fPyjRQO00QgghhPFJOZt+7i+4c1bdLCJHSJEuhMrSa/7e7ed/pfl7HrPmxC1Oh0RgZ2nGh23Kqh3HONw6Dhc2ABpoMUXtNEIIIYRxcqsEFTrrp3d/rm4WkSOkSBfCSKQ0f3+zsjtaaf6ep0TGJvHV1ksAjG7hQ2F7K5UTGQFFgR1Peq2t0guKlFc3jxBCCGHMmk4CjSlc2QrB/6qdRmQzKdKFMCJ2lmbMfqb5e1tp/p7rfb/zCg9jEvEubEe/eiXUjmMcrm6Hm/5gaglNP1I7jRBCCGHcCnpD1d766V3T9D92izxLinQhjMzTzd9LFbQlTJq/52oXw6L4/fANAKa+WQFzU/nYRaeFnVP007XfA8eiqsYRQgghcoXGE8DUQv8j97VdaqcR2UiOFoUwUuXdHdgozd9zNUVR+HTDeXQKtPN1o753QbUjGYfTK+DeBbByhIZj1U4jstmMGTOoWbMm9vb2FC5cmI4dO3L58uWXrrd69WrKli2LlZUVvr6+bN68OQfSCiGEEXMsCjUH6aflbHqeJkW6EEZMmr/nbhtP3+bojXCszU35qF05teMYh6S4/4aQaTgOrJ3VzSOy3b59+xg2bBj//vsvO3bsICkpiVatWhETE/PcdQ4dOkTPnj155513OHXqFB07dqRjx46cO3cuB5MLIYQRajgOLOwg7DRc3Kh2GpFNNIqSv36CiYqKwtHRkcjISBwcHNSOI0SGXbgdxfDlJ7n+IAZTEw0f+JXh3YalMJGxto1SdEIyzb7dy73HCXzgV4ZhTb3VjmQc/GfrO4xzKAojToC5dKIH+eu76f79+xQuXJh9+/bRqFGjdJfp3r07MTEx/PPPP4Z5derUoUqVKsyfPz9D+8lPr6kQIp/Z/QXs/xoKloahh8HUTO1EIgMy870kZ9KFyCWebf7+5ZZLvPPbMcKl+btRmrvrKvceJ1CigA2DGpZUO45xiHsEB2bqp5t+JAV6PhUZGQmAi4vLc5c5fPgwLVq0SDXPz8+Pw4cPP3edhIQEoqKiUt2EECJPqjdc3xLtwRU4s1LtNCIbSJEuRC6S0vx9Rmd98/c9l+/Tbs4Bjt+Q5u/GJPBeNAsPBgHwafsKWJqZqpzISBz4DuIjoXAFqNxD7TRCBTqdjtGjR1O/fn0qVqz43OXu3LlDkSJFUs0rUqQId+7cee46M2bMwNHR0XDz9PTMstxCCGFUrByhwRj99N4vITlB3Twiy0mRLkQuo9Fo6Fkrde/v3X/5l1k7r5Ck1akdTwDzdl8lWafQolxhmpYtrHYc4xARAkd+1k+3mAIm8sNFfjRs2DDOnTvHihUrsnzbEydOJDIy0nALCQnJ8n0IIYTRqDkY7FwhMhhOLFE7jchiUqQLkUulNH/vUEXf/H3Wzqu8Nf8w1+9Hqx0tX4tJSGbb+bsAch360/bOAG0CFG8APi3VTiNUMHz4cP755x/27NlD0aIvHnbP1dWVu3fvppp39+5dXF1dn7uOpaUlDg4OqW5CCJFnWdhA4w/00/u/gcTnd8Ypch8p0oXIxewszZjVvQqze1TBwcqM0yERtJ1zgD8O3yCf9QlpNLZfuENckpaSBW2p4umkdhzjcPc8BCzXT7ecBhrp7DA/URSF4cOHs27dOnbv3k3Jki/vo6Fu3brs2pV6DOAdO3ZQt27d7IophBC5T9W+4FwCYu7Dvz+pnUZkISnShcjlNBoNHap4sG1MI+p7FyA+SccnG87Tb/Ex7kbFqx0v31l36jYAHaq4o5FiVG/nVECB8h2gaHW104gcNmzYMJYuXcry5cuxt7fnzp073Llzh7i4OMMyffv2ZeLEiYb7o0aNYuvWrcycOZNLly4xZcoUjh8/zvDhw9V4CkIIYZzMLKDJR/pp/zn6DlpFniBFuhB5hJujNX8MrM2n7ctjaWbC/iv38Zu1n3/O3FY7Wr5x73E8B6/eB6BjFQ+V0xiJGwfh6jbQmELzT9VOI1Tw008/ERkZSZMmTXBzczPcVq78r0fi4OBgwsLCDPfr1avH8uXL+eWXX6hcuTJr1qxh/fr1L+xsTggh8iXft6BweUiI1BfqIk+QcdKFyIMC7z1mzMrTnA3VD3XUsYo7UztUxNHaXOVkeduig0FM++cCVYs5se79+mrHUZ+iwILmEHoCarwDb3yndiKjJd9NWU9eUyFEvnFpE6zoBeY2MDIA7Iu8dBWR82ScdCHyOe/C9qx9vx4jm3ljooH1AbdpPWs//oEP1I6Wp60PCAWgU1U5iw7AhQ36At3cFhpPUDuNEEIIkTeVaQseNSApFg58q3YakQWkSBcijzI3NWFsqzKsGVqPEgVsCIuMp/eCI0z9+zzxSVq14+U51+5Hc+ZWJKYmGtr5uqkdR33aJNg1TT9db7j8qi+EEEJkF40Gmk/WTx9fDI9uqptHvDYp0oXI46oVc2bzqIb0rl0MgMX+N3hj7kHO3opUOVnesuGU/ix649KFKGBnqXIaI3DyNwi/BjYFod4ItdMIIYQQeVupxlCyMeiSYO+XaqcRr0mKdCHyARsLM77o5MviATUpZG9J4L1oOv3oz7zdV0nW6tSOl+spisK6J03dO0pTd0iIhr1f6acbTwBLe3XzCCGEEPlBytn0Myvg3iV1s4jXIkW6EPlI0zKF2Ta6EW0qupKsU/h2+xW6/nyYGw9i1I6Wq50MfkRIeBy2Fqa0LCfNujn8A8TcA+eSUL2/2mmEEEKI/KFoDSj7Big62POF2mnEa5AiXYh8xsXWgh97V+O7bpWxtzTjVHAEbWYfYNmRm+SzwR6yzLonTd39KrpibWGqchqVRd+HQ0+GgGk+WT+GqxBCCCFyRtNJgAYuboTQk2qnEa9IinQh8iGNRkPnakXZOqYRdUsVIC5Jy6R15xi45Bj3ouLVjperJCbr2HRGP76z9OoO7P8aEqPBvSqU76h2GiGEECJ/KVIeKnXTT+/+TN0s4pVJkS5EPubhZM2yQbX5uF05LMxM2HP5Pn6z9rPlbJja0XKN/Vfu8yg2iUL2ltTzKqh2HHU9vAbHF+mnW04DE/mKEUIIIXJck4lgYgbXdkPQAbXTiFcgR1BC5HMmJhoGNSzFPyMaUN7NgUexSQxddpKxKwOIik9SO57RS+kw7s3K7piaaFROo7Ldn4MuGbxbQMlGaqcRQggh8ieXklCtn3561zSQyxlzHSnShRAAlC5iz/ph9RnW1AsTDaw9FUqbWQc4dO2B2tGM1uP4JHZeuAtIU3dCT8D5tYAGWkxRO40QQgiRvzX6AMys4dZR/Xe0yFWkSBdCGFiYmfCBX1lWD6lLMRcbQiPi6PXrET775wLxSVq14xmdrefukJCsw7uwHRXcHdSOo65dT657q9QdXH3VzSKEEELkdw5uULqVfvrqDnWziEyTIl0IkUb14i5sGdWQnrWKAbDwYBDt5x7kXGikysmMy/onTd07VfVAo8nHTd3jo+D6Xv10kw9VjSKEEEKIJ7xb6v8G7lQ3h8g0KdKFEOmytTRjRmdfFvWvQUE7S67ei6bjD/7M232VZK1O7XiquxMZz6FrDwH99ej5WugJQAGnYvrr4IQQQgihPu/m+r+hJyA2XN0sIlOkSBdCvFCzskXYPqYRbSq6kqxT+Hb7Fbr+fJgbD2LUjqaqjadDURSoWcIZTxcbteOo69Yx/d+iNdXNIYQQQoj/OLhD4QqAou/pXeQaUqQLIV7KxdaCH3tX47tulbG3NONUcARtZh9g6b83UfJpj6HrT90GoGN+7zAOIOSo/m/RWurmEEIIIURqKWfTpcl7riJFuhAiQzQaDZ2rFWXrmEbULVWAuCQtH68/R//Fx7gbFa92vBx1+c5jLoRFYW6qoZ2vm9px1KXT/Xcm3VPOpAshhBBGxbuF/m/gLv13tsgVpEgXQmSKh5M1ywbV5pM3ymNhZsK+K/fxm7WfTWfC1I6WY1I6jGtSpjBONhYqp1FZ+DWIjwAzKygivboLIYQQRqVYXTC3hZh7cPes2mlEBkmRLoTINBMTDe80KMmmEQ2o6OFARGwSw5afZPSKU0TGJakdL1vpdAobA/RN3fP92OjwX1N396pgls9/sBBCCCGMjZkFlGqsn5Ym77mGFOlCiFfmU8SetUPrM6KZNyYaWB9wm9az9uMf+EDtaNnm2I1wQiPisLc0o1nZwmrHUd+tlOvRpam7EEIIYZRSrku/KkV6biFFuhDitViYmTCuVRnWDK1HiQI2hEXG03vBEaZsPE98klbteFkupal7G19XrMxNVU5jBEKkZ3chhBDCqHk9KdJDjkB8pLpZRIZIkS6EyBLVijmzeVRD3q5TDIAlh27Qbs4BztyKUDdYFkpI1hquvZde3YH4KLh3QT/tKT27CyGEEEbJpSQU8AZFC9f3qZ1GZIAU6UKILGNjYcbnHX1ZMqAmhe0tuXY/hs4/HmL2zqska3N/j6J7Lt0nKj4ZN0cr6pQsoHYc9YWeABRwLAb2rmqnEUIIIcTzeLfU/5Xr0nMFKdKFEFmuSZnCbBvdiHaV3EjWKXy/8wrdfj7M7Yg4taO9lvWn9E3d36zijomJRuU0RuDWcf1fGXpNCCGEMG5PD8WmKOpmES8lRboQIls421owr2dVZveogr2VGSeDI2g35wB7L99TO9oriYxNYvclffaOVaSpO/BUp3HS1F0IIYQwaiXq64dLjboF9y+pnUa8hBTpQohso9Fo6FDFg00jGlLRw4FHsUkMWHKMmdsvo9Xlrl9xN58LI1Gro6yrPeXcHNSOoz5FgVtPOo2TM+lCCCGEcTO3huL19dPS5N3oqV6k//DDD5QoUQIrKytq167N0aNHX7h8REQEw4YNw83NDUtLS0qXLs3mzZtzKK0Q4lUUK2DDmiH1eLtOMRQF5u4O5O0FR7j3OF7taBmW0tRdOox74mEgxD3S/ypfxFftNEIIIYR4GUOTdynSjZ2qRfrKlSsZO3Ysn376KSdPnqRy5cr4+flx7176zWETExNp2bIlN27cYM2aNVy+fJlff/0VDw85aBbC2FmZm/J5R19m96iCjYUph68/pO3sgxy+9lDtaC8VGhHHkaBwNBp4s7K72nGMQ8iTH1TdqoCZhapRhBBCCJEBPk86j7t5CBJj1M0iXkjVIv27775j8ODBDBgwgPLlyzN//nxsbGxYtGhRussvWrSI8PBw1q9fT/369SlRogSNGzemcuXKOZxcCPGqOlTxYOPwBpQpYs+D6AR6L/iXH/YEojPi5u8bnoyNXrukC+5O1iqnMRIp16NLU3chhBAidyjgDU7FQJsINw6qnUa8QKaL9BIlSjBt2jSCg4Nfa8eJiYmcOHGCFi1a/BfGxIQWLVpw+PDhdNfZuHEjdevWZdiwYRQpUoSKFSsyffp0tFrtc/eTkJBAVFRUqpsQQl3ehe1YP6w+XaoVRafAN9suM/C3YzyKSVQ7WhqKohiauneSpu7/SenZXTqNE0IIIXIHjea/Ju9Xd6ibRbxQpov00aNHs3btWkqVKkXLli1ZsWIFCQkJmd7xgwcP0Gq1FClSJNX8IkWKcOfOnXTXuX79OmvWrEGr1bJ582Y++eQTZs6cyeeff/7c/cyYMQNHR0fDzdPTM9NZhRBZz9rClJndKvN1l0pYmpmw9/J92s05wImbj9SOlsrFsMdcuRuNhZkJrSu6qR3HOCQ8hnsX9NOeUqQLIYQQuYZcl54rvFKRHhAQwNGjRylXrhwjRozAzc2N4cOHc/LkyezIaKDT6ShcuDC//PIL1atXp3v37kyaNIn58+c/d52JEycSGRlpuIWEhGRrRiFE5nSr6cn6YfUpWdCW25HxdP/5MAsOXEcxkjE81z9p6t68bGEcrc1VTmMkQk+AogPHYmDvqnYaIYQQQmRUyUZgYg6PguDhNbXTiOd45WvSq1Wrxpw5c7h9+zaffvopCxYsoGbNmlSpUoVFixa99AC7YMGCmJqacvfu3VTz7969i6tr+gd9bm5ulC5dGlNTU8O8cuXKcefOHRIT028ma2lpiYODQ6qbEMK4lHNzYOPw+rSr5EayTuHzTRcZsvQEkXFJqubS6hTD9ejSq/tTQp4MvVa0hro5hBBCCJE5lvZQrI5+OnCXulnEc71ykZ6UlMSqVat48803GTduHDVq1GDBggV06dKFjz76iN69e79wfQsLC6pXr86uXf+9OXQ6Hbt27aJu3brprlO/fn0CAwPR6XSGeVeuXMHNzQ0LC+ldWIjczN7KnHk9qzKtQwXMTTVsO3+X9nMPci40UrVMR64/5G5UAo7W5jQpU0i1HEbH0GmcNHUXQgghch1p8m70Ml2knzx5MlUT9woVKnDu3DkOHjzIgAED+OSTT9i5cyfr1q176bbGjh3Lr7/+ym+//cbFixcZOnQoMTExDBgwAIC+ffsyceJEw/JDhw4lPDycUaNGceXKFTZt2sT06dMZNmxYZp+GEMIIaTQa+tYtwZoh9SjqbE1weCydfzrEsiM3VWn+vu5Jh3HtKrlhaWb6kqXzCUWBWyln0qVIF0IIIXKdlCL9xgFIilc3i0iXWWZXqFmzJi1btuSnn36iY8eOmJunvUazZMmS9OjR46Xb6t69O/fv32fy5MncuXOHKlWqsHXrVkNncsHBwZiY/Pc7gqenJ9u2bWPMmDFUqlQJDw8PRo0axYQJEzL7NIQQRqyypxObRjRk3OoAdl68x6R15zgaFM70Tr7YWmb6Y+uVxCdp2XJO34llxyrS1N3g4TWIewRmVuDqq3YaIYQQQmRWkQpg5wrRdyD4EHg1UzuReIZGyeTpqZs3b1K8ePHsypPtoqKicHR0JDIyUq5PF8LIKYrCrweu89XWy2h1Cl6FbPmxd3XKuNpn+77/OXOb4ctP4eFkzYH/NcXERJPt+8wVApbD+qHgWQfe2aZ2mjxDvpuynrymQgjxAuuHQcBSqDsc/L5QO02+kJnvpUw3d7937x5HjhxJM//IkSMcP348s5sTQojn0mg0vNvIi5Xv1sHVwYpr92Po8MNB/jpxK9v3vf7UbQA6VnWXAv1pISnXo9dUN4cQQgghXp2PXJduzDJdpA8bNizdYcxCQ0Pl2nAhRLaoUcKFTSMb0NCnIPFJOsatPs341aeJjM2e3t/DYxLZe/keIE3d0zBcjy5FuhBCCJFrlWoCGhO4fwkiZIhqY5PpIv3ChQtUq1YtzfyqVaty4cKFLAklhBDPKmBnyZIBtRjTojQaDaw5cYvm3+3j79O3s7xTuU1nw0jWKVRwd8CnSPY3rc81Eh7DvSef89JpnBBCCJF7WTv/94P7NRmKzdhkuki3tLRMM7Y5QFhYGGZmOdOhkxAifzI10TCqhQ8r362LVyFbHkQnMOLPUwxYcoyQ8Ngs28/6J726d5Kx0VMLPQmKDhw9wcFN7TRCCCGEeB0pvbxf3aFuDpFGpov0Vq1aMXHiRCIj/xu7OCIigo8++oiWLVtmaTghhEhPrZIubB7VkNEtfLAwNWHv5fu0+n4/v+y/RrJW91rbDn4Yy4mbjzDRQPvK7lmUOI9IGR9dmroLIYQQuZ93c/3f6/tAmz2XEIpXk+ki/dtvvyUkJITixYvTtGlTmjZtSsmSJblz5w4zZ87MjoxCCJGGpZkpo1uUZvOohtQu6UJckpbpmy/x5jx/TodEvPJ2NwToz6LX8ypIEQerLEqbR4Q8uR7dU5q6CyGEELmeW1WwKQCJj//rGFYYhUwX6R4eHpw5c4avv/6a8uXLU716dWbPns3Zs2fx9PTMjoxCCPFc3oXtWPFuHb7uUglHa3MuhEXR6Ud/pv59nuiE5ExtS1EU1j0p0jtKU/fUFOWpTuOkSBdCCCFyPRMT8HpyNl16eTcqr3QRua2tLe+++25WZxFCiFei0WjoVtOTZuUK8/k/F1gfcJvF/jfYeu4O0zpUpGX5IhnazrnQKK7fj8HK3AS/ChlbJ994eA3iwsHUElx91U4jhBBCiKzg3QLOrtIX6S0+VTuNeOKVe3q7cOECwcHBJCYmppr/5ptvvnYoIYR4FQXtLJnVoyqdqxVl0vqzhITHMfj347Su4MqUNyvg6vji5uvrnnQY17K8K/ZW5jkROfdIuR7dvQqYWagaRQghhBBZxKuZ/u+dM/D4LtjLSQpjkOki/fr163Tq1ImzZ8+i0WgMQx9pNBoAtFpt1iYUQohMalS6ENtHN2b2rqv8euA6W8/f4WDgA/7Xugy9axfH1ESTZp1krY6Np28D0LGKdBiXhoyPni+FhISg0WgoWrQoAEePHmX58uWUL19eWtQJIUReYFcI3KpAWIB+KLYqvdROJHiFa9JHjRpFyZIluXfvHjY2Npw/f579+/dTo0YN9u7dmw0RhRAi86wtTPmwTVn+GdGAKp5ORCckM3nDebr8dIiLYVFplve/9pAH0Qk425jTqHQhFRIbOek0Ll/q1asXe/bsAeDOnTu0bNmSo0ePMmnSJKZNm6ZyOiGEEFnC58kIXXJdutHIdJF++PBhpk2bRsGCBTExMcHExIQGDRowY8YMRo4cmR0ZhRDilZVzc+CvofWY1qECdpZmBIRE0H7uQb7ccom4xP9a/mx40tS9fWV3zE0z/dGYtyU8hnvn9dPSaVy+cu7cOWrV0v+br1q1iooVK3Lo0CGWLVvGkiVL1A0nhBAia6SMl35tN+ikVbQxyPSRqFarxd7eHoCCBQty+7a+eWjx4sW5fPly1qYTQogsYGqioW/dEuwc25jWFVxJ1inM33cNv1n7OXD1PrGJyWw9fweQXt3TFXoSFB04eoKDm9ppRA5KSkrC0tISgJ07dxr6nSlbtixhYWFqRhNCCJFVPGqApSPEPYLbp9ROI3iFIr1ixYqcPn0agNq1a/P111/j7+/PtGnTKFWqVJYHFEKIrOLqaMX8PtX5tW8N3BytCA6Ppc/Co/T45V9iE7UUL2BDVU8ntWMan5RO44rWUDeHyHEVKlRg/vz5HDhwgB07dtC6dWsAbt++TYECBVROJ4QQIkuYmoFXE/301R2qRhF6mS7SP/74Y3Q6HQDTpk0jKCiIhg0bsnnzZubMmZPlAYUQIqu1LF+EHWMb079eCTQaOHMrEoAOVTwMnWCKp4TI+Oj51VdffcXPP/9MkyZN6NmzJ5UrVwZg48aNhmbwQggh8oCUJu9yXbpRyHTv7n5+foZpb29vLl26RHh4OM7OznJwK4TINewszZjyZgU6VfXgkw3nCIuMp3tNT7VjGR9F+a9nd+k0Lt9p0qQJDx48ICoqCmdnZ8P8d999FxsbmwxtY//+/XzzzTecOHGCsLAw1q1bR8eOHZ+7/N69e2natGma+WFhYbi6umb6OQghhMiAlCI99ATEhoONi7p58rlMnUlPSkrCzMyMc+fOpZrv4uIiBboQIleq7OnExuENOPpRczycrNWOY3zCr0NcOJhagmsltdOIHBYXF0dCQoKhQL958yazZs3i8uXLFC5cOEPbiImJoXLlyvzwww+Z2vfly5cJCwsz3DK6PyGEEK/AwR0KVwAUfQdyQlWZOpNubm5OsWLFZCx0IUSeIz80PkfIk+vR3auAmYWqUUTO69ChA507d2bIkCFERERQu3ZtzM3NefDgAd999x1Dhw596TbatGlDmzZtMr3vwoUL4+Tk9AqphRBCvBLv5vrRXAJ3ge9baqfJ1zJ9TfqkSZP46KOPCA8Pz448QgghjImh07ia6uYQqjh58iQNGzYEYM2aNRQpUoSbN2/y+++/Z3s/NFWqVMHNzY2WLVvi7+//0uUTEhKIiopKdRNCCJEJT1+X/qQPMqGOTF+TPm/ePAIDA3F3d6d48eLY2tqmevzkyZNZFk4IIYTKDJ3GSZGeH8XGxhqGXd2+fTudO3fGxMSEOnXqcPPmzWzZp5ubG/Pnz6dGjRokJCSwYMECmjRpwpEjR6hWrdpz15sxYwZTp07NlkxCCJEvFKsD5rYQcw/ungW3ymonyrcyXaS/qLMXIYQQeUhCtL7ZG0incfmUt7c369evp1OnTmzbto0xY8YAcO/ePRwcHLJln2XKlKFMmTKG+/Xq1ePatWt8//33/PHHH89db+LEiYwdO9ZwPyoqCk9P6QxSCCEyzMwSSjWGy5v1Z9OlSFdNpov0Tz/9NDtyCCGEMDa3T4KiA4ei+g5lRL4zefJkevXqxZgxY2jWrBl169YF9GfVq1atmmM5atWqxcGDB1+4jKWlJZaWljmUSAgh8ijv5k+K9F3QcJzaafKtTBfpQggh8omUTuM8pal7fvXWW2/RoEEDwsLCDGOkAzRv3pxOnTrlWI6AgADc3NxybH9CCJFveTXX/w05AvGRYOWobp58KtNFuomJyQt7QZae34UQIo9IGR+9qDR1z89cXV1xdXXl1q1bABQtWpRatTL+noiOjiYwMNBwPygoiICAAFxcXChWrBgTJ04kNDSU33//HYBZs2ZRsmRJKlSoQHx8PAsWLGD37t1s3749a5+YEEKItFxKQgFveBgI1/dB+TfVTpQvZbpIX7duXar7SUlJnDp1it9++006bBFCiLxCUf4r0uV69HxLp9Px+eefM3PmTKKjowGwt7dn3LhxTJo0CROTlw8Sc/z4cZo2bWq4n3LdeL9+/ViyZAlhYWEEBwcbHk9MTGTcuHGEhoZiY2NDpUqV2LlzZ6ptCCGEyEbeLfVFeuBOKdJVolEURcmKDS1fvpyVK1eyYcOGrNhctomKisLR0ZHIyMhs6/RGCCFyvYfXYG41MLWEibdkjPRsZqzfTRMnTmThwoVMnTqV+vXrA3Dw4EGmTJnC4MGD+eKLL1RO+HzG+poKIYTRu7oTlnXR90kz5hy8oBW1yLjMfC9l2TXpderU4d13382qzQkhhFBTyll0t8pSoOdjv/32GwsWLODNN/87k1KpUiU8PDx4//33jbpIF0II8YpK1AczK4i6BfcvQ+GyaifKd17eTi0D4uLimDNnDh4eHlmxOSGEEGozdBonTd3zs/DwcMqWTXtwVrZsWcLDw1VIJIQQItuZW0NxfespAneqmyWfynSR7uzsjIuLi+Hm7OyMvb09ixYt4ptvvsmOjEIIIXLarSdFelHp2T0/q1y5MvPmzUszf968eVSqVEmFREIIIXKEdwv938Ad6ubIpzLd3P37779P1bu7iYkJhQoVonbt2jg7O2dpOCGEECpIiIa75/XTciY9X/v6669p164dO3fuNIyRfvjwYUJCQti8ebPK6YQQQmQbn5awbSLcPASJMWBhq3aifCXTRXr//v2zIYYQQgijcfskKDp9hzEO7mqnESpq3LgxV65c4YcffuDSpUsAdO7cmXfffZfPP/+chg0bqpxQCCFEtijgDU7FICIYbhyE0n5qJ8pXMl2kL168GDs7O7p27Zpq/urVq4mNjaVfv35ZFk4IIYQKDNejS1N3Ae7u7mk6iDt9+jQLFy7kl19+USmVEEKIbKXR6Ju8H1+kvy5divQclelr0mfMmEHBggXTzC9cuDDTp0/PklBCCCFUdOu4/q9cjy6EEELkX4br0qXzuJyW6SI9ODiYkiVLpplfvHhxgoODsySUEEIIlSjKU53GyfXoQgghRL5VshGYmEP4dXh4Te00+Uqmi/TChQtz5syZNPNPnz5NgQIFsiSUEEIIlYRfh9iHYGoBbtJ7txBCCJFvWdpDsTr66cBd6mbJZzJ9TXrPnj0ZOXIk9vb2NGrUCIB9+/YxatQoevTokeUBhRBC5KBbx/R/3aqAmaWqUYR6Onfu/MLHIyIiciaIEEIIdXm3gBsH9E3ea7+rdpp8I9NF+meffcaNGzdo3rw5Zmb61XU6HX379pVr0oUQIrczdBonTd3zM0dHx5c+3rdv3xxKI4QQQjXeLWDnp/pCPSkezK3UTpQvZLpIt7CwYOXKlXz++ecEBARgbW2Nr68vxYsXz458QgghclLKmXTpNC5fW7x4sdoRhBAiS914EMPRoHDaV3bH2sJU7Ti5R5EKYOcK0Xcg+DB4NVU7Ub6Q6SI9hY+PDz4+PlmZRQghhJoSY+Duef20FOlCCCHygDO3Ivh533W2nAtDp8C525FM61BR7Vi5R8pQbAFL9U3epUjPEZnuOK5Lly589dVXaeZ//fXXacZOF0IIkYuEngRFCw4e4OihdhohhBDilSiKwr4r9+n167+8Oc+fTWf1BTrA6uO3iIxNUjdgbuMjQ7HltEwX6fv376dt27Zp5rdp04b9+/dnSSghhBAqMAy9JmfRhRBC5D7JWh0bAkJpO+cg/RYd5dC1h5iZaOhc1YMtoxpS1tWeuCQtK4/LsNGZUqoJaEzg/iWICFE7Tb6Q6ebu0dHRWFhYpJlvbm5OVFRUloQSQgihgpAn16NLp3FCCCFykdjEZFYdC+HXA0GERsQBYGNhSo+axXinYUk8nKwBGFC/BBP+Ostvh24ysH5JzEwzfb4yf7J21v+AH3IEru2C6v3VTpTnZfqd6evry8qVK9PMX7FiBeXLl8+SUEIIIXKYojx1Jl2KdCGEEMYvPCaR73dcof6Xu5ny9wVCI+IoYGvBuJalOfRhMya3L28o0AE6VPHAxdaC0Ig4dly4q2LyXMhbmrznpEyfSf/kk0/o3Lkz165do1mzZgDs2rWL5cuXs2bNmiwPKIQQIgc8CoLYh2BqAW6V1E4jhBBCPFdIeCwLDlxn5fEQ4pN0ABRzsWFwo1J0rV4UK/P0e2+3MjelV61izNsTyCL/INr4uuVk7NzNuzns+QKu7wNtEpiaq50oT8t0kd6+fXvWr1/P9OnTWbNmDdbW1lSuXJndu3fj4uKSHRmFEEJkt5Sm7m6VwcxS3SxCCCFEOs6FRvLL/utsOhuG9klPcL4ejgxp7EXriq6Ymmheuo0+dYszf981jt14xLnQSCp6OGZ37LzBrSrYFND/oB9yFErUVztRnvZKQ7C1a9eOdu3aARAVFcWff/7J+PHjOXHiBFqtNksDCiGEyAHS1F0IIYQRUhSFQ9ceMn/fNQ5cfWCY36h0IYY0KkVdrwJoNC8vzlMUcbCiXSU3NgTcZpF/EN91q5INqfMgExN9k/czK+HSJinSs9kr95awf/9++vXrh7u7OzNnzqRZs2b8+++/WZlNCCFETgl5UqR7Ss/uQggh1KfVKfxz5jZvzvOn94IjHLj6AFMTDR2quLNpZAN+H1iLet4FM1WgpxhQvyQAf5++zb3H8VkdPe8q31H/9/w60OlUjZLXZepM+p07d1iyZAkLFy4kKiqKbt26kZCQwPr166XTOCGEyK0SY+Duef20nEkXQgihsst3HjNudQDnQvUjR1mZm+h7am9QEk8Xm9fefhVPJ6oVc+JkcATL/g1mTMvSr73NfMG7OVg6wuPbEPIvFK+ndqI8K8Nn0tu3b0+ZMmU4c+YMs2bN4vbt28ydOzc7swkhhMgJoSdB0YKDBzh6qJ1GCCFEPqXVKfy09xrt5x7kXGgUDlZmjG7hw6EPmzPlzQpZUqCnGNhAfzZ92ZGbJCTL5boZYmYJ5d7QT5/7S90seVyGz6Rv2bKFkSNHMnToUHx8fLIzkxBCiJx060mncUWlqbsQQgh1XL8fzfjVpzkZHAFA87KFmdHFl8L2VtmyP78Krrg5WhEWGc/fp8N4q3rRbNlPnlOxMwQsg/ProfVXYPpKXZyJl8jwmfSDBw/y+PFjqlevTu3atZk3bx4PHjx4+YpCCCGMmxTpQgghVKLTKSzxD6LtnAOcDI7A3tKMb96qxIJ+NbKtQAcwNzWhb90SACw6GISiKNm2rzylZOMnvbw/gBsH1E6TZ2W4SK9Tpw6//vorYWFhvPfee6xYsQJ3d3d0Oh07duzg8ePH2ZlTCCFEdlCUpzqNk+vRhRBC5JyQ8Fh6LzjClL8vEJ+ko4F3QbaOaUTXGp6v1CFcZvWs5YmVuQkXwqI4GhSe7fvLE0zNodyb+mlp8p5tMt27u62tLQMHDuTgwYOcPXuWcePG8eWXX1K4cGHefPPN7MgohBAiuzwK0v8abmqhHyNdCCGEyGaKorDiaDCtZ+3n8PWHWJub8lmHCvw+sBYeTtY5lsPJxoJOVfXN3Bf5B+XYfnO9il30fy9uhOREdbPkUa88BBtAmTJl+Prrr7l16xZ//vlnVmUSQgiRU0KeNHV3q6zvEEYIIYTIRnej4hmw5Bgfrj1LTKKWmiWc2TKqIX3qlsDEJPvPnj9rYP0SAOy4cJeQ8Ngc33+uVLwe2LlCfCRc2612mjzptYr0FKampnTs2JGNGzdmxeaEEELklFtPmrrL0GtCCCGykaIobAgIpdX3+9l7+T4WZiZMaluOFe/WpURBW9Vy+RSxp6FPQXQK/Hbohmo5chUTU6jQUT99fq2qUfKqLCnShRBC5FIpncZ5SqdxQgghssfD6ATeX3aSUSsCiIxLolJRRzaNaMDgRqUwVeHs+bMG1tcPx7byeAjRCckqp8klUpq8X9oESXHqZsmDpEgXQoj8KjEG7pzTT0vP7kIIIbLB1nN3aPX9fracu4OZiYaxLUvz19B6+BSxVzuaQePShShV0JbH8cn8deKW2nFyh6I1wbEYJEbD1e1qp8lzpEgXQoj86vYpULRg7w6OMj6sEEKIrBMZm8SYlQEMWXqChzGJlHW1Z/2w+oxs7oO5qXGVICYmGvo/uTZ9yaEb6HQyHNtLaTRQsZN++pw0ec9qxvU/RAghRM4xDL0mZ9GFEEJknb2X79Fq1j7WnQrFRAPvN/Fiw/D6VPRwVDvac3WpVhR7KzOCHsSw98o9tePkDhU66/9e2QYJMhx3VpIiXQgh8quU69Gl0zghhBBZIDohmYlrz9J/8THuRiVQqqAta4bW43+ty2JpZqp2vBeytTSjR01PABb731A3TG7hVhlcvCA5Di5vVTtNniJFuhBC5EeK8lSncVKkCyGEeD2Hrz2k9az9/Hk0GIAB9UuwaWRDqhVzVjlZxvWtWwITDRy4+oArd+XM8EtpNP91ICe9vGcpKdKFECI/enQDYu6DqYX+l3AhhBDiFTyMTmD86tP0/PVfbj2Kw8PJmuWDa/Np+wpYWxj32fNnebrY0Kq86//bu+/4Kqr8/+Ovm3ZTSCUkIRAIvfcSgiAWFJBVEAsqK4htVWRV9LvKroLr7v7QVYFVEdQV2LUBKmBBQciKdJAmPXRCS6jppN07vz8uiUQIEEgyc2/ez8djHpnMnbl5z53cnHzunDkD6Gz6ZWt9tsv7roVw5rS5WTyIinQRkeqo+Cx6TFvwsZubRURE3I7TaTBjTQo3jv+JL86OiH5fQj0WPHMt3RtFmpzuyg0/O4Dc7PWHOJ1TYG4YdxDVAqJagrPQdTs2qRAq0kVEqqOSQePU1V1ERMpnR2omd723khdmbyY9t5DmMcF8+Xh3/t/tbahh9zE73lXp2iCCVrEh5Bc5+eznFLPjuIfis+lbvjQ3hwdRkS4iUh0dOluk6/7oIiJymXILihj33Xb6v7WMdQdOE+jnzYv9W/DtyB50qu8+155fjM1mY/g1DQD474oDFDqcJidyA8WjvO/9CXJOmJvFQ6hIFxGpbgpyIXWLa15n0kVE5DL8sDWVm8Yv4b0le3E4Dfq2imHRqF483LMhPha77/nVurVdbSJr+JGamcf8Lalmx7G+mo2gdnswHLDtK7PTeATPekeJiMil7f3R1ZCGxkFoXbPTiIiIhR06ncvD/1nLox+t43D6GeqGBzD1gc5Mub8TsWEBZserFHYfb4Yk1Adg6vJ9JqdxE8WjvG/RKO8VQUW6iEh1U9yAthxgbg4REbGsQoeT937aw03jl7Boexo+XjaeuK4RC5/pxQ3No82OV+mGdKuHr7eNDSnpbEjRqOWX1Op219cDyyHzqLlZPICKdBGR6qQgF5K/d80XX0MmIiJyjrX7T/G7t5Yx7vsdnCl00DU+gu+e6smf+jZ3u9uqXamoYH9ubRcL6HZslyUsDuISAAO2zTU7jduzRJE+adIk4uPj8ff3JyEhgTVr1lzWdjNmzMBmszFw4MDKDSgi4il2LYDCHAirD3U6mp1GREQs5HROAc9/sYk7p6wkOS2LiCA/Xr+zLTP/0I2m0cFmx6tyD54dQO67zUdJzcgzOY0bKOnyrlHer5bpRfrMmTMZNWoUY8eOZf369bRr144+ffpw7Nixi263f/9+nnvuOXr27FlFSUVEPEBxV/dWt4PNZm4WERGxBMMw+HztQW54czEz1x4E4J4ucSSN6sVdneOwVdP2onWdULrGR1DkNPho1X6z41hfy4Fg84JDP8PpA2ancWumF+njx4/nkUceYfjw4bRs2ZIpU6YQGBjI1KlTy9zG4XAwZMgQ/vrXv9KwYcMqTCsi4sbys2DXD6751urqLiIisCsti8Hvr+L/vtjE6dxCmkUH88Vjibx6R1vCg/zMjme64dfEA/Dp6hTyCh3mhrG64GiI7+Ga3zrH3CxuztQivaCggHXr1tG7d++SZV5eXvTu3ZuVK1eWud0rr7xCVFQUDz300CV/Rn5+PpmZmaUmEZFqKXk+FOVBRCOIaWt2GhERMdGZAgevzd9Bv38tZc2+UwT4ejO6X3O+/WMPOsdHmB3PMm5qGU2dsABO5xYyd8Nhs+NYX/F4N+ryflVMLdJPnDiBw+EgOrr0CJHR0dGkpl74noTLli3jww8/5IMPPrisnzFu3DhCQ0NLpri4uKvOLSLilrae7ereepC6uouIVGM/7TzOTRN+YvLiPRQ5DW5qGc2iZ3vxh16N8PWwe55fLR9vL4Z1d92Obdry/RiGYXIii2txG3j5QOomOLHb7DRuy63ehVlZWdx///188MEHREZGXtY2o0ePJiMjo2Q6ePBgJacUEbGgM+mwe5FrXqO6i4hUS6dzChg1cyPDpq7h0Okz1AkL4IOhnflgaGfqeOg9zyvC4M71CPTzJjktixV7Tpodx9qCakLD613zW3XP9CvlY+YPj4yMxNvbm7S0tFLL09LSiImJOW/9PXv2sH//fm699daSZU6nEwAfHx+Sk5Np1KhRqW3sdjt2u70S0ouIuJHk78BRALVaQHRLs9OIiEgVMgyDr385wivfbONkTgE2Gwzv3oBnb25KkN3UcsAthAb6ckfHuny06gDTlu/jmsaXd7Kw2mo9CHYvhM1fwLX/p957V8DUM+l+fn506tSJpKSkkmVOp5OkpCQSExPPW7958+Zs3ryZjRs3lky33XYb119/PRs3blRXdhGRsmw5p6u7iIhUG4fTz/Dg9J95asZGTuYU0Cw6mNmPd2fMrS1VoJfDA2cHkEvacYz9J3LMDWN1zfuDtx+cSIZj28xO45ZMf2eOGjWKYcOG0blzZ7p27crEiRPJyclh+PDhAAwdOpQ6deowbtw4/P39ad26dantw8LCAM5bLiIiZ+Wegr0/uubV1V1EpFpwOg0+WnWAf87fQU6BAz9vL0be0Jg/9GqEn49bXfFqCY1q1eC6ZrVYnHyc6Sv28/JtrcyOZF3+odDkZtjxrWsAuWi9VuVl+jt08ODBvPHGG4wZM4b27duzceNG5s+fXzKYXEpKCkePHjU5pYiIG9v+NTiLIKYNRDY2O41UM0uWLOHWW28lNjYWm83G3LlzL7nN4sWL6dixI3a7ncaNGzN9+vRKzyniSXalZXHnlBWM/XorOQUOOtcP57unejDyxiYq0K/Cg9c0AOCLdYfIyis0OY3FFffc2zIbNNheuZl+Jh3gySef5Mknn7zgY4sXL77otmq4RUQuobiru86iiwlycnJo164dDz74IIMGXfp3cN++ffTv35/HHnuMTz75hKSkJB5++GFq165Nnz59qiCxiPsqKHIyefEeJv24mwKHkxp2H57v15whXevh5aXrgq9WzyaRNI6qwe5j2cxae4iHejQwO5J1Ne0LvoFweh8c2QB1OpqdyK1YokgXEZFKkn0M9i91zbe63dwsUi3169ePfv36Xfb6U6ZMoUGDBrz55psAtGjRgmXLljFhwgQV6SIXsT7lNC98uYmdadkA3Ng8ir8NbE2sRm2vMDabjeHXxPOXOVv4z4r9PNA9Hm99+HFhfkGuQn3rbFeXdxXp5aL+LiIinmzbV2A4IbYjROgTf7G+lStX0rt371LL+vTpw8qVKy+6XX5+PpmZmaUmkeogJ7+Il7/eyh2TV7AzLZuaQX68fW8H/j2sswr0SjCoQ11CA3xJOZVL0va0S29QnbW+w/V161w4e0cuuTwq0kVEPNnWOa6vGtVd3ERqamrJuDTFoqOjyczM5MyZM2VuN27cOEJDQ0sm3fFFqoMfk49x84QlTF+xH8OAOzrWZdGoXtzazjUGhFS8AD9v7unq+vsybfl+c8NYXePeYA+BzENwaI3ZadyKinQREU+VeRQOrHDNq6u7eLjRo0eTkZFRMh08eNDsSCKV5mR2Pk/P2MDwaT9zOP0MdcMD+Oihrrx5dzvCg/zMjufxhia6urmv3HuS7UfVa6dMvv6u27GBq8u7XDYV6SIinmrbXMCAuG4QWtfsNCKXJSYmhrS00l1I09LSCAkJISCg7K67drudkJCQUpOIpzEMg7kbDnPThCXM3XgELxs83KMBPzxzLT2b1DI7XrVRJyyAvq1iAPj30n0mp7G4Ul3eHaZGcScq0kVEPFXxqO7q6i5uJDExkaSkpFLLFi5cSGJiokmJRKzh0Olchk//madnbuRUTgHNY4KZ/cQ1vPi7lgT6aSzoqvZwT9c4L3M2HGL3sSyT01hYw+sgIBxyjsH+ZWancRsq0kVEPFF6ytnrv2zQcoDZaaQay87OZuPGjWzcuBFw3WJt48aNpKSkAK5u6kOHDi1Z/7HHHmPv3r386U9/YseOHbz77rvMmjWLZ555xoz4IqYzDIOPVx3g5glLWJx8HD8fL/6vTzO+GdmD9nFhZsertjrUC6d3i2icBry+INnsONbl7QstbnPNq8v7ZVORLiLiiYoHjIvvAcEx5maRam3t2rV06NCBDh06ADBq1Cg6dOjAmDFjADh69GhJwQ7QoEED5s2bx8KFC2nXrh1vvvkm//73v3X7NamWUjPyGDbtZ16cu4XcAgdd4sP5/qmejLi+Mb7e+jfebH/q2wwvGyzYmsb6lNNmx7Gu4i7v278GR6G5WdyE+saIiHii4q7uGjBOTHbddddhGEaZj0+fPv2C22zYsKESU4lYm2EYfLXxCGO+2kJmXhF2Hy+e79ucB7rH46X7cltG0+hgBnWsyxfrDvHa9zuY8Wg3jap/IfE9ICjK1eV972JocpPZiSxPH8GJiHiak3vg6Eaweauru4iImzmVU8CIT9fz9MyNZOYV0a5uKPP+2JMHezRQgW5Bz9zUFD8fL1bvO8VPO4+bHceavLyh1UDXvLq8XxYV6SIinqa4q3uDayEo0twsIiJy2ZK2p3HzhCV8tzkVHy8bo25qypePd6dxVA2zo0kZ6oQFMLRbfQBem5+M01l2z6FqraTL+7dQmGduFjegIl1ExNMUF+ka1V1ExC1k5RXypy9+4aH/rOVEdj5Nomowd8Q1/PHGJvjo2nPLG3F9Y4LtPmw/msk3m46YHcea6naFkLpQkAW7F5mdxvL0rhcR8STHd0LaFvDygea/MzuNiIhcwso9J+k7cSmz1h7CZoNHejbgm5E9aF0n1OxocpnCg/z4Q6+GALz5w04KipwmJ7IgLy91eS8HFekiIp5k69kB4xrdAIER5mYREZEy5RU6eOWbbdz7wSoOp58hLiKAGY904y/9W+Lv6212PCmnB3s0oFawnZRTuXy2JuXSG1RHxV3ed86Hghxzs1icinQREU9hGL9+Ol3cEIqIiOVsOpRO/7eWMnX5PgDu7VqP75+6loSGNU1OJlcq0M+HP97YBIC3/7eLnPwikxNZUGwHCG8AhbmQ/L3ZaSxNRbqIiKdI2wondoK3HZrdYnYaERH5jUKHkwkLd3L7uyvYczyHqGA70x7owrhBbahh152R3d09XeKoXzOQE9kF/HvpPrPjWI/N9utJhOLxc+SCVKSLiHiK4q7uTW4C/xBzs4iISCm70rIY9O4K/pW0C4fT4Hdta7Pg6Wu5vnmU2dGkgvh6e/Hszc0AeH/JHk5m55ucyIKKB7Xd9QPkZZibxcJUpIuIeALDgC1ni/RWt5ubRURESjicBh8s2Uv/t5ex+XAGoQG+vHVvB965ryPhQX5mx5MK9rs2tWkVG0JOgYN3ftxtdhzriWoJtZqDowB2zDM7jWWpSBcR8QRHN8LpfeATAE37mp1GRESAg6dyufeDVfzju+0UFDm5rlktfnjmWm5rF2t2NKkkXl42nu/bHIBPVqVw8FSuyYks5twu78UnF+Q8KtJFRDxBcUPXtA/Ya5ibRUSkmjMMgxlrUug7cQlr9p0iyM+bcYPaMO2BLkSH+JsdTypZzyaRdG9UkwKHkwmLdpodx3pane3yvvdHyDlpbhaLUpEuIuLuDAO2znXNF1/rJSIipjiWlcdD/1nLC7M3k1PgoGt8BN8/dS33dq2HzWYzO55UAZvt17PpczYcZkdqpsmJLCayMcS0BWcRbP/a7DSWpCJdRMTdHVoLGSngVwOa3Gx2GhGRamv+lqP0mbCE/+04hp+3F3++pTmfPdqNejUDzY4mVaxdXBi3tInBMOD1+clmx7Geki7vX5qbw6JUpIuIuLviUd2b9QPfAHOziIhUQ5l5hTw76xce+3g9p3MLaVE7hG9G9uDRaxvh7aWz59XVczc3w9vLRtKOY/y8/5TZcayleJDb/csgK9XcLBakIl1ExJ05nb/ea7T4U2kREakyq/eepN/EpXy5/hA2Gzx+XSPmjuhOs5hgs6OJyRrWqsHdneMAePX7HRiGYXIiCwmvD3W7AAb8729wer/ZiSxFRbqIiDtLWQlZR8EeCo1uMDuNiEi1kV/kYNx327nng1UcTj9DXEQAs/6QyPN9m2P38TY7nljE072b4O/rxboDp1m0/ZjZcayl/RDX1w0fw7/awQc3wMpJkHnE3FwWoCJdRMSdFXd1b/E78LGbm0VEpJrYfjSTAe8s570lezEMGNw5ju+fupYu8RFmRxOLiQ7xZ/g1DQB4fcEOHE6dTS/R6QEYOAUaXgc2Lzi8Dhb8Gca3hGm3wJoPIPu42SlN4WN2ABERuUKOItj2lWu+lUZ1FxGpbA6nwb+X7uXNH3ZS4HBSM8iPV+9oy00to82OJhb2WK9GfLo6hZ1p2cxef4i7znaBr/ZsNmh/r2vKPub6n2bLl65eggeWu6bv/wQNerku6WvxOwgINzt1ldCZdBERd3VgGeQch4AIaNjL7DQiIh7t4Klc7n1/FeO+30GBw0nvFtEseOZaFehySaEBvjxxXSMAJizcSV6hw+REFlQjCro+Ag/Oh2e2ws3/gNiOYDhd91P/+kl4vQl8Ohg2zYL8LLMTVyqdSRcRcVdbiru63wrevuZmERHxUIZh8MW6Q/z1m21k5xcR5OfN2FtbcVfnurrvuVy2Yd3jmb5iP0cy8vh41QEe7tnQ7EjWFVoXuj/pmk7tdQ2Qu2U2pG2BnfNdk4+/67azre+Apn087u42KtJFRNyRoxC2f+2ab62u7iIileFkdj6jZ2/mh21pAHSJD+fNu9rrvudSbv6+3jzduwnPf7mZST/u5u4ucYT46wP2S4poCD2fdU3HdrjG4tnyJZzc7fo/aPvX4FcDmt3iKtgb3QA+fmanvmoq0kVE3NHen+DMaQiqBfV7mJ1GRMTjJG1P4/kvN3EiuwBfbxujbmrGo9c21H3P5Yrd0bEu7y/Zy57jOXywZC/P3tzM7EjuJao5RP0ZrhsNqZtdxfqW2ZCRAptnuSb/UIhq6TrT7hvgGlTXJwB8/V1ffexnl/ufXcf/nMf9y94uIAy8qu6uDSrSRUTcUfGo7i0HgLf+lIuIVJSc/CL+Pm8bn605CECz6GDGD25Hq9hQk5OJu/Px9uL/+jTjsY/X8++l+7g/sT5Rwf5mx3I/NhvUbuuaer/sGhW+uGDPTnUNPFfRnt4MYfUq/nnLoP/sRETcTVE+bP/WNa9R3UVEKsy6A6d4ZuYvpJzKxWaDh3s04Nmbm+Hvq/ueS8Xo0yqG9nFhbDyYzttJu/nbwNZmR3JvNhvU7eyabv47HFoLWUehKM81FeZB0RnX/06FZ84uO/t90Zmzj+ddfLmjwHU2vQqpSBcRcTe7kyA/A4JrQ71Es9OIiLi9giIn/0rayeTFe3AaUCcsgDfuakdio5pmRxMPY7PZeL5vc+79YBWfrUnhoR4NiI8MMjuWZ/DyhnoJFf+8TofrPu5VSLdgExFxN8Vd3VvdDl76My4icjV2H8ti0OTlTPrRVaAP6liH75/uqQJdKk1io5r0alqLIqfBmwt3mh1HLsXL23XGvip/ZJX+NBERuTqFZyD5e9e8urqLiFwxp9Ng+vJ99H9rGVsOZxIW6MvkIR0Zf3d7jbotle5PfV2Dxn3zyxG2HM4wOY1YjYp0ERF3susHKMiG0Hqu669ERKTc0jLzGDZtDS9/s438Iie9mtbih6evpV+b2mZHk2qiVWwoA9rHAvDa/B0mpxGrUZEuIuJOthR3dR9Y5V2vREQ8wXebj9Jn4hKW7jqB3ceLVwa0YvrwLkSFaJRtqVrP3tQMX28bS3edYMXuE2bHEQtRkS4i4i7ys2HnAtd8a3V1FxEpj8y8QkbN2sgTn6wnPbeQNnVCmffHngxNjMemDz3FBPVqBnJfV9dtvV6bvwPDMExOJFahIl1ExF3snO+6LUh4A6jd3uw0IiJuY82+U/SbuJTZ6w/jZYMnr2/Ml493p3FUDbOjSTX35A1NCPTz5pdDGczfkmp2HLEIFekiIu5i6xzX19aD1NVdROQyFBQ5efX7HQx+fyWH088QFxHArD8k8lyfZvj56N9gMV+tYDsP92wIwOs/JFPkcJqcSKxAf51ERNxBXoZr0DjQqO4iIpdhZ1oWAyctZ8pPezAMuKtTXb5/6lo6x0eYHU2klEd6NiAiyI+9x3P47OeDZscRC/AxO4CIiFyGHd+BowAim0F0K7PTiIhYltNp8J+V+xn3/Q4KipyEB/oyblAb+rbWyO1iTcH+vjx5fWNe+XYbL83dwjv/20X7uDDax4XTPi6MtnVDCbKrbKtOdLRFRNzB1rOjuquru4hImVIz8vi/L35h6S7XSNm9mtbi9TvbauR2sbwh3eqxZt8pFm5PIy0znwVb01iwNQ0ALxs0jQ4+W7iH0b5eGE2igvH20v8DnkpFuoiI1eWegj3/c82rq7uIyAXN23SUP8/ZTMaZQvx9vfjLLS34fbf6Grld3ILdx5sp93cit6CILYcz2XjwNBsPprMxJZ0jGXnsSM1iR2oWM852hw/y86ZN3dCSs+0d6oURrQ+jPIaKdBERq9vyJTiLILo11GpqdhoREUvJzCvk5a+2MnvDYQDa1AllwuD2Grld3FKgnw9dG0TQtcGvYyccy8xjw8H0kqJ906F0cgocrNp7ilV7T5WsVzvU/9ez7XFhtKkbSqCfyj13pKMmImJljiJY8ZZrvuMwc7OIiFjM6r0nGTXrFw6nn8HLBiOub8wfb2yCr7fGRhbPERXiT59WMfRpFQOAw2mw+1h2ydn2DSnp7EzL4mhGHkczUvn+7K3cvL1sxNcMpHZoAFEhdqJD/IkOdn2NCvEnOsROrWA7dh9vM3dPLkBFuoiIlW2dDekpEBgJHX5vdhoREUvIL3IwfuFO3l+yF8OAehGBTBjcjk71NXK7eD5vLxvNYoJpFhPM4C71AMjJL2Lz4YySs+0bD6aTmpnHnuM57Dmec9HniwjyI+ps8R4dck4RX7LMn8gafviU8eGX02mQX+TkTKGDvEIHZwodnClwkF/k4ExB6eV5xfMFTvKKHCWDO0aH+BMT6k9MiD/Rof4E232q9aUqKtJFRKzK6YRlE1zz3R4Hv0Bz84iIWMDe49k8+ekGth3NBODuznUZc2sramj0a6nGguw+dGtYk24Na5YsS83IY/exbI5l5ZGWmU9aZl7p+cx8ChxOTuUUcCqngB2pWWU+v80GkTXshAf6UugwOFPgIK+ouBiv+Hu7B/p5l3xoUFy4x4T4l5qvFWz32F4z+msmImJVuxbAsW3gFwxdHjY7jYiI6b7+5Qijv9xEToGDiCA/xg1qU9IFWERKiwl1nZ0ui2EYpOcWklaqcP91Pi0rn2OZeRzLysfhNDielc/xrPyL/kw/by/8fb3w9/UmwM+bAF9v7L7eBBQv8z13mTe+PjZOZReQmplHWmYeqRl5ZOYVkVvgYN+JHPadKLsXQPEHByWF/NkivnN8BN0aRrj1mXgV6SIiVmQYsHS8a77LgxAQZmocEREz5RU6+Nu32/hkdQoACQ0ieOveDhrNWuQq2Gw2woP8CA/yo/lFPutyOA1O5RSQlplHem4hdl8v/H28CfBzFd7Fxbe/r3eF3BbuTIHDVbCfU7ifO5+Wmc+xrDwKHb9+cLDlcGap52gYGcR9CfW4s1NdwgL9rjpTVVORLiJiRQdWwKE14G2Hbk+YnUZExDT7TuTwxCfr2X40E5sNRlzXmKd7Nynz+lgRqVjeXjZqBbsGmasKAX7exEcGER8ZVOY6TqfBqdyCs0X72SI+I4+UU7ks3JbG3hM5/H3edl5fkEz/trX5fbf6dIgLc5uz6yrSRUSsaNnZs+jt74NgdeUUkerpm1+OMHr2ZrLzi4gI8mPC4Pb0alrL7FgiYjIvLxuRNexE1rDTuk5oqcey84v4auNhPl6Vwvajmcxef5jZ6w/TonYIQxLqMbBDHcuPYWEzDMMwO0RVyszMJDQ0lIyMDEJCQsyOIyJyvqOb4L2eYPOCkesgoqHZiaSSqW2qeHpN3VteoYO/z9vGx6tc3du7NojgrXs6XPT6WhGRcxmGwcaD6XyyOoVvfjlSMsBdkJ83AzrU4fcJ9WkZW3XtQ3naJWt/hCAiUh0Vj+jeapAKdBGpdvaf7d5ePHr7k9ere7uIlJ/NZqNDvXA61Avnpf4t+WL9IT5ZfYC9x3P4dHUKn65OoUO9MIYk1Od3bWvj72ud+8XrTLqIiJWc3APvdAbDCY8tg5g2ZieSKqC2qeLpNXVP8zYd5fkvN6l7u4hUCsMwWLX3FJ+sPsCCrakUOlylcGiAL3d0rMuQbvVoVKtGpfxsnUkXEXFXK95yFehNblaBLiLVRl6hg//33Xb+u/IAAF3iw3nr3g7UDg0wOZmIeBKbzUZio5okNqrJ8ax8Zq09yKerUzicfoapy/cxdfk+EhvWZEi3etzcMgY/H3N68KhIFxGxisyjsPFT13yPZ8zNIiJSRQ6czGHEp+tLbqH0xHWNGHVTU3VvF5FKVSvYzojrG/NYr0Ys2XWcT1al8L8daazce5KVe08SWcOPuzvHcW/XesRFBFZpNhXpIiJWsWoSOAogrhvU7252GhGRSjdv01Fe+HITWflFhAf6MmFwe65rFmV2LBGpRry9bFzfLIrrm0VxOP0MM9ekMOPngxzLyufdxXuY/NMeZj6aSNcGEVWWSUW6iIgVnDkNa6e55nuOMjeLiEglyy9y8I95v3Zv71w/nLfvU/d2ETFXnbAARt3cjJE3NiFpexqfrE5hZ1oWHeqFVWkO9SMSEbGCNf+GgmyIauW6Hl3Ew0yaNIn4+Hj8/f1JSEhgzZo1Za47ffp0bDZbqcnfX7fe8hQHTuZwx+QVJQX649c14rNHu6lAFxHL8PX2om/r2nz0UAKLRvXCt4ovv9GZdBERsxXkwurJrvkez4DNZm4ekQo2c+ZMRo0axZQpU0hISGDixIn06dOH5ORkoqIu3LU5JCSE5OTkku9tel94hO83H+VPX/zavX383e25vrm6t4uIdQX7+1b5z9SZdBERs234CHJPQlh9aHW72WlEKtz48eN55JFHGD58OC1btmTKlCkEBgYyderUMrex2WzExMSUTNHR0VWYWCpafpGDl7/eyuOfrCcrv4hO9cOZ98eeKtBFRC5ARbqIiJkchbDibdf8NX8Eb3VwEs9SUFDAunXr6N27d8kyLy8vevfuzcqVK8vcLjs7m/r16xMXF8eAAQPYunXrRX9Ofn4+mZmZpSaxhpSTudw1ZSXTV+wH4LFejZjxaDdiw9S9XUTkQlSki4iYafMXkHEQgqKg/e/NTiNS4U6cOIHD4TjvTHh0dDSpqakX3KZZs2ZMnTqVr776io8//hin00n37t05dOhQmT9n3LhxhIaGlkxxcXEVuh9yZeZvSaX/20vZdCiDsEBfpj7QmRf6Na/y6ztFRNyJ/kKKiJjF6YRlE1zziU+ArwbGEgFITExk6NChtG/fnl69ejF79mxq1arFe++9V+Y2o0ePJiMjo2Q6ePBgFSaW3yoocvLKN9t47ON1ZOUV0bFeGPP+2JMbmuuyBRGRS1G/ShERsyR/ByeSwR4CnR80O41IpYiMjMTb25u0tLRSy9PS0oiJibms5/D19aVDhw7s3r27zHXsdjt2u/2qskrFOHQ6lxGfbuCXg+kAPNKzAX/qq7PnIiKXS38tRUTMYBiwbLxrvsvD4B9qbh6RSuLn50enTp1ISkoqWeZ0OklKSiIxMfGynsPhcLB582Zq165dWTGlgizalkb/t5bxy8F0Qvx9+GBoZ/7Sv6UKdBGRctCZdBERM+xfCofXgY8/dHvc7DQilWrUqFEMGzaMzp0707VrVyZOnEhOTg7Dhw8HYOjQodSpU4dx48YB8Morr9CtWzcaN25Meno6r7/+OgcOHODhhx82czfkIgodTl5fkMz7S/YC0C4ujHfu7UBcRKDJyURE3I8lPtacNGkS8fHx+Pv7k5CQwJo1a8pc94MPPqBnz56Eh4cTHh5O7969L7q+iIglLT17Fr3D76GGbkEknm3w4MG88cYbjBkzhvbt27Nx40bmz59fMphcSkoKR48eLVn/9OnTPPLII7Ro0YJbbrmFzMxMVqxYQcuWLc3aBbmII+lnuOf9VSUF+vBr4vn8D4kq0EVErpDNMAzDzAAzZ85k6NChTJkyhYSEBCZOnMjnn39OcnIyUVHn/+M6ZMgQrrnmGrp3746/vz+vvfYac+bMYevWrdSpU+eSPy8zM5PQ0FAyMjIICQmpjF0SEbm4Ixvg/evA5g1/3ADh9c1OJCZT21Tx9JpWjR+TjzFq5kZO5xYS7O/D63e2pW9rXZYgIvJb5WmXTC/SExIS6NKlC++88w7guk4tLi6OkSNH8sILL1xye4fDQXh4OO+88w5Dhw695PpqtEXEdLOGwravoO1gGPS+2WnEAtQ2VTy9ppWryOFk/MKdvLt4DwBt6oQy6b6O1Kups+ciIhdSnnbJ1GvSCwoKWLduHaNHjy5Z5uXlRe/evVm5cuVlPUdubi6FhYVERERc8PH8/Hzy8/NLvs/MzLy60CIiV+PEbtj2tWv+mqdNjSIiciXSMvMY+dkG1uw7BcDQxPr8pX8L7D7eJicTEfEMpl6TfuLECRwOR8k1acWio6NJTU29rOd4/vnniY2NpXfv3hd8fNy4cYSGhpZMcXFxV51bROSKLZ8IGNC0H0Tr+loRcS9Ldx3nln8tZc2+U9Sw+/DOfR14ZUBrFegiIhXIEgPHXalXX32VGTNmMGfOHPz9/S+4zujRo8nIyCiZDh48WMUpRUTOyjgMv8xwzfccZW4WEZFycDgNxv+QzNCpaziZU0DL2iF8M7IHv2sba3Y0ERGPY2p398jISLy9vUlLSyu1PC0tjZiYmItu+8Ybb/Dqq6+yaNEi2rZtW+Z6drsdu91eIXlFRK7KqnfBWQj1r4G4rmanERG5LMey8njqs42s3HsSgPsS6jHmdy3x99XZcxGRymDqmXQ/Pz86depEUlJSyTKn00lSUhKJiYllbvfPf/6Tv/3tb8yfP5/OnTtXRVQRkauTewrWTnPN99BZdBFxDyt2n+CWfy1j5d6TBPp586972vP/bm+jAl1EpBKZeiYdYNSoUQwbNozOnTvTtWtXJk6cSE5ODsOHDwdg6NCh1KlTh3HjxgHw2muvMWbMGD799FPi4+NLrl2vUaMGNWrUMG0/REQuas37UJgDMW2g8Y1mpxERuSiH02DSj7uZuGgnTgOaRQczaUhHGkfpfy0RkcpmepE+ePBgjh8/zpgxY0hNTaV9+/bMnz+/ZDC5lJQUvLx+PeE/efJkCgoKuPPOO0s9z9ixY3n55ZerMrqIyOUpyIHVU1zzPZ4Bm83cPCIiF3Eqp4CnZmxg6a4TANzduS5/va01AX46ey4iUhVMv096VdN9U0Wkyq18FxaMhvAGMHIdeOkfXSlNbVPF02t6ZTLOFHLP+6vYfjSTAF9v/j6wNXd0qmt2LBERt+c290kXEfF4RQWw8h3X/DVPqUAXEcvKK3TwyH/Wsv1oJpE17HzycALNYoLNjiUiUu249S3YREQsb/MsyDwMNWKg/X1mpxERuaBCh5MnP13Pmv2nCPb34b8PdlWBLiJiEhXpIiKVxemAZRNd84kjwEe3gxQR63E6DZ7/YhOLth/D7uPFh8O60DJWlwiIiJhFRbqISGXZMQ9O7gL/UOg83Ow0IiLnMQyDv8/bzuwNh/H2svHukI50bRBhdiwRkWpNRbqISGUwDFg23jXf9VGwq9uoiFjPu4v3MHX5PgBev7MtN7aINjmRiIioSBcRqQx7F8ORDeATAAmPmZ1GROQ8n6w+wOsLkgEY87uWDOqoUdxFRKxARbqISGVYNsH1teNQCIo0N4uIyG/M23SUF+duAWDkDY15sEcDkxOJiEgxFekiIhXt8DrY9xN4+UD3kWanEREpZemu4zw9cwOGAUMS6jHqpqZmRxIRkXOoSBcRqUi5p2DuE675NndDWJy5eUREzrEh5TR/+GgdhQ6D/m1r88qA1thsNrNjiYjIOVSki4hUlIIc+PRuOL4DgmvDDX8xO5GISIldaVkMn/4zuQUOejaJZMLd7fH2UoEuImI1KtJFRCqCoxBmDYVDP4N/GNw/B0I1CJOIWMOh07nc/+Ea0nMLaR8XxpTfd8LPR/8GiohYkf46i4hcLacT5j4Ouxe5RnMf8jlEtTA7lYgIACey8xn64RpSM/NoElWDaQ90IcjuY3YsEREpg4p0EZGrYRiwYDRs/tw1UNzgjyCuq9mpREQAyMor5IFpa9h7Ioc6YQF89FAC4UF+ZscSEZGLUJEuInI1lr4Bq6e45gdOhiY3mZtHROSsvEIHj/x3LVsOZ1IzyI+PH04gJtTf7FgiInIJKtJFRK7U2mnwv7+75vu+Cm3vNjePiMhZRQ4nf/xsA6v2niLY7sN/HuxKg8ggs2OJiMhlUJEuInIltn0F80a55ns+B90eNzePiMhZhmEwevZmftiWhp+PFx8M60zrOqFmxxIRkcukIl1EpLz2/gRfPgyGEzo9ADe8aHYiEZESr36/g8/XHcLby8ak+zrSrWFNsyOJiEg5qEgXESmPIxtgxn3gKIAWt0L/8WDTfYZFxBomL97De0v2AvDaHW25qWW0yYlERKS8VKSLiFyuE7vh4zuhIBvie8Kgf4OXt9mpREQA+GxNCq/N3wHAi/1bcGenuiYnEhGRK6EiXUTkcmQehY9uh9wTULsd3PMp+GqUZBGxhu83H+UvczYD8MR1jXi4Z0OTE4mIyJVSkS4icilnTsPHgyAjBSIawZAvwT/E7FQiIgD8tPM4T83YiNOAe7vG8X99mpkdSUREroKP2QFERCytIBc+HQzHtkGNGLh/DtSoZXYqERHyCh28+UMy/162D8OAfq1j+PvANtg0ToaIiFtTkS4iUhZHIXw+DA6uBv9QV4EeXt/sVCIibDyYzrOzNrLneA4Ad3Wqy99vb423lwp0ERF3pyJdRORCnE74agTs+gF8AuC+WRDd0uxUIlLN5Rc5eCtpF5MX78FpQK1gO68OasONLTSKu4iIp1CRLiLyW4YBP7wIm2aCzRvu/g/U62Z2KhGp5rYeyeDZWb+wIzULgAHtY3n51laEB/mZnExERCqSinQRqXxn0sHpcA225u1rdppLWzYBVk1yzQ98F5r2MTePiFRrhQ4n7/64h7f/t4sip0HNID/+PrA1/drUNjuaiIhUAhXpIlI5nA7YnQRrP3R1GTecruV+NcA/zHWNd0BY+eZ9A6CyB0Ra9x9I+qtrvs//g3b3VO7PExG5iJ1pWTw76xc2H84AoG+rGP5+e2sia9hNTiYiIpVFRbqIVKzs47DhI1g3DdJTzn+8INs1ZR4q/3N7+7kK9oAwCKoFoXEQFuf6GloXwuq5vvoGXFn27d/At0+75nuMgsQRV/Y8IiJXyeE0eH/JXiYs3EmBw0logC+vDGjFbe1iNXq7iIiHU5EuUtkcRZB+AE7s/HVyFEFkY4hs6poiGoKPG58VMQxIWeU6a77tK3AUuJb7h0L730Pn4RDeAPIzXfccz0uHvAxXN/jLms8Aw+F63pxjrunEzrLznFfAnzMfFucq9H/7T+6+pfDFQ64z/h2Hwo1jKvxlEhG5HHuOZ/Pc57+wISUdgBuaRzFuUBuiQ/zNDSYiIlVCRbpIRcnLgBO7SxfjJ3bBqb3gLLz4tjYvCI+Hmk0gssmvxXtkUwiqWSXxr0hepmtwtbVTXfcRLxbbEbo8BK0GgV/gr8sDI1xTeRmG6+x7cfF+Jh2y01xn6jMOQsYhSD/omi/IhpzjrunI+gs/n1/w2TPvZwv34BhY/hY48qH576D/hMrvVi8i8htOp8G0Ffv55/wd5Bc5Cbb78NKtLbmrU12dPRcRqUZUpIuUh9MJmYd/LcDPLcazU8vezjcQap5z5tzbp3RBn5/pKuZP7YVdC0pvGxBxdrtzi/cmEFbf9TxmSN0MP38Imz93FcXguk1ZmztdxXlsh4r9eTYb2INdE3Flr2cYrjP1vy3c01Nc32ccdBXvBVlwfLtrOld8T7jjQ/NeVxGptlJO5vLcF7+wZt8pAHo2ieS1O9oSG3aFl++IiIjb0n+iVyN5PqSsMDuFVDbDCZlHzhbUu6HoTNnr1og5v5iObAohdcDLq4znNyD7WOmCv/hrRgqcOQUHV7mmc3n7QUQjV7f5mk0gooGrS3l4PITEgpd3hb0EABTmubqyr/0QDq7+dXlkU+j8oGuAtYDwiv2Z5WWz/Xq2vna7C69TeOZsAX9O4Z5+EHz84Oa/g6+6k4rIr46kn+H9JXuJiwikXkQg9WsGEhceSIBfxfyNNQyDj1enMO677eQWOAj08+Yv/VtwX9d6OnsuIlJNqUi/GvuXwsp3zE4hVc3LF2o2Kl2M12ziKpb9Q8v/fDYbBEe7pgY9Sz9WkAMn95xfvJ/cBUV5Fz4bDK4CPqyeq2AvLtzD412FfFh9sNe4/Hyn9sLaabDhY9cHBgBePq5u4V0ecp19dqd/JH0Dzh67JmYnERE3kJyWxfQV+89bXivY7iraIwJLCvh6NV1fo4Ltl1VgH04/w/NfbGLZ7hMAJDSI4PU721GvZuAlthQREU+mIv1q1L/G7ARSVYJqQa1mroK8KruZ+wVB7bau6VxOp+sMcHHhfnI3nN7vmtJTXAOsndztmi4kqNb5xXvxfI0YV++BXQtcXdr3JP26XUgd6DQcOt7vuo5bRMTD1QkL4LFejTh4KpeUU7kcOJlDZl4Rx7PyOZ6Vz7oDp8/bxt/Xi7hwV8F+7hn44u/tPl58vvYQf/t2G1n5Rfj7evGnPs15oHs8Xl5u9KGniIhUCpthGIbZIapSZmYmoaGhZGRkEBISYnYckYrndLiumz+9H07t+7V4P312/sz5/1CW4uPvOtt87nqNbnSdNW/SR9dri1QCtU0VrzJf04zcQlLOFu2uKadk/kh6Hg7nxf+1Cgv0JT3XNaBox3phvHFXOxrWKkcPJxERcTvlaZf037aIp/HydnV1D6sHDa49//Ez6ecU7vt/Ld5P73ddm12U55oCIqDD2dunRTSsyj0QEbG00EBf2gSG0qbu+Zc4FTqcHEk/U7qIP/nr16z8ItJzC/Hz9uLZm5vycM+GeOvsuYiInENFukh1ExAGAe0htv35jzkKXYOp5RyHmLYaRE1EpJx8vb2oXzOI+jWDznvMMAwyzrjOwseE+hMVrL+xIiJyPhXpIvIrb1/X9ekRDcxOIiLicWw2G2GBfoQF+pkdRURELKyMe0KJiIiIiIiISFVTkS4iIiIiIiJiESrSRURERERERCxCRbqIiIiIiIiIRahIFxEREREREbEIFekiIiJS6SZNmkR8fDz+/v4kJCSwZs2ai67/+eef07x5c/z9/WnTpg3fffddFSUVERExl4p0ERERqVQzZ85k1KhRjB07lvXr19OuXTv69OnDsWPHLrj+ihUruPfee3nooYfYsGEDAwcOZODAgWzZsqWKk4uIiFQ9m2EYhtkhqlJmZiahoaFkZGQQEhJidhwRERGPb5sSEhLo0qUL77zzDgBOp5O4uDhGjhzJCy+8cN76gwcPJicnh2+//bZkWbdu3Wjfvj1Tpky5rJ/p6a+piIi4l/K0SzqTLiIiIpWmoKCAdevW0bt375JlXl5e9O7dm5UrV15wm5UrV5ZaH6BPnz5lrg+Qn59PZmZmqUlERMQdqUgXERGRSnPixAkcDgfR0dGllkdHR5OamnrBbVJTU8u1PsC4ceMIDQ0tmeLi4q4+vIiIiAlUpIuIiIjbGz16NBkZGSXTwYMHzY4kIiJyRXzMDiAiIiKeKzIyEm9vb9LS0kotT0tLIyYm5oLbxMTElGt9ALvdjt1uv/rAIiIiJtOZdBEREak0fn5+dOrUiaSkpJJlTqeTpKQkEhMTL7hNYmJiqfUBFi5cWOb6IiIinkRn0kVERKRSjRo1imHDhtG5c2e6du3KxIkTycnJYfjw4QAMHTqUOnXqMG7cOACeeuopevXqxZtvvkn//v2ZMWMGa9eu5f333zdzN0RERKpEtSvSi+84p1FfRUTEKorbJE+9K+rgwYM5fvw4Y8aMITU1lfbt2zN//vySweFSUlLw8vq1c1/37t359NNPefHFF/nzn/9MkyZNmDt3Lq1bt77sn6n2XkRErKQ8bX21u0/6oUOHNOKriIhY0sGDB6lbt67ZMTyC2nsREbGiy2nrq12R7nQ6OXLkCMHBwdhstqt6rszMTOLi4jh48OAlb0hvddoX6/GU/QDP2RdP2Q/wnH3xlP0wDIOsrCxiY2NLnVGWK6f2/nyesh/gOfviKfsB2hcr8pT9AM/Yl/K09dWuu7uXl1eFn6UICQlx21+W39K+WI+n7Ad4zr54yn6A5+yLJ+xHaGio2RE8itr7snnKfoDn7Iun7AdoX6zIU/YD3H9fLret18f1IiIiIiIiIhahIl1ERERERETEIlSkXwW73c7YsWOx2+1mR7lq2hfr8ZT9AM/ZF0/ZD/CcffGU/RBr85TfM0/ZD/CcffGU/QDtixV5yn6AZ+3L5ah2A8eJiIiIiIiIWJXOpIuIiIiIiIhYhIp0EREREREREYtQkS4iIiIiIiJiESrSRURERERERCxCRfolTJo0ifj4ePz9/UlISGDNmjUXXf/zzz+nefPm+Pv706ZNG7777rsqSlq2cePG0aVLF4KDg4mKimLgwIEkJydfdJvp06djs9lKTf7+/lWUuGwvv/zyebmaN29+0W2seEzi4+PP2w+bzcaIESMuuL6VjseSJUu49dZbiY2NxWazMXfu3FKPG4bBmDFjqF27NgEBAfTu3Ztdu3Zd8nnL+16rCBfbl8LCQp5//nnatGlDUFAQsbGxDB06lCNHjlz0Oa/kd7Qy9wPggQceOC9T3759L/m8VjsmwAXfNzabjddff73M5zTjmIj7cff2Xm29tY5HMXdt79XWq62vTGrrL01F+kXMnDmTUaNGMXbsWNavX0+7du3o06cPx44du+D6K1as4N577+Whhx5iw4YNDBw4kIEDB7Jly5YqTl7aTz/9xIgRI1i1ahULFy6ksLCQm2++mZycnItuFxISwtGjR0umAwcOVFHii2vVqlWpXMuWLStzXasek59//rnUPixcuBCAu+66q8xtrHI8cnJyaNeuHZMmTbrg4//85z956623mDJlCqtXryYoKIg+ffqQl5dX5nOW971WUS62L7m5uaxfv56XXnqJ9evXM3v2bJKTk7ntttsu+bzl+R2tCJc6JgB9+/Ytlemzzz676HNa8ZgApfbh6NGjTJ06FZvNxh133HHR563qYyLuxRPae7X11joexdy1vVdbr7a+MqmtvwyGlKlr167GiBEjSr53OBxGbGysMW7cuAuuf/fddxv9+/cvtSwhIcH4wx/+UKk5y+vYsWMGYPz0009lrjNt2jQjNDS06kJdprFjxxrt2rW77PXd5Zg89dRTRqNGjQyn03nBx616PABjzpw5Jd87nU4jJibGeP3110uWpaenG3a73fjss8/KfJ7yvtcqw2/35ULWrFljAMaBAwfKXKe8v6MV7UL7MWzYMGPAgAHleh53OSYDBgwwbrjhhouuY/YxEevzxPZebb21jkcxd2zv1dafz+x2RW39+cw+JhVNZ9LLUFBQwLp16+jdu3fJMi8vL3r37s3KlSsvuM3KlStLrQ/Qp0+fMtc3S0ZGBgAREREXXS87O5v69esTFxfHgAED2Lp1a1XEu6Rdu3YRGxtLw4YNGTJkCCkpKWWu6w7HpKCggI8//pgHH3wQm81W5npWPR7n2rdvH6mpqaVe89DQUBISEsp8za/kvWaWjIwMbDYbYWFhF12vPL+jVWXx4sVERUXRrFkzHn/8cU6ePFnmuu5yTNLS0pg3bx4PPfTQJde14jERa/DU9l5tvbWOB3hOe6+23sWK7YraeusdkyulIr0MJ06cwOFwEB0dXWp5dHQ0qampF9wmNTW1XOubwel08vTTT3PNNdfQunXrMtdr1qwZU6dO5auvvuLjjz/G6XTSvXt3Dh06VIVpz5eQkMD06dOZP38+kydPZt++ffTs2ZOsrKwLru8Ox2Tu3Lmkp6fzwAMPlLmOVY/HbxW/ruV5za/kvWaGvLw8nn/+ee69915CQkLKXK+8v6NVoW/fvvz3v/8lKSmJ1157jZ9++ol+/frhcDguuL67HJP//Oc/BAcHM2jQoIuuZ8VjItbhie292nprHY9intLeq623Zruitt56x+Rq+JgdQKrWiBEj2LJlyyWv0UhMTCQxMbHk++7du9OiRQvee+89/va3v1V2zDL169evZL5t27YkJCRQv359Zs2adVmfsFnRhx9+SL9+/YiNjS1zHasej+qisLCQu+++G8MwmDx58kXXteLv6D333FMy36ZNG9q2bUujRo1YvHgxN954oymZKsLUqVMZMmTIJQdVsuIxEalMauutSe29tamtt6bq2tbrTHoZIiMj8fb2Ji0trdTytLQ0YmJiLrhNTExMudavak8++STffvstP/74I3Xr1i3Xtr6+vnTo0IHdu3dXUrorExYWRtOmTcvMZfVjcuDAARYtWsTDDz9cru2sejyKX9fyvOZX8l6rSsWN9oEDB1i4cOFFP1m/kEv9jpqhYcOGREZGlpnJ6scEYOnSpSQnJ5f7vQPWPCZiHk9r79XWu1jleBTzpPZebf35rNiuqK233jEpDxXpZfDz86NTp04kJSWVLHM6nSQlJZX6hPNciYmJpdYHWLhwYZnrVxXDMHjyySeZM2cO//vf/2jQoEG5n8PhcLB582Zq165dCQmvXHZ2Nnv27Ckzl1WPSbFp06YRFRVF//79y7WdVY9HgwYNiImJKfWaZ2Zmsnr16jJf8yt5r1WV4kZ7165dLFq0iJo1a5b7OS71O2qGQ4cOcfLkyTIzWfmYFPvwww/p1KkT7dq1K/e2VjwmYh5Pae/V1lvrePyWJ7X3auvPZ8V2RW299Y5JuZg7bp21zZgxw7Db7cb06dONbdu2GY8++qgRFhZmpKamGoZhGPfff7/xwgsvlKy/fPlyw8fHx3jjjTeM7du3G2PHjjV8fX2NzZs3m7ULhmEYxuOPP26EhoYaixcvNo4ePVoy5ebmlqzz233561//aixYsMDYs2ePsW7dOuOee+4x/P39ja1bt5qxCyWeffZZY/Hixca+ffuM5cuXG7179zYiIyONY8eOGYbhPsfEMFwjaNarV894/vnnz3vMyscjKyvL2LBhg7FhwwYDMMaPH29s2LChZBTUV1991QgLCzO++uorY9OmTcaAAQOMBg0aGGfOnCl5jhtuuMF4++23S76/1HvNjH0pKCgwbrvtNqNu3brGxo0bS7138vPzy9yXS/2OVvV+ZGVlGc8995yxcuVKY9++fcaiRYuMjh07Gk2aNDHy8vLK3A8rHpNiGRkZRmBgoDF58uQLPocVjom4F09o79XWW+t4nMsd23u19WrrK5Pa+ktTkX4Jb7/9tlGvXj3Dz8/P6Nq1q7Fq1aqSx3r16mUMGzas1PqzZs0ymjZtavj5+RmtWrUy5s2bV8WJzwdccJo2bVrJOr/dl6effrpkv6Ojo41bbrnFWL9+fdWH/43BgwcbtWvXNvz8/Iw6deoYgwcPNnbv3l3yuLscE8MwjAULFhiAkZycfN5jVj4eP/744wV/n4rzOp1O46WXXjKio6MNu91u3HjjjeftY/369Y2xY8eWWnax95oZ+7Jv374y3zs//vhjmftyqd/Rqt6P3Nxc4+abbzZq1apl+Pr6GvXr1zceeeSR8xpgdzgmxd577z0jICDASE9Pv+BzWOGYiPtx9/Zebb21jse53LG9V1uvtt6sfSlW3dt6m2EYxpWehRcRERERERGRiqNr0kVEREREREQsQkW6iIiIiIiIiEWoSBcRERERERGxCBXpIiIiIiIiIhahIl1ERERERETEIlSki4iIiIiIiFiEinQRERERERERi1CRLiIiIiIiImIRKtJFpMrZbDbmzp1rdgwRERGpJGrrRa6cinSRauaBBx7AZrOdN/Xt29fsaCIiIlIB1NaLuDcfswOISNXr27cv06ZNK7XMbreblEZEREQqmtp6EfelM+ki1ZDdbicmJqbUFB4eDri6p02ePJl+/foREBBAw4YN+eKLL0ptv3nzZm644QYCAgKoWbMmjz76KNnZ2aXWmTp1Kq1atcJut1O7dm2efPLJUo+fOHGC22+/ncDAQJo0acLXX39duTstIiJSjaitF3FfKtJF5DwvvfQSd9xxB7/88gtDhgzhnnvuYfv27QDk5OTQp08fwsPD+fnnn/n8889ZtGhRqYZ58uTJjBgxgkcffZTNmzfz9ddf07hx41I/469//St33303mzZt4pZbbmHIkCGcOnWqSvdTRESkulJbL2JhhohUK8OGDTO8vb2NoKCgUtM//vEPwzAMAzAee+yxUtskJCQYjz/+uGEYhvH+++8b4eHhRnZ2dsnj8+bNM7y8vIzU1FTDMAwjNjbW+Mtf/lJmBsB48cUXS77Pzs42AOP777+vsP0UERGprtTWi7g3XZMuUg1df/31TJ48udSyiIiIkvnExMRSjyUmJrJx40YAtm/fTrt27QgKCip5/JprrsHpdJKcnIzNZuPIkSPceOONF83Qtm3bkvmgoCBCQkI4duzYle6SiIiInENtvYj7UpEuUg0FBQWd1yWtogQEBFzWer6+vqW+t9lsOJ3OyogkIiJS7aitF3FfuiZdRM6zatWq875v0aIFAC1atOCXX34hJyen5PHly5fj5eVFs2bNCA4OJj4+nqSkpCrNLCIiIpdPbb2IdelMukg1lJ+fT2pqaqllPj4+REZGAvD555/TuXNnevTowSeffMKaNWv48MMPARgyZAhjx45l2LBhvPzyyxw/fpyRI0dy//33Ex0dDcDLL7/MY489RlRUFP369SMrK4vly5czcuTIqt1RERGRakptvYj7UpEuUg3Nnz+f2rVrl1rWrFkzduzYAbhGY50xYwZPPPEEtWvX5rPPPqNly5YABAYGsmDBAp566im6dOlCYGAgd9xxB+PHjy95rmHDhpGXl8eECRN47rnniIyM5M4776y6HRQREanm1NaLuC+bYRiG2SFExDpsNhtz5sxh4MCBZkcRERGRSqC2XsTadE26iIiIiIiIiEWoSBcRERERERGxCHV3FxEREREREbEInUkXERERERERsQgV6SIiIiIiIiIWoSJdRERERERExCJUpIuIiIiIiIhYhIp0EREREREREYtQkS4iIiIiIiJiESrSRURERERERCxCRbqIiIiIiIiIRfx/nDubmlP5CN8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 및 검증 정확도 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_exp26.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_exp26.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_exp26.history['loss'], label='Training Loss')\n",
    "plt.plot(history_exp26.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
